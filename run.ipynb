{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n",
      "tensor([[-1.3852, -0.9624, -1.0003],\n",
      "        [-1.3570, -1.1749, -0.8354],\n",
      "        [-1.3794, -1.2678, -0.7618],\n",
      "        [-1.3699, -1.1893, -0.8177],\n",
      "        [-1.3667, -1.2508, -0.7792]])\n",
      "tensor([[-0.0341, -4.1614, -4.0227],\n",
      "        [-4.5262, -0.0158, -5.3256],\n",
      "        [-3.7815, -4.2559, -0.0377],\n",
      "        [-0.0226, -4.4558, -4.5316],\n",
      "        [-4.6019, -0.0128, -5.9298]])\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "######################################################################\n",
    "# Create the model:\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "\n",
    "######################################################################\n",
    "# Train the model:\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)\n",
    "\n",
    "######################################################################\n",
    "# Exercise: Augmenting the LSTM part-of-speech tagger with character-level features\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# In the example above, each word had an embedding, which served as the\n",
    "# inputs to our sequence model. Let's augment the word embeddings with a\n",
    "# representation derived from the characters of the word. We expect that\n",
    "# this should help significantly, since character-level information like\n",
    "# affixes have a large bearing on part-of-speech. For example, words with\n",
    "# the affix *-ly* are almost always tagged as adverbs in English.\n",
    "#\n",
    "# To do this, let :math:`c_w` be the character-level representation of\n",
    "# word :math:`w`. Let :math:`x_w` be the word embedding as before. Then\n",
    "# the input to our sequence model is the concatenation of :math:`x_w` and\n",
    "# :math:`c_w`. So if :math:`x_w` has dimension 5, and :math:`c_w`\n",
    "# dimension 3, then our LSTM should accept an input of dimension 8.\n",
    "#\n",
    "# To get the character level representation, do an LSTM over the\n",
    "# characters of a word, and let :math:`c_w` be the final hidden state of\n",
    "# this LSTM. Hints:\n",
    "#\n",
    "# * There are going to be two LSTM's in your new model.\n",
    "#   The original one that outputs POS tag scores, and the new one that\n",
    "#   outputs a character-level representation of each word.\n",
    "# * To do a sequence model over characters, you will have to embed characters.\n",
    "#   The character embeddings will be the input to the character LSTM.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_vocab(answer_vocab_dir):\n",
    "    index2answer = []\n",
    "    answer2index = {}\n",
    "    with open(answer_vocab_dir, 'r') as file:\n",
    "        answers = file.readlines()\n",
    "        for i in range(len(answers)):\n",
    "            w = word_tokenize(answers[i])\n",
    "            index2answer.append(w)\n",
    "            if w in answer2index:\n",
    "                print(answer2index[w], i, w)\n",
    "            answer2index[w] = i\n",
    "    pickle.dump((index2answer, answer2index), open(\"../data/vocabs/answer_index.pkl\",'wb'))\n",
    "    return index2answer, answer2index\n",
    "\n",
    "def word_tokenize(word):\n",
    "    word = word.lower()\n",
    "    word = word.replace(\"?\", \"\").replace(\"'s\", \" 's\") \n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "i2a, a2i = answer_vocab(\"../data/vocabs/answers_textvqa_more_than_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3995, 3995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2a), len(a2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计单词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(open(\"../data/imdb/textvqa_0.5/imdb_textvqa_train.npy\", \"rb\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=1 python run.py --config options/al/exp_1_15_9.yaml  --eval_name test #--is_train True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=1 python run.py --config options/al/exp_1_17_1.yaml  --is_train True --eval_name test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=1 python run.py --config options/al/exp_1_17_1.yaml  --eval_name test #--is_train True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . .\n",
      "Total 34602 train samples.\n",
      "Use 34602 train samples.\n",
      "no existing answer 9241\n",
      "Total 5000 val samples.\n",
      "Use 5000 val samples.\n",
      "no existing answer 1345\n",
      "nParams: 61824341\n",
      "sucees to create model.\n",
      "train with train dataset\n",
      "Epoch 1 of Train:\n",
      "/home/zs/anaconda2/envs/py3_pt4/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "[1/541/9] iter:10 accuracy:0.00 loss:17.26013 lr: 0.000375\n",
      "[1/541/19] iter:20 accuracy:0.00 loss:6.37488 lr: 0.000375\n",
      "[1/541/29] iter:30 accuracy:0.52 loss:2.86010 lr: 0.000375\n",
      "[1/541/39] iter:40 accuracy:7.81 loss:1.58068 lr: 0.000375\n",
      "[1/541/49] iter:50 accuracy:7.29 loss:1.00685 lr: 0.000375\n",
      "[1/541/59] iter:60 accuracy:10.94 loss:0.75308 lr: 0.000375\n",
      "[1/541/69] iter:70 accuracy:10.94 loss:0.68325 lr: 0.000375\n",
      "[1/541/79] iter:80 accuracy:7.29 loss:0.74481 lr: 0.000375\n",
      "[1/541/89] iter:90 accuracy:4.69 loss:0.64164 lr: 0.000375\n",
      "[1/541/99] iter:100 accuracy:17.71 loss:0.62559 lr: 0.000375\n",
      "[1/541/109] iter:110 accuracy:6.77 loss:0.58874 lr: 0.000375\n",
      "[1/541/119] iter:120 accuracy:9.90 loss:0.50894 lr: 0.000375\n",
      "[1/541/129] iter:130 accuracy:18.75 loss:0.54054 lr: 0.000375\n",
      "[1/541/139] iter:140 accuracy:8.85 loss:0.54902 lr: 0.000375\n",
      "[1/541/149] iter:150 accuracy:10.94 loss:0.51534 lr: 0.000375\n",
      "[1/541/159] iter:160 accuracy:8.33 loss:0.60288 lr: 0.000375\n",
      "[1/541/169] iter:170 accuracy:19.79 loss:0.59032 lr: 0.000375\n",
      "[1/541/179] iter:180 accuracy:21.88 loss:0.61328 lr: 0.000375\n",
      "[1/541/189] iter:190 accuracy:16.67 loss:0.51272 lr: 0.000375\n",
      "[1/541/199] iter:200 accuracy:16.67 loss:0.43058 lr: 0.000375\n",
      "[1/541/209] iter:210 accuracy:18.75 loss:0.57475 lr: 0.000375\n",
      "[1/541/219] iter:220 accuracy:16.67 loss:0.54555 lr: 0.000375\n",
      "[1/541/229] iter:230 accuracy:19.27 loss:0.59237 lr: 0.000375\n",
      "[1/541/239] iter:240 accuracy:22.40 loss:0.47585 lr: 0.000375\n",
      "[1/541/249] iter:250 accuracy:19.27 loss:0.57105 lr: 0.000375\n",
      "[1/541/259] iter:260 accuracy:20.31 loss:0.47312 lr: 0.000375\n",
      "[1/541/269] iter:270 accuracy:23.96 loss:0.58965 lr: 0.000375\n",
      "[1/541/279] iter:280 accuracy:16.15 loss:0.46869 lr: 0.000375\n",
      "[1/541/289] iter:290 accuracy:23.44 loss:0.56490 lr: 0.000375\n",
      "[1/541/299] iter:300 accuracy:18.23 loss:0.60672 lr: 0.000375\n",
      "[1/541/309] iter:310 accuracy:16.67 loss:0.55276 lr: 0.000375\n",
      "[1/541/319] iter:320 accuracy:20.31 loss:0.48772 lr: 0.000375\n",
      "[1/541/329] iter:330 accuracy:16.15 loss:0.51063 lr: 0.000375\n",
      "[1/541/339] iter:340 accuracy:21.88 loss:0.48493 lr: 0.000375\n",
      "[1/541/349] iter:350 accuracy:22.40 loss:0.48663 lr: 0.000375\n",
      "[1/541/359] iter:360 accuracy:21.35 loss:0.52003 lr: 0.000375\n",
      "[1/541/369] iter:370 accuracy:29.69 loss:0.50046 lr: 0.000375\n",
      "[1/541/379] iter:380 accuracy:15.10 loss:0.48823 lr: 0.000375\n",
      "[1/541/389] iter:390 accuracy:13.02 loss:0.40622 lr: 0.000375\n",
      "[1/541/399] iter:400 accuracy:13.54 loss:0.42786 lr: 0.000375\n",
      "[1/541/409] iter:410 accuracy:25.52 loss:0.64443 lr: 0.000375\n",
      "[1/541/419] iter:420 accuracy:19.27 loss:0.40775 lr: 0.000375\n",
      "[1/541/429] iter:430 accuracy:14.06 loss:0.52857 lr: 0.000375\n",
      "[1/541/439] iter:440 accuracy:17.71 loss:0.50184 lr: 0.000375\n",
      "[1/541/449] iter:450 accuracy:22.92 loss:0.61557 lr: 0.000375\n",
      "[1/541/459] iter:460 accuracy:13.54 loss:0.55508 lr: 0.000375\n",
      "[1/541/469] iter:470 accuracy:20.31 loss:0.44957 lr: 0.000375\n",
      "[1/541/479] iter:480 accuracy:28.65 loss:0.52982 lr: 0.000375\n",
      "[1/541/489] iter:490 accuracy:30.21 loss:0.47027 lr: 0.000375\n",
      "[1/541/499] iter:500 accuracy:27.08 loss:0.54387 lr: 0.000375\n",
      "[1/541/509] iter:510 accuracy:25.00 loss:0.44700 lr: 0.000375\n",
      "[1/541/519] iter:520 accuracy:21.35 loss:0.48198 lr: 0.000375\n",
      "[1/541/529] iter:530 accuracy:34.90 loss:0.41881 lr: 0.000375\n",
      "[1/541/539] iter:540 accuracy:32.29 loss:0.47866 lr: 0.000375\n",
      "Epoch 1 of Valuation:\n",
      "[0] accuracy:21.354 loss:0.631\n",
      "[5] accuracy:21.875 loss:0.581\n",
      "[10] accuracy:32.292 loss:0.681\n",
      "[15] accuracy:17.188 loss:0.549\n",
      "[20] accuracy:21.875 loss:0.629\n",
      "[25] accuracy:19.792 loss:0.654\n",
      "[30] accuracy:26.562 loss:0.518\n",
      "[35] accuracy:17.708 loss:0.611\n",
      "[40] accuracy:30.729 loss:0.563\n",
      "[45] accuracy:16.667 loss:0.612\n",
      "[50] accuracy:17.188 loss:0.672\n",
      "[55] accuracy:18.750 loss:0.594\n",
      "[60] accuracy:18.750 loss:0.549\n",
      "[65] accuracy:15.104 loss:0.616\n",
      "[70] accuracy:21.875 loss:0.545\n",
      "[75] accuracy:20.833 loss:0.585\n",
      "Result\n",
      "Train accuracy:16.57, Train loss: 0.02100, Val accuracy:21.41, Val loss: 0.00948\n",
      "Patient 0\n",
      "Epoch 2 of Train:\n",
      "[2/541/9] iter:551 accuracy:19.79 loss:0.49653 lr: 0.000750\n",
      "[2/541/19] iter:561 accuracy:25.52 loss:0.46274 lr: 0.000750\n",
      "[2/541/29] iter:571 accuracy:29.17 loss:0.48493 lr: 0.000750\n",
      "[2/541/39] iter:581 accuracy:26.56 loss:0.47509 lr: 0.000750\n",
      "[2/541/49] iter:591 accuracy:16.67 loss:0.48815 lr: 0.000750\n",
      "[2/541/59] iter:601 accuracy:21.35 loss:0.51762 lr: 0.000750\n",
      "[2/541/69] iter:611 accuracy:25.00 loss:0.49797 lr: 0.000750\n",
      "[2/541/79] iter:621 accuracy:23.96 loss:0.49055 lr: 0.000750\n",
      "[2/541/89] iter:631 accuracy:19.27 loss:0.44828 lr: 0.000750\n",
      "[2/541/99] iter:641 accuracy:18.23 loss:0.51811 lr: 0.000750\n",
      "[2/541/109] iter:651 accuracy:23.44 loss:0.46497 lr: 0.000750\n",
      "[2/541/119] iter:661 accuracy:33.33 loss:0.46918 lr: 0.000750\n",
      "[2/541/129] iter:671 accuracy:23.96 loss:0.55741 lr: 0.000750\n",
      "[2/541/139] iter:681 accuracy:33.33 loss:0.53561 lr: 0.000750\n",
      "[2/541/149] iter:691 accuracy:22.40 loss:0.35668 lr: 0.000750\n",
      "[2/541/159] iter:701 accuracy:26.56 loss:0.39254 lr: 0.000750\n",
      "[2/541/169] iter:711 accuracy:22.40 loss:0.38849 lr: 0.000750\n",
      "[2/541/179] iter:721 accuracy:30.21 loss:0.55022 lr: 0.000750\n",
      "[2/541/189] iter:731 accuracy:22.40 loss:0.43267 lr: 0.000750\n",
      "[2/541/199] iter:741 accuracy:28.65 loss:0.47529 lr: 0.000750\n",
      "[2/541/209] iter:751 accuracy:29.69 loss:0.52213 lr: 0.000750\n",
      "[2/541/219] iter:761 accuracy:28.12 loss:0.42477 lr: 0.000750\n",
      "[2/541/229] iter:771 accuracy:14.58 loss:0.41084 lr: 0.000750\n",
      "[2/541/239] iter:781 accuracy:25.52 loss:0.42706 lr: 0.000750\n",
      "[2/541/249] iter:791 accuracy:20.83 loss:0.43148 lr: 0.000750\n",
      "[2/541/259] iter:801 accuracy:21.88 loss:0.44834 lr: 0.000750\n",
      "[2/541/269] iter:811 accuracy:30.73 loss:0.46381 lr: 0.000750\n",
      "[2/541/279] iter:821 accuracy:21.35 loss:0.54722 lr: 0.000750\n",
      "[2/541/289] iter:831 accuracy:23.44 loss:0.37086 lr: 0.000750\n",
      "[2/541/299] iter:841 accuracy:36.46 loss:0.41262 lr: 0.000750\n",
      "[2/541/309] iter:851 accuracy:25.52 loss:0.37991 lr: 0.000750\n",
      "[2/541/319] iter:861 accuracy:26.56 loss:0.44807 lr: 0.000750\n",
      "[2/541/329] iter:871 accuracy:26.04 loss:0.45698 lr: 0.000750\n",
      "[2/541/339] iter:881 accuracy:22.92 loss:0.39691 lr: 0.000750\n",
      "[2/541/349] iter:891 accuracy:27.60 loss:0.44164 lr: 0.000750\n",
      "[2/541/359] iter:901 accuracy:41.67 loss:0.51287 lr: 0.000750\n",
      "[2/541/369] iter:911 accuracy:26.56 loss:0.38493 lr: 0.000750\n",
      "[2/541/379] iter:921 accuracy:15.62 loss:0.40851 lr: 0.000750\n",
      "[2/541/389] iter:931 accuracy:20.83 loss:0.43173 lr: 0.000750\n",
      "[2/541/399] iter:941 accuracy:31.77 loss:0.50118 lr: 0.000750\n",
      "[2/541/409] iter:951 accuracy:25.52 loss:0.39908 lr: 0.000750\n",
      "[2/541/419] iter:961 accuracy:28.12 loss:0.46471 lr: 0.000750\n",
      "[2/541/429] iter:971 accuracy:30.73 loss:0.47321 lr: 0.000750\n",
      "[2/541/439] iter:981 accuracy:24.48 loss:0.40076 lr: 0.000750\n",
      "[2/541/449] iter:991 accuracy:36.46 loss:0.47023 lr: 0.000750\n",
      "[2/541/459] iter:1001 accuracy:15.62 loss:0.42091 lr: 0.000750\n",
      "[2/541/469] iter:1011 accuracy:20.31 loss:0.50283 lr: 0.000750\n",
      "[2/541/479] iter:1021 accuracy:28.12 loss:0.44749 lr: 0.000750\n",
      "[2/541/489] iter:1031 accuracy:28.65 loss:0.48240 lr: 0.000750\n",
      "[2/541/499] iter:1041 accuracy:28.65 loss:0.39387 lr: 0.000750\n",
      "[2/541/509] iter:1051 accuracy:29.17 loss:0.50520 lr: 0.000750\n",
      "[2/541/519] iter:1061 accuracy:23.96 loss:0.42667 lr: 0.000750\n",
      "[2/541/529] iter:1071 accuracy:31.77 loss:0.44985 lr: 0.000750\n",
      "[2/541/539] iter:1081 accuracy:29.17 loss:0.42308 lr: 0.000750\n",
      "Epoch 2 of Valuation:\n",
      "[0] accuracy:26.042 loss:0.472\n",
      "[5] accuracy:29.167 loss:0.406\n",
      "[10] accuracy:39.062 loss:0.489\n",
      "[15] accuracy:22.396 loss:0.405\n",
      "[20] accuracy:23.958 loss:0.462\n",
      "[25] accuracy:25.000 loss:0.461\n",
      "[30] accuracy:28.646 loss:0.339\n",
      "[35] accuracy:21.875 loss:0.447\n",
      "[40] accuracy:31.250 loss:0.373\n",
      "[45] accuracy:27.604 loss:0.459\n",
      "[50] accuracy:23.438 loss:0.488\n",
      "[55] accuracy:24.479 loss:0.407\n",
      "[60] accuracy:19.792 loss:0.403\n",
      "[65] accuracy:21.875 loss:0.439\n",
      "[70] accuracy:20.833 loss:0.380\n",
      "[75] accuracy:23.438 loss:0.384\n",
      "Result\n",
      "Train accuracy:24.26, Train loss: 0.00722, Val accuracy:25.86, Val loss: 0.00676\n",
      "Patient 0\n",
      "Epoch 3 of Train:\n",
      "[3/541/9] iter:1092 accuracy:28.65 loss:0.34478 lr: 0.001125\n",
      "[3/541/19] iter:1102 accuracy:26.04 loss:0.48206 lr: 0.001125\n",
      "[3/541/29] iter:1112 accuracy:22.40 loss:0.45552 lr: 0.001125\n",
      "[3/541/39] iter:1122 accuracy:29.69 loss:0.38023 lr: 0.001125\n",
      "[3/541/49] iter:1132 accuracy:24.48 loss:0.45325 lr: 0.001125\n",
      "[3/541/59] iter:1142 accuracy:23.96 loss:0.38888 lr: 0.001125\n",
      "[3/541/69] iter:1152 accuracy:19.27 loss:0.38038 lr: 0.001125\n",
      "[3/541/79] iter:1162 accuracy:17.19 loss:0.40301 lr: 0.001125\n",
      "[3/541/89] iter:1172 accuracy:15.10 loss:0.49564 lr: 0.001125\n",
      "[3/541/99] iter:1182 accuracy:21.35 loss:0.40231 lr: 0.001125\n",
      "[3/541/109] iter:1192 accuracy:30.73 loss:0.47556 lr: 0.001125\n",
      "[3/541/119] iter:1202 accuracy:24.48 loss:0.50401 lr: 0.001125\n",
      "[3/541/129] iter:1212 accuracy:29.69 loss:0.51852 lr: 0.001125\n",
      "[3/541/139] iter:1222 accuracy:36.46 loss:0.57710 lr: 0.001125\n",
      "[3/541/149] iter:1232 accuracy:27.60 loss:0.37875 lr: 0.001125\n",
      "[3/541/159] iter:1242 accuracy:17.71 loss:0.42562 lr: 0.001125\n",
      "[3/541/169] iter:1252 accuracy:25.52 loss:0.43945 lr: 0.001125\n",
      "[3/541/179] iter:1262 accuracy:30.73 loss:0.51936 lr: 0.001125\n",
      "[3/541/189] iter:1272 accuracy:26.04 loss:0.42030 lr: 0.001125\n",
      "[3/541/199] iter:1282 accuracy:27.60 loss:0.39154 lr: 0.001125\n",
      "[3/541/209] iter:1292 accuracy:29.69 loss:0.41691 lr: 0.001125\n",
      "[3/541/219] iter:1302 accuracy:23.96 loss:0.38036 lr: 0.001125\n",
      "[3/541/229] iter:1312 accuracy:15.10 loss:0.43056 lr: 0.001125\n",
      "[3/541/239] iter:1322 accuracy:19.79 loss:0.35969 lr: 0.001125\n",
      "[3/541/249] iter:1332 accuracy:27.08 loss:0.44843 lr: 0.001125\n",
      "[3/541/259] iter:1342 accuracy:32.29 loss:0.45229 lr: 0.001125\n",
      "[3/541/269] iter:1352 accuracy:20.31 loss:0.47567 lr: 0.001125\n",
      "[3/541/279] iter:1362 accuracy:23.96 loss:0.45121 lr: 0.001125\n",
      "[3/541/289] iter:1372 accuracy:18.75 loss:0.35047 lr: 0.001125\n",
      "[3/541/299] iter:1382 accuracy:27.60 loss:0.46449 lr: 0.001125\n",
      "[3/541/309] iter:1392 accuracy:31.77 loss:0.44966 lr: 0.001125\n",
      "[3/541/319] iter:1402 accuracy:30.21 loss:0.46109 lr: 0.001125\n",
      "[3/541/329] iter:1412 accuracy:25.52 loss:0.36753 lr: 0.001125\n",
      "[3/541/339] iter:1422 accuracy:21.88 loss:0.55276 lr: 0.001125\n",
      "[3/541/349] iter:1432 accuracy:28.12 loss:0.42633 lr: 0.001125\n",
      "[3/541/359] iter:1442 accuracy:27.08 loss:0.36178 lr: 0.001125\n",
      "[3/541/369] iter:1452 accuracy:15.62 loss:0.40761 lr: 0.001125\n",
      "[3/541/379] iter:1462 accuracy:28.65 loss:0.43077 lr: 0.001125\n",
      "[3/541/389] iter:1472 accuracy:27.60 loss:0.44433 lr: 0.001125\n",
      "[3/541/399] iter:1482 accuracy:31.77 loss:0.50328 lr: 0.001125\n",
      "[3/541/409] iter:1492 accuracy:32.81 loss:0.37426 lr: 0.001125\n",
      "[3/541/419] iter:1502 accuracy:26.56 loss:0.44527 lr: 0.001125\n",
      "[3/541/429] iter:1512 accuracy:26.56 loss:0.43323 lr: 0.001125\n",
      "[3/541/439] iter:1522 accuracy:26.56 loss:0.45487 lr: 0.001125\n",
      "[3/541/449] iter:1532 accuracy:23.96 loss:0.41697 lr: 0.001125\n",
      "[3/541/459] iter:1542 accuracy:29.17 loss:0.40364 lr: 0.001125\n",
      "[3/541/469] iter:1552 accuracy:32.81 loss:0.42439 lr: 0.001125\n",
      "[3/541/479] iter:1562 accuracy:20.83 loss:0.42425 lr: 0.001125\n",
      "[3/541/489] iter:1572 accuracy:26.56 loss:0.40676 lr: 0.001125\n",
      "[3/541/499] iter:1582 accuracy:25.00 loss:0.30821 lr: 0.001125\n",
      "[3/541/509] iter:1592 accuracy:32.81 loss:0.47038 lr: 0.001125\n",
      "[3/541/519] iter:1602 accuracy:23.96 loss:0.47255 lr: 0.001125\n",
      "[3/541/529] iter:1612 accuracy:31.25 loss:0.44602 lr: 0.001125\n",
      "[3/541/539] iter:1622 accuracy:20.83 loss:0.39250 lr: 0.001125\n",
      "Epoch 3 of Valuation:\n",
      "[0] accuracy:21.875 loss:0.451\n",
      "[5] accuracy:31.771 loss:0.373\n",
      "[10] accuracy:39.583 loss:0.452\n",
      "[15] accuracy:24.479 loss:0.380\n",
      "[20] accuracy:28.125 loss:0.433\n",
      "[25] accuracy:28.125 loss:0.411\n",
      "[30] accuracy:28.125 loss:0.312\n",
      "[35] accuracy:21.354 loss:0.428\n",
      "[40] accuracy:31.771 loss:0.348\n",
      "[45] accuracy:26.042 loss:0.446\n",
      "[50] accuracy:22.917 loss:0.465\n",
      "[55] accuracy:25.521 loss:0.384\n",
      "[60] accuracy:22.917 loss:0.377\n",
      "[65] accuracy:25.000 loss:0.407\n",
      "[70] accuracy:19.792 loss:0.352\n",
      "[75] accuracy:23.958 loss:0.366\n",
      "Result\n",
      "Train accuracy:26.30, Train loss: 0.00671, Val accuracy:27.10, Val loss: 0.00634\n",
      "Patient 0\n",
      "Epoch 4 of Train:\n",
      "[4/541/9] iter:1633 accuracy:24.48 loss:0.50713 lr: 0.001500\n",
      "[4/541/19] iter:1643 accuracy:32.81 loss:0.37896 lr: 0.001500\n",
      "[4/541/29] iter:1653 accuracy:34.38 loss:0.44812 lr: 0.001500\n",
      "[4/541/39] iter:1663 accuracy:22.40 loss:0.38281 lr: 0.001500\n",
      "[4/541/49] iter:1673 accuracy:31.77 loss:0.41956 lr: 0.001500\n",
      "[4/541/59] iter:1683 accuracy:29.17 loss:0.51644 lr: 0.001500\n",
      "[4/541/69] iter:1693 accuracy:27.60 loss:0.48819 lr: 0.001500\n",
      "[4/541/79] iter:1703 accuracy:28.12 loss:0.47074 lr: 0.001500\n",
      "[4/541/89] iter:1713 accuracy:34.38 loss:0.48056 lr: 0.001500\n",
      "[4/541/99] iter:1723 accuracy:28.12 loss:0.35865 lr: 0.001500\n",
      "[4/541/109] iter:1733 accuracy:27.60 loss:0.38157 lr: 0.001500\n",
      "[4/541/119] iter:1743 accuracy:29.69 loss:0.37739 lr: 0.001500\n",
      "[4/541/129] iter:1753 accuracy:32.29 loss:0.43189 lr: 0.001500\n",
      "[4/541/139] iter:1763 accuracy:28.12 loss:0.43678 lr: 0.001500\n",
      "[4/541/149] iter:1773 accuracy:23.96 loss:0.40610 lr: 0.001500\n",
      "[4/541/159] iter:1783 accuracy:35.94 loss:0.38569 lr: 0.001500\n",
      "[4/541/169] iter:1793 accuracy:20.31 loss:0.40602 lr: 0.001500\n",
      "[4/541/179] iter:1803 accuracy:30.21 loss:0.41421 lr: 0.001500\n",
      "[4/541/189] iter:1813 accuracy:19.79 loss:0.39389 lr: 0.001500\n",
      "[4/541/199] iter:1823 accuracy:23.44 loss:0.40249 lr: 0.001500\n",
      "[4/541/209] iter:1833 accuracy:22.40 loss:0.35443 lr: 0.001500\n",
      "[4/541/219] iter:1843 accuracy:20.31 loss:0.35757 lr: 0.001500\n",
      "[4/541/229] iter:1853 accuracy:29.69 loss:0.45182 lr: 0.001500\n",
      "[4/541/239] iter:1863 accuracy:28.12 loss:0.38738 lr: 0.001500\n",
      "[4/541/249] iter:1873 accuracy:35.42 loss:0.46542 lr: 0.001500\n",
      "[4/541/259] iter:1883 accuracy:23.44 loss:0.37471 lr: 0.001500\n",
      "[4/541/269] iter:1893 accuracy:25.00 loss:0.36828 lr: 0.001500\n",
      "[4/541/279] iter:1903 accuracy:32.81 loss:0.39995 lr: 0.001500\n",
      "[4/541/289] iter:1913 accuracy:19.27 loss:0.41920 lr: 0.001500\n",
      "[4/541/299] iter:1923 accuracy:23.96 loss:0.39036 lr: 0.001500\n",
      "[4/541/309] iter:1933 accuracy:35.94 loss:0.30312 lr: 0.001500\n",
      "[4/541/319] iter:1943 accuracy:23.96 loss:0.35921 lr: 0.001500\n",
      "[4/541/329] iter:1953 accuracy:33.33 loss:0.38850 lr: 0.001500\n",
      "[4/541/339] iter:1963 accuracy:25.52 loss:0.52594 lr: 0.001500\n",
      "[4/541/349] iter:1973 accuracy:28.65 loss:0.40765 lr: 0.001500\n",
      "[4/541/359] iter:1983 accuracy:38.02 loss:0.41845 lr: 0.001500\n",
      "[4/541/369] iter:1993 accuracy:25.52 loss:0.47112 lr: 0.001500\n",
      "[4/541/379] iter:2003 accuracy:21.35 loss:0.40634 lr: 0.001500\n",
      "[4/541/389] iter:2013 accuracy:40.62 loss:0.54772 lr: 0.001500\n",
      "[4/541/399] iter:2023 accuracy:30.73 loss:0.33696 lr: 0.001500\n",
      "[4/541/409] iter:2033 accuracy:25.52 loss:0.33217 lr: 0.001500\n",
      "[4/541/419] iter:2043 accuracy:24.48 loss:0.33013 lr: 0.001500\n",
      "[4/541/429] iter:2053 accuracy:23.44 loss:0.43200 lr: 0.001500\n",
      "[4/541/439] iter:2063 accuracy:28.12 loss:0.36018 lr: 0.001500\n",
      "[4/541/449] iter:2073 accuracy:33.33 loss:0.41833 lr: 0.001500\n",
      "[4/541/459] iter:2083 accuracy:31.25 loss:0.33009 lr: 0.001500\n",
      "[4/541/469] iter:2093 accuracy:25.52 loss:0.43223 lr: 0.001500\n",
      "[4/541/479] iter:2103 accuracy:33.33 loss:0.37814 lr: 0.001500\n",
      "[4/541/489] iter:2113 accuracy:36.46 loss:0.36568 lr: 0.001500\n",
      "[4/541/499] iter:2123 accuracy:26.04 loss:0.41998 lr: 0.001500\n",
      "[4/541/509] iter:2133 accuracy:41.67 loss:0.43788 lr: 0.001500\n",
      "[4/541/519] iter:2143 accuracy:23.96 loss:0.38963 lr: 0.001500\n",
      "[4/541/529] iter:2153 accuracy:28.65 loss:0.37184 lr: 0.001500\n",
      "[4/541/539] iter:2163 accuracy:24.48 loss:0.37663 lr: 0.001500\n",
      "Epoch 4 of Valuation:\n",
      "[0] accuracy:20.833 loss:0.458\n",
      "[5] accuracy:30.729 loss:0.361\n",
      "[10] accuracy:43.229 loss:0.432\n",
      "[15] accuracy:23.438 loss:0.367\n",
      "[20] accuracy:30.729 loss:0.407\n",
      "[25] accuracy:25.521 loss:0.402\n",
      "[30] accuracy:31.771 loss:0.308\n",
      "[35] accuracy:19.792 loss:0.419\n",
      "[40] accuracy:33.854 loss:0.335\n",
      "[45] accuracy:25.521 loss:0.431\n",
      "[50] accuracy:28.646 loss:0.442\n",
      "[55] accuracy:26.042 loss:0.371\n",
      "[60] accuracy:28.125 loss:0.356\n",
      "[65] accuracy:29.688 loss:0.391\n",
      "[70] accuracy:23.438 loss:0.339\n",
      "[75] accuracy:25.000 loss:0.361\n",
      "Result\n",
      "Train accuracy:28.28, Train loss: 0.00639, Val accuracy:28.77, Val loss: 0.00616\n",
      "Patient 0\n",
      "Epoch 5 of Train:\n",
      "[5/541/9] iter:2174 accuracy:35.42 loss:0.42259 lr: 0.001500\n",
      "[5/541/19] iter:2184 accuracy:32.29 loss:0.37438 lr: 0.001500\n",
      "[5/541/29] iter:2194 accuracy:31.25 loss:0.38900 lr: 0.001500\n",
      "[5/541/39] iter:2204 accuracy:19.79 loss:0.35957 lr: 0.001500\n",
      "[5/541/49] iter:2214 accuracy:38.02 loss:0.40445 lr: 0.001500\n",
      "[5/541/59] iter:2224 accuracy:28.65 loss:0.46015 lr: 0.001500\n",
      "[5/541/69] iter:2234 accuracy:30.73 loss:0.36825 lr: 0.001500\n",
      "[5/541/79] iter:2244 accuracy:31.77 loss:0.38665 lr: 0.001500\n",
      "[5/541/89] iter:2254 accuracy:35.94 loss:0.38228 lr: 0.001500\n",
      "[5/541/99] iter:2264 accuracy:34.38 loss:0.39994 lr: 0.001500\n",
      "[5/541/109] iter:2274 accuracy:38.02 loss:0.41214 lr: 0.001500\n",
      "[5/541/119] iter:2284 accuracy:34.90 loss:0.35779 lr: 0.001500\n",
      "[5/541/129] iter:2294 accuracy:34.90 loss:0.34439 lr: 0.001500\n",
      "[5/541/139] iter:2304 accuracy:41.15 loss:0.37927 lr: 0.001500\n",
      "[5/541/149] iter:2314 accuracy:43.75 loss:0.42841 lr: 0.001500\n",
      "[5/541/159] iter:2324 accuracy:27.08 loss:0.33201 lr: 0.001500\n",
      "[5/541/169] iter:2334 accuracy:29.17 loss:0.38263 lr: 0.001500\n",
      "[5/541/179] iter:2344 accuracy:28.65 loss:0.36672 lr: 0.001500\n",
      "[5/541/189] iter:2354 accuracy:34.38 loss:0.44094 lr: 0.001500\n",
      "[5/541/199] iter:2364 accuracy:34.38 loss:0.47157 lr: 0.001500\n",
      "[5/541/209] iter:2374 accuracy:21.35 loss:0.39840 lr: 0.001500\n",
      "[5/541/219] iter:2384 accuracy:29.17 loss:0.35344 lr: 0.001500\n",
      "[5/541/229] iter:2394 accuracy:27.08 loss:0.43923 lr: 0.001500\n",
      "[5/541/239] iter:2404 accuracy:26.56 loss:0.38584 lr: 0.001500\n",
      "[5/541/249] iter:2414 accuracy:27.08 loss:0.31674 lr: 0.001500\n",
      "[5/541/259] iter:2424 accuracy:23.96 loss:0.30623 lr: 0.001500\n",
      "[5/541/269] iter:2434 accuracy:34.38 loss:0.45354 lr: 0.001500\n",
      "[5/541/279] iter:2444 accuracy:17.19 loss:0.37911 lr: 0.001500\n",
      "[5/541/289] iter:2454 accuracy:34.38 loss:0.36515 lr: 0.001500\n",
      "[5/541/299] iter:2464 accuracy:37.50 loss:0.49465 lr: 0.001500\n",
      "[5/541/309] iter:2474 accuracy:31.77 loss:0.36227 lr: 0.001500\n",
      "[5/541/319] iter:2484 accuracy:28.65 loss:0.48572 lr: 0.001500\n",
      "[5/541/329] iter:2494 accuracy:24.48 loss:0.36690 lr: 0.001500\n",
      "[5/541/339] iter:2504 accuracy:25.00 loss:0.42776 lr: 0.001500\n",
      "[5/541/349] iter:2514 accuracy:36.98 loss:0.38049 lr: 0.001500\n",
      "[5/541/359] iter:2524 accuracy:26.56 loss:0.45141 lr: 0.001500\n",
      "[5/541/369] iter:2534 accuracy:29.69 loss:0.34830 lr: 0.001500\n",
      "[5/541/379] iter:2544 accuracy:24.48 loss:0.35132 lr: 0.001500\n",
      "[5/541/389] iter:2554 accuracy:25.52 loss:0.35031 lr: 0.001500\n",
      "[5/541/399] iter:2564 accuracy:28.12 loss:0.33937 lr: 0.001500\n",
      "[5/541/409] iter:2574 accuracy:28.12 loss:0.39617 lr: 0.001500\n",
      "[5/541/419] iter:2584 accuracy:29.17 loss:0.42864 lr: 0.001500\n",
      "[5/541/429] iter:2594 accuracy:31.25 loss:0.44942 lr: 0.001500\n",
      "[5/541/439] iter:2604 accuracy:32.29 loss:0.26875 lr: 0.001500\n",
      "[5/541/449] iter:2614 accuracy:34.38 loss:0.38453 lr: 0.001500\n",
      "[5/541/459] iter:2624 accuracy:23.44 loss:0.40570 lr: 0.001500\n",
      "[5/541/469] iter:2634 accuracy:32.29 loss:0.38411 lr: 0.001500\n",
      "[5/541/479] iter:2644 accuracy:28.65 loss:0.43734 lr: 0.001500\n",
      "[5/541/489] iter:2654 accuracy:31.25 loss:0.34696 lr: 0.001500\n",
      "[5/541/499] iter:2664 accuracy:29.69 loss:0.38321 lr: 0.001500\n",
      "[5/541/509] iter:2674 accuracy:22.92 loss:0.41678 lr: 0.001500\n",
      "[5/541/519] iter:2684 accuracy:32.81 loss:0.45154 lr: 0.001500\n",
      "[5/541/529] iter:2694 accuracy:27.60 loss:0.32730 lr: 0.001500\n",
      "[5/541/539] iter:2704 accuracy:26.04 loss:0.35732 lr: 0.001500\n",
      "Epoch 5 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.445\n",
      "[5] accuracy:32.292 loss:0.344\n",
      "[10] accuracy:43.229 loss:0.417\n",
      "[15] accuracy:25.000 loss:0.354\n",
      "[20] accuracy:30.729 loss:0.402\n",
      "[25] accuracy:29.167 loss:0.403\n",
      "[30] accuracy:34.896 loss:0.296\n",
      "[35] accuracy:22.917 loss:0.411\n",
      "[40] accuracy:35.417 loss:0.306\n",
      "[45] accuracy:32.292 loss:0.427\n",
      "[50] accuracy:29.688 loss:0.449\n",
      "[55] accuracy:32.292 loss:0.373\n",
      "[60] accuracy:26.042 loss:0.347\n",
      "[65] accuracy:27.604 loss:0.393\n",
      "[70] accuracy:23.958 loss:0.334\n",
      "[75] accuracy:28.125 loss:0.336\n",
      "Result\n",
      "Train accuracy:29.72, Train loss: 0.00609, Val accuracy:29.61, Val loss: 0.00604\n",
      "Patient 0\n",
      "Epoch 6 of Train:\n",
      "[6/541/9] iter:2715 accuracy:25.00 loss:0.35763 lr: 0.001500\n",
      "[6/541/19] iter:2725 accuracy:20.83 loss:0.31562 lr: 0.001500\n",
      "[6/541/29] iter:2735 accuracy:34.38 loss:0.43117 lr: 0.001500\n",
      "[6/541/39] iter:2745 accuracy:25.52 loss:0.37860 lr: 0.001500\n",
      "[6/541/49] iter:2755 accuracy:24.48 loss:0.33979 lr: 0.001500\n",
      "[6/541/59] iter:2765 accuracy:30.21 loss:0.33958 lr: 0.001500\n",
      "[6/541/69] iter:2775 accuracy:28.65 loss:0.35165 lr: 0.001500\n",
      "[6/541/79] iter:2785 accuracy:16.15 loss:0.34483 lr: 0.001500\n",
      "[6/541/89] iter:2795 accuracy:38.54 loss:0.41062 lr: 0.001500\n",
      "[6/541/99] iter:2805 accuracy:38.54 loss:0.45582 lr: 0.001500\n",
      "[6/541/109] iter:2815 accuracy:32.81 loss:0.41285 lr: 0.001500\n",
      "[6/541/119] iter:2825 accuracy:43.23 loss:0.37043 lr: 0.001500\n",
      "[6/541/129] iter:2835 accuracy:32.81 loss:0.41188 lr: 0.001500\n",
      "[6/541/139] iter:2845 accuracy:26.04 loss:0.36611 lr: 0.001500\n",
      "[6/541/149] iter:2855 accuracy:29.17 loss:0.32764 lr: 0.001500\n",
      "[6/541/159] iter:2865 accuracy:31.77 loss:0.38557 lr: 0.001500\n",
      "[6/541/169] iter:2875 accuracy:34.90 loss:0.40287 lr: 0.001500\n",
      "[6/541/179] iter:2885 accuracy:33.33 loss:0.34149 lr: 0.001500\n",
      "[6/541/189] iter:2895 accuracy:30.21 loss:0.36070 lr: 0.001500\n",
      "[6/541/199] iter:2905 accuracy:26.56 loss:0.41395 lr: 0.001500\n",
      "[6/541/209] iter:2915 accuracy:25.00 loss:0.36908 lr: 0.001500\n",
      "[6/541/219] iter:2925 accuracy:33.33 loss:0.47395 lr: 0.001500\n",
      "[6/541/229] iter:2935 accuracy:33.33 loss:0.41228 lr: 0.001500\n",
      "[6/541/239] iter:2945 accuracy:28.65 loss:0.34769 lr: 0.001500\n",
      "[6/541/249] iter:2955 accuracy:31.25 loss:0.41047 lr: 0.001500\n",
      "[6/541/259] iter:2965 accuracy:31.25 loss:0.35438 lr: 0.001500\n",
      "[6/541/269] iter:2975 accuracy:22.40 loss:0.34290 lr: 0.001500\n",
      "[6/541/279] iter:2985 accuracy:25.00 loss:0.32906 lr: 0.001500\n",
      "[6/541/289] iter:2995 accuracy:28.12 loss:0.34433 lr: 0.001500\n",
      "[6/541/299] iter:3005 accuracy:35.94 loss:0.41123 lr: 0.001500\n",
      "[6/541/309] iter:3015 accuracy:30.73 loss:0.32392 lr: 0.001500\n",
      "[6/541/319] iter:3025 accuracy:30.21 loss:0.42300 lr: 0.001500\n",
      "[6/541/329] iter:3035 accuracy:24.48 loss:0.39184 lr: 0.001500\n",
      "[6/541/339] iter:3045 accuracy:24.48 loss:0.39709 lr: 0.001500\n",
      "[6/541/349] iter:3055 accuracy:30.73 loss:0.43921 lr: 0.001500\n",
      "[6/541/359] iter:3065 accuracy:38.02 loss:0.34211 lr: 0.001500\n",
      "[6/541/369] iter:3075 accuracy:35.42 loss:0.36319 lr: 0.001500\n",
      "[6/541/379] iter:3085 accuracy:32.81 loss:0.41986 lr: 0.001500\n",
      "[6/541/389] iter:3095 accuracy:36.98 loss:0.29751 lr: 0.001500\n",
      "[6/541/399] iter:3105 accuracy:32.29 loss:0.33286 lr: 0.001500\n",
      "[6/541/409] iter:3115 accuracy:34.90 loss:0.36130 lr: 0.001500\n",
      "[6/541/419] iter:3125 accuracy:38.02 loss:0.43456 lr: 0.001500\n",
      "[6/541/429] iter:3135 accuracy:35.42 loss:0.36665 lr: 0.001500\n",
      "[6/541/439] iter:3145 accuracy:27.60 loss:0.31673 lr: 0.001500\n",
      "[6/541/449] iter:3155 accuracy:32.29 loss:0.40540 lr: 0.001500\n",
      "[6/541/459] iter:3165 accuracy:33.33 loss:0.31221 lr: 0.001500\n",
      "[6/541/469] iter:3175 accuracy:35.42 loss:0.44167 lr: 0.001500\n",
      "[6/541/479] iter:3185 accuracy:36.98 loss:0.41684 lr: 0.001500\n",
      "[6/541/489] iter:3195 accuracy:39.58 loss:0.36097 lr: 0.001500\n",
      "[6/541/499] iter:3205 accuracy:31.25 loss:0.35276 lr: 0.001500\n",
      "[6/541/509] iter:3215 accuracy:36.46 loss:0.36944 lr: 0.001500\n",
      "[6/541/519] iter:3225 accuracy:36.46 loss:0.34534 lr: 0.001500\n",
      "[6/541/529] iter:3235 accuracy:40.62 loss:0.36053 lr: 0.001500\n",
      "[6/541/539] iter:3245 accuracy:28.12 loss:0.45952 lr: 0.001500\n",
      "Epoch 6 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.453\n",
      "[5] accuracy:38.542 loss:0.328\n",
      "[10] accuracy:46.354 loss:0.412\n",
      "[15] accuracy:28.125 loss:0.355\n",
      "[20] accuracy:33.333 loss:0.398\n",
      "[25] accuracy:31.771 loss:0.400\n",
      "[30] accuracy:33.333 loss:0.289\n",
      "[35] accuracy:20.833 loss:0.416\n",
      "[40] accuracy:35.938 loss:0.295\n",
      "[45] accuracy:29.167 loss:0.418\n",
      "[50] accuracy:34.375 loss:0.451\n",
      "[55] accuracy:31.771 loss:0.370\n",
      "[60] accuracy:31.771 loss:0.346\n",
      "[65] accuracy:32.292 loss:0.383\n",
      "[70] accuracy:23.438 loss:0.323\n",
      "[75] accuracy:27.604 loss:0.347\n",
      "Result\n",
      "Train accuracy:30.72, Train loss: 0.00586, Val accuracy:30.89, Val loss: 0.00595\n",
      "Patient 0\n",
      "Epoch 7 of Train:\n",
      "[7/541/9] iter:3256 accuracy:27.60 loss:0.43107 lr: 0.001500\n",
      "[7/541/19] iter:3266 accuracy:39.58 loss:0.44162 lr: 0.001500\n",
      "[7/541/29] iter:3276 accuracy:28.65 loss:0.37749 lr: 0.001500\n",
      "[7/541/39] iter:3286 accuracy:28.12 loss:0.34766 lr: 0.001500\n",
      "[7/541/49] iter:3296 accuracy:37.50 loss:0.33323 lr: 0.001500\n",
      "[7/541/59] iter:3306 accuracy:36.46 loss:0.40407 lr: 0.001500\n",
      "[7/541/69] iter:3316 accuracy:25.00 loss:0.32426 lr: 0.001500\n",
      "[7/541/79] iter:3326 accuracy:38.02 loss:0.28404 lr: 0.001500\n",
      "[7/541/89] iter:3336 accuracy:29.17 loss:0.31649 lr: 0.001500\n",
      "[7/541/99] iter:3346 accuracy:28.12 loss:0.37543 lr: 0.001500\n",
      "[7/541/109] iter:3356 accuracy:32.29 loss:0.33500 lr: 0.001500\n",
      "[7/541/119] iter:3366 accuracy:32.81 loss:0.34574 lr: 0.001500\n",
      "[7/541/129] iter:3376 accuracy:38.02 loss:0.35154 lr: 0.001500\n",
      "[7/541/139] iter:3386 accuracy:25.52 loss:0.33038 lr: 0.001500\n",
      "[7/541/149] iter:3396 accuracy:30.73 loss:0.34149 lr: 0.001500\n",
      "[7/541/159] iter:3406 accuracy:31.77 loss:0.31180 lr: 0.001500\n",
      "[7/541/169] iter:3416 accuracy:37.50 loss:0.38971 lr: 0.001500\n",
      "[7/541/179] iter:3426 accuracy:31.77 loss:0.37418 lr: 0.001500\n",
      "[7/541/189] iter:3436 accuracy:24.48 loss:0.39592 lr: 0.001500\n",
      "[7/541/199] iter:3446 accuracy:33.33 loss:0.33324 lr: 0.001500\n",
      "[7/541/209] iter:3456 accuracy:28.12 loss:0.39646 lr: 0.001500\n",
      "[7/541/219] iter:3466 accuracy:25.52 loss:0.27334 lr: 0.001500\n",
      "[7/541/229] iter:3476 accuracy:36.46 loss:0.38647 lr: 0.001500\n",
      "[7/541/239] iter:3486 accuracy:25.52 loss:0.36846 lr: 0.001500\n",
      "[7/541/249] iter:3496 accuracy:23.44 loss:0.41256 lr: 0.001500\n",
      "[7/541/259] iter:3506 accuracy:30.21 loss:0.47707 lr: 0.001500\n",
      "[7/541/269] iter:3516 accuracy:32.29 loss:0.39593 lr: 0.001500\n",
      "[7/541/279] iter:3526 accuracy:25.00 loss:0.34838 lr: 0.001500\n",
      "[7/541/289] iter:3536 accuracy:32.29 loss:0.41053 lr: 0.001500\n",
      "[7/541/299] iter:3546 accuracy:41.67 loss:0.34031 lr: 0.001500\n",
      "[7/541/309] iter:3556 accuracy:31.77 loss:0.39331 lr: 0.001500\n",
      "[7/541/319] iter:3566 accuracy:44.79 loss:0.46513 lr: 0.001500\n",
      "[7/541/329] iter:3576 accuracy:48.96 loss:0.37762 lr: 0.001500\n",
      "[7/541/339] iter:3586 accuracy:27.60 loss:0.36162 lr: 0.001500\n",
      "[7/541/349] iter:3596 accuracy:36.98 loss:0.28991 lr: 0.001500\n",
      "[7/541/359] iter:3606 accuracy:36.46 loss:0.46134 lr: 0.001500\n",
      "[7/541/369] iter:3616 accuracy:36.98 loss:0.33198 lr: 0.001500\n",
      "[7/541/379] iter:3626 accuracy:33.33 loss:0.42111 lr: 0.001500\n",
      "[7/541/389] iter:3636 accuracy:28.12 loss:0.38180 lr: 0.001500\n",
      "[7/541/399] iter:3646 accuracy:24.48 loss:0.37796 lr: 0.001500\n",
      "[7/541/409] iter:3656 accuracy:36.46 loss:0.38353 lr: 0.001500\n",
      "[7/541/419] iter:3666 accuracy:32.29 loss:0.31824 lr: 0.001500\n",
      "[7/541/429] iter:3676 accuracy:38.54 loss:0.41616 lr: 0.001500\n",
      "[7/541/439] iter:3686 accuracy:33.33 loss:0.36076 lr: 0.001500\n",
      "[7/541/449] iter:3696 accuracy:30.73 loss:0.35141 lr: 0.001500\n",
      "[7/541/459] iter:3706 accuracy:23.44 loss:0.37932 lr: 0.001500\n",
      "[7/541/469] iter:3716 accuracy:30.21 loss:0.32500 lr: 0.001500\n",
      "[7/541/479] iter:3726 accuracy:29.17 loss:0.35898 lr: 0.001500\n",
      "[7/541/489] iter:3736 accuracy:29.17 loss:0.41135 lr: 0.001500\n",
      "[7/541/499] iter:3746 accuracy:31.77 loss:0.38998 lr: 0.001500\n",
      "[7/541/509] iter:3756 accuracy:32.81 loss:0.32138 lr: 0.001500\n",
      "[7/541/519] iter:3766 accuracy:26.04 loss:0.33180 lr: 0.001500\n",
      "[7/541/529] iter:3776 accuracy:32.29 loss:0.39910 lr: 0.001500\n",
      "[7/541/539] iter:3786 accuracy:23.96 loss:0.34608 lr: 0.001500\n",
      "Epoch 7 of Valuation:\n",
      "[0] accuracy:25.000 loss:0.446\n",
      "[5] accuracy:39.063 loss:0.320\n",
      "[10] accuracy:46.875 loss:0.419\n",
      "[15] accuracy:23.958 loss:0.359\n",
      "[20] accuracy:31.250 loss:0.394\n",
      "[25] accuracy:30.729 loss:0.399\n",
      "[30] accuracy:43.229 loss:0.271\n",
      "[35] accuracy:24.479 loss:0.415\n",
      "[40] accuracy:35.417 loss:0.293\n",
      "[45] accuracy:31.250 loss:0.431\n",
      "[50] accuracy:33.333 loss:0.453\n",
      "[55] accuracy:32.812 loss:0.365\n",
      "[60] accuracy:28.125 loss:0.347\n",
      "[65] accuracy:31.250 loss:0.387\n",
      "[70] accuracy:20.312 loss:0.342\n",
      "[75] accuracy:26.562 loss:0.357\n",
      "Result\n",
      "Train accuracy:32.06, Train loss: 0.00566, Val accuracy:31.26, Val loss: 0.00594\n",
      "Patient 0\n",
      "Epoch 8 of Train:\n",
      "[8/541/9] iter:3797 accuracy:33.33 loss:0.37213 lr: 0.001500\n",
      "[8/541/19] iter:3807 accuracy:31.25 loss:0.31975 lr: 0.001500\n",
      "[8/541/29] iter:3817 accuracy:31.77 loss:0.34362 lr: 0.001500\n",
      "[8/541/39] iter:3827 accuracy:35.42 loss:0.33546 lr: 0.001500\n",
      "[8/541/49] iter:3837 accuracy:27.08 loss:0.36651 lr: 0.001500\n",
      "[8/541/59] iter:3847 accuracy:31.77 loss:0.28914 lr: 0.001500\n",
      "[8/541/69] iter:3857 accuracy:33.33 loss:0.40069 lr: 0.001500\n",
      "[8/541/79] iter:3867 accuracy:34.38 loss:0.31798 lr: 0.001500\n",
      "[8/541/89] iter:3877 accuracy:30.73 loss:0.37369 lr: 0.001500\n",
      "[8/541/99] iter:3887 accuracy:28.12 loss:0.35524 lr: 0.001500\n",
      "[8/541/109] iter:3897 accuracy:36.46 loss:0.29882 lr: 0.001500\n",
      "[8/541/119] iter:3907 accuracy:36.46 loss:0.34257 lr: 0.001500\n",
      "[8/541/129] iter:3917 accuracy:38.02 loss:0.28101 lr: 0.001500\n",
      "[8/541/139] iter:3927 accuracy:34.90 loss:0.28998 lr: 0.001500\n",
      "[8/541/149] iter:3937 accuracy:23.44 loss:0.35601 lr: 0.001500\n",
      "[8/541/159] iter:3947 accuracy:38.54 loss:0.34489 lr: 0.001500\n",
      "[8/541/169] iter:3957 accuracy:21.88 loss:0.30811 lr: 0.001500\n",
      "[8/541/179] iter:3967 accuracy:34.38 loss:0.34581 lr: 0.001500\n",
      "[8/541/189] iter:3977 accuracy:19.79 loss:0.36067 lr: 0.001500\n",
      "[8/541/199] iter:3987 accuracy:19.79 loss:0.31015 lr: 0.001500\n",
      "[8/541/209] iter:3997 accuracy:35.42 loss:0.30738 lr: 0.001500\n",
      "[8/541/219] iter:4007 accuracy:38.54 loss:0.33186 lr: 0.001500\n",
      "[8/541/229] iter:4017 accuracy:31.77 loss:0.39990 lr: 0.001500\n",
      "[8/541/239] iter:4027 accuracy:26.56 loss:0.37607 lr: 0.001500\n",
      "[8/541/249] iter:4037 accuracy:25.00 loss:0.36298 lr: 0.001500\n",
      "[8/541/259] iter:4047 accuracy:32.29 loss:0.32045 lr: 0.001500\n",
      "[8/541/269] iter:4057 accuracy:39.58 loss:0.41122 lr: 0.001500\n",
      "[8/541/279] iter:4067 accuracy:34.38 loss:0.33875 lr: 0.001500\n",
      "[8/541/289] iter:4077 accuracy:39.06 loss:0.32312 lr: 0.001500\n",
      "[8/541/299] iter:4087 accuracy:35.42 loss:0.42005 lr: 0.001500\n",
      "[8/541/309] iter:4097 accuracy:29.69 loss:0.37822 lr: 0.001500\n",
      "[8/541/319] iter:4107 accuracy:37.50 loss:0.41362 lr: 0.001500\n",
      "[8/541/329] iter:4117 accuracy:27.60 loss:0.39800 lr: 0.001500\n",
      "[8/541/339] iter:4127 accuracy:32.81 loss:0.37437 lr: 0.001500\n",
      "[8/541/349] iter:4137 accuracy:30.21 loss:0.32409 lr: 0.001500\n",
      "[8/541/359] iter:4147 accuracy:30.21 loss:0.33894 lr: 0.001500\n",
      "[8/541/369] iter:4157 accuracy:36.46 loss:0.32660 lr: 0.001500\n",
      "[8/541/379] iter:4167 accuracy:43.23 loss:0.36405 lr: 0.001500\n",
      "[8/541/389] iter:4177 accuracy:30.73 loss:0.31341 lr: 0.001500\n",
      "[8/541/399] iter:4187 accuracy:27.60 loss:0.33117 lr: 0.001500\n",
      "[8/541/409] iter:4197 accuracy:36.46 loss:0.35234 lr: 0.001500\n",
      "[8/541/419] iter:4207 accuracy:14.58 loss:0.40818 lr: 0.001500\n",
      "[8/541/429] iter:4217 accuracy:35.94 loss:0.27542 lr: 0.001500\n",
      "[8/541/439] iter:4227 accuracy:36.46 loss:0.47659 lr: 0.001500\n",
      "[8/541/449] iter:4237 accuracy:39.58 loss:0.35198 lr: 0.001500\n",
      "[8/541/459] iter:4247 accuracy:31.25 loss:0.33623 lr: 0.001500\n",
      "[8/541/469] iter:4257 accuracy:31.25 loss:0.29520 lr: 0.001500\n",
      "[8/541/479] iter:4267 accuracy:35.42 loss:0.33790 lr: 0.001500\n",
      "[8/541/489] iter:4277 accuracy:23.44 loss:0.31281 lr: 0.001500\n",
      "[8/541/499] iter:4287 accuracy:28.65 loss:0.37147 lr: 0.001500\n",
      "[8/541/509] iter:4297 accuracy:29.17 loss:0.34341 lr: 0.001500\n",
      "[8/541/519] iter:4307 accuracy:36.98 loss:0.36478 lr: 0.001500\n",
      "[8/541/529] iter:4317 accuracy:34.38 loss:0.35865 lr: 0.001500\n",
      "[8/541/539] iter:4327 accuracy:34.38 loss:0.37633 lr: 0.001500\n",
      "Epoch 8 of Valuation:\n",
      "[0] accuracy:22.917 loss:0.453\n",
      "[5] accuracy:41.667 loss:0.310\n",
      "[10] accuracy:46.354 loss:0.401\n",
      "[15] accuracy:25.000 loss:0.344\n",
      "[20] accuracy:38.021 loss:0.371\n",
      "[25] accuracy:30.208 loss:0.385\n",
      "[30] accuracy:38.021 loss:0.280\n",
      "[35] accuracy:22.917 loss:0.413\n",
      "[40] accuracy:36.979 loss:0.298\n",
      "[45] accuracy:30.729 loss:0.410\n",
      "[50] accuracy:31.771 loss:0.433\n",
      "[55] accuracy:30.208 loss:0.349\n",
      "[60] accuracy:30.729 loss:0.329\n",
      "[65] accuracy:30.729 loss:0.371\n",
      "[70] accuracy:23.958 loss:0.327\n",
      "[75] accuracy:23.958 loss:0.356\n",
      "Result\n",
      "Train accuracy:32.93, Train loss: 0.00548, Val accuracy:31.08, Val loss: 0.00584\n",
      "Patient 1\n",
      "Epoch 9 of Train:\n",
      "[9/541/9] iter:4338 accuracy:37.50 loss:0.34647 lr: 0.001500\n",
      "[9/541/19] iter:4348 accuracy:38.54 loss:0.35736 lr: 0.001500\n",
      "[9/541/29] iter:4358 accuracy:31.77 loss:0.36340 lr: 0.001500\n",
      "[9/541/39] iter:4368 accuracy:38.02 loss:0.34122 lr: 0.001500\n",
      "[9/541/49] iter:4378 accuracy:40.62 loss:0.34336 lr: 0.001500\n",
      "[9/541/59] iter:4388 accuracy:39.58 loss:0.35400 lr: 0.001500\n",
      "[9/541/69] iter:4398 accuracy:31.25 loss:0.38071 lr: 0.001500\n",
      "[9/541/79] iter:4408 accuracy:32.29 loss:0.34017 lr: 0.001500\n",
      "[9/541/89] iter:4418 accuracy:35.94 loss:0.37060 lr: 0.001500\n",
      "[9/541/99] iter:4428 accuracy:27.60 loss:0.26620 lr: 0.001500\n",
      "[9/541/109] iter:4438 accuracy:40.62 loss:0.29839 lr: 0.001500\n",
      "[9/541/119] iter:4448 accuracy:33.33 loss:0.41487 lr: 0.001500\n",
      "[9/541/129] iter:4458 accuracy:29.69 loss:0.34998 lr: 0.001500\n",
      "[9/541/139] iter:4468 accuracy:40.10 loss:0.32894 lr: 0.001500\n",
      "[9/541/149] iter:4478 accuracy:45.31 loss:0.37951 lr: 0.001500\n",
      "[9/541/159] iter:4488 accuracy:38.02 loss:0.31631 lr: 0.001500\n",
      "[9/541/169] iter:4498 accuracy:23.96 loss:0.33545 lr: 0.001500\n",
      "[9/541/179] iter:4508 accuracy:29.69 loss:0.31627 lr: 0.001500\n",
      "[9/541/189] iter:4518 accuracy:42.19 loss:0.38721 lr: 0.001500\n",
      "[9/541/199] iter:4528 accuracy:39.06 loss:0.30824 lr: 0.001500\n",
      "[9/541/209] iter:4538 accuracy:25.00 loss:0.27092 lr: 0.001500\n",
      "[9/541/219] iter:4548 accuracy:36.46 loss:0.35371 lr: 0.001500\n",
      "[9/541/229] iter:4558 accuracy:24.48 loss:0.32489 lr: 0.001500\n",
      "[9/541/239] iter:4568 accuracy:33.85 loss:0.40727 lr: 0.001500\n",
      "[9/541/249] iter:4578 accuracy:31.77 loss:0.30092 lr: 0.001500\n",
      "[9/541/259] iter:4588 accuracy:40.10 loss:0.30886 lr: 0.001500\n",
      "[9/541/269] iter:4598 accuracy:38.54 loss:0.33509 lr: 0.001500\n",
      "[9/541/279] iter:4608 accuracy:33.33 loss:0.34725 lr: 0.001500\n",
      "[9/541/289] iter:4618 accuracy:33.33 loss:0.32096 lr: 0.001500\n",
      "[9/541/299] iter:4628 accuracy:36.46 loss:0.34040 lr: 0.001500\n",
      "[9/541/309] iter:4638 accuracy:29.69 loss:0.32768 lr: 0.001500\n",
      "[9/541/319] iter:4648 accuracy:36.46 loss:0.26740 lr: 0.001500\n",
      "[9/541/329] iter:4658 accuracy:35.42 loss:0.39633 lr: 0.001500\n",
      "[9/541/339] iter:4668 accuracy:26.56 loss:0.29609 lr: 0.001500\n",
      "[9/541/349] iter:4678 accuracy:31.25 loss:0.31778 lr: 0.001500\n",
      "[9/541/359] iter:4688 accuracy:29.17 loss:0.36902 lr: 0.001500\n",
      "[9/541/369] iter:4698 accuracy:33.33 loss:0.35874 lr: 0.001500\n",
      "[9/541/379] iter:4708 accuracy:33.33 loss:0.30246 lr: 0.001500\n",
      "[9/541/389] iter:4718 accuracy:35.94 loss:0.35559 lr: 0.001500\n",
      "[9/541/399] iter:4728 accuracy:27.08 loss:0.28840 lr: 0.001500\n",
      "[9/541/409] iter:4738 accuracy:39.06 loss:0.27203 lr: 0.001500\n",
      "[9/541/419] iter:4748 accuracy:42.19 loss:0.35657 lr: 0.001500\n",
      "[9/541/429] iter:4758 accuracy:27.08 loss:0.34984 lr: 0.001500\n",
      "[9/541/439] iter:4768 accuracy:29.17 loss:0.36052 lr: 0.001500\n",
      "[9/541/449] iter:4778 accuracy:28.65 loss:0.27000 lr: 0.001500\n",
      "[9/541/459] iter:4788 accuracy:33.85 loss:0.33640 lr: 0.001500\n",
      "[9/541/469] iter:4798 accuracy:40.10 loss:0.32792 lr: 0.001500\n",
      "[9/541/479] iter:4808 accuracy:35.42 loss:0.32789 lr: 0.001500\n",
      "[9/541/489] iter:4818 accuracy:25.52 loss:0.38138 lr: 0.001500\n",
      "[9/541/499] iter:4828 accuracy:38.02 loss:0.33026 lr: 0.001500\n",
      "[9/541/509] iter:4838 accuracy:34.38 loss:0.30511 lr: 0.001500\n",
      "[9/541/519] iter:4848 accuracy:41.15 loss:0.30805 lr: 0.001500\n",
      "[9/541/529] iter:4858 accuracy:39.06 loss:0.40828 lr: 0.001500\n",
      "[9/541/539] iter:4868 accuracy:45.31 loss:0.31965 lr: 0.001500\n",
      "Epoch 9 of Valuation:\n",
      "[0] accuracy:23.438 loss:0.459\n",
      "[5] accuracy:34.375 loss:0.312\n",
      "[10] accuracy:42.188 loss:0.420\n",
      "[15] accuracy:24.479 loss:0.346\n",
      "[20] accuracy:38.542 loss:0.385\n",
      "[25] accuracy:33.333 loss:0.394\n",
      "[30] accuracy:35.938 loss:0.278\n",
      "[35] accuracy:23.438 loss:0.413\n",
      "[40] accuracy:36.979 loss:0.296\n",
      "[45] accuracy:32.812 loss:0.428\n",
      "[50] accuracy:32.292 loss:0.467\n",
      "[55] accuracy:34.375 loss:0.357\n",
      "[60] accuracy:28.125 loss:0.343\n",
      "[65] accuracy:32.292 loss:0.397\n",
      "[70] accuracy:23.438 loss:0.335\n",
      "[75] accuracy:25.521 loss:0.358\n",
      "Result\n",
      "Train accuracy:33.73, Train loss: 0.00531, Val accuracy:31.19, Val loss: 0.00592\n",
      "Patient 2\n",
      "Epoch 10 of Train:\n",
      "[10/541/9] iter:4879 accuracy:36.98 loss:0.28784 lr: 0.001500\n",
      "[10/541/19] iter:4889 accuracy:32.29 loss:0.30395 lr: 0.001500\n",
      "[10/541/29] iter:4899 accuracy:31.77 loss:0.31050 lr: 0.001500\n",
      "[10/541/39] iter:4909 accuracy:35.42 loss:0.42291 lr: 0.001500\n",
      "[10/541/49] iter:4919 accuracy:31.77 loss:0.30833 lr: 0.001500\n",
      "[10/541/59] iter:4929 accuracy:25.52 loss:0.24942 lr: 0.001500\n",
      "[10/541/69] iter:4939 accuracy:41.15 loss:0.33393 lr: 0.001500\n",
      "[10/541/79] iter:4949 accuracy:24.48 loss:0.36003 lr: 0.001500\n",
      "[10/541/89] iter:4959 accuracy:28.12 loss:0.36764 lr: 0.001500\n",
      "[10/541/99] iter:4969 accuracy:38.02 loss:0.30668 lr: 0.001500\n",
      "[10/541/109] iter:4979 accuracy:42.71 loss:0.29818 lr: 0.001500\n",
      "[10/541/119] iter:4989 accuracy:38.02 loss:0.34849 lr: 0.001500\n",
      "[10/541/129] iter:4999 accuracy:34.90 loss:0.26721 lr: 0.001500\n",
      "[10/541/139] iter:5009 accuracy:40.62 loss:0.31476 lr: 0.001500\n",
      "[10/541/149] iter:5019 accuracy:34.90 loss:0.26948 lr: 0.001500\n",
      "[10/541/159] iter:5029 accuracy:41.15 loss:0.29533 lr: 0.001500\n",
      "[10/541/169] iter:5039 accuracy:34.38 loss:0.33695 lr: 0.001500\n",
      "[10/541/179] iter:5049 accuracy:33.33 loss:0.28870 lr: 0.001500\n",
      "[10/541/189] iter:5059 accuracy:32.29 loss:0.37333 lr: 0.001500\n",
      "[10/541/199] iter:5069 accuracy:41.15 loss:0.32790 lr: 0.001500\n",
      "[10/541/209] iter:5079 accuracy:33.33 loss:0.34465 lr: 0.001500\n",
      "[10/541/219] iter:5089 accuracy:33.33 loss:0.32495 lr: 0.001500\n",
      "[10/541/229] iter:5099 accuracy:29.17 loss:0.31184 lr: 0.001500\n",
      "[10/541/239] iter:5109 accuracy:29.17 loss:0.28649 lr: 0.001500\n",
      "[10/541/249] iter:5119 accuracy:32.29 loss:0.33782 lr: 0.001500\n",
      "[10/541/259] iter:5129 accuracy:35.42 loss:0.29449 lr: 0.001500\n",
      "[10/541/269] iter:5139 accuracy:42.19 loss:0.31089 lr: 0.001500\n",
      "[10/541/279] iter:5149 accuracy:28.12 loss:0.34314 lr: 0.001500\n",
      "[10/541/289] iter:5159 accuracy:30.21 loss:0.31788 lr: 0.001500\n",
      "[10/541/299] iter:5169 accuracy:33.85 loss:0.28232 lr: 0.001500\n",
      "[10/541/309] iter:5179 accuracy:22.92 loss:0.33555 lr: 0.001500\n",
      "[10/541/319] iter:5189 accuracy:32.29 loss:0.31332 lr: 0.001500\n",
      "[10/541/329] iter:5199 accuracy:28.65 loss:0.35416 lr: 0.001500\n",
      "[10/541/339] iter:5209 accuracy:44.27 loss:0.36617 lr: 0.001500\n",
      "[10/541/349] iter:5219 accuracy:39.06 loss:0.26500 lr: 0.001500\n",
      "[10/541/359] iter:5229 accuracy:35.42 loss:0.34785 lr: 0.001500\n",
      "[10/541/369] iter:5239 accuracy:35.94 loss:0.32012 lr: 0.001500\n",
      "[10/541/379] iter:5249 accuracy:32.81 loss:0.33695 lr: 0.001500\n",
      "[10/541/389] iter:5259 accuracy:40.62 loss:0.32795 lr: 0.001500\n",
      "[10/541/399] iter:5269 accuracy:34.90 loss:0.30680 lr: 0.001500\n",
      "[10/541/409] iter:5279 accuracy:30.73 loss:0.26149 lr: 0.001500\n",
      "[10/541/419] iter:5289 accuracy:42.19 loss:0.34155 lr: 0.001500\n",
      "[10/541/429] iter:5299 accuracy:37.50 loss:0.32892 lr: 0.001500\n",
      "[10/541/439] iter:5309 accuracy:28.65 loss:0.44049 lr: 0.001500\n",
      "[10/541/449] iter:5319 accuracy:30.73 loss:0.29799 lr: 0.001500\n",
      "[10/541/459] iter:5329 accuracy:36.46 loss:0.27663 lr: 0.001500\n",
      "[10/541/469] iter:5339 accuracy:31.25 loss:0.27348 lr: 0.001500\n",
      "[10/541/479] iter:5349 accuracy:30.21 loss:0.31331 lr: 0.001500\n",
      "[10/541/489] iter:5359 accuracy:36.98 loss:0.28584 lr: 0.001500\n",
      "[10/541/499] iter:5369 accuracy:30.73 loss:0.35907 lr: 0.001500\n",
      "[10/541/509] iter:5379 accuracy:34.90 loss:0.32833 lr: 0.001500\n",
      "[10/541/519] iter:5389 accuracy:29.17 loss:0.24855 lr: 0.001500\n",
      "[10/541/529] iter:5399 accuracy:35.94 loss:0.31833 lr: 0.001500\n",
      "[10/541/539] iter:5409 accuracy:32.81 loss:0.36774 lr: 0.001500\n",
      "Epoch 10 of Valuation:\n",
      "[0] accuracy:27.083 loss:0.453\n",
      "[5] accuracy:43.229 loss:0.301\n",
      "[10] accuracy:43.229 loss:0.422\n",
      "[15] accuracy:22.396 loss:0.359\n",
      "[20] accuracy:28.646 loss:0.385\n",
      "[25] accuracy:31.771 loss:0.406\n",
      "[30] accuracy:40.625 loss:0.274\n",
      "[35] accuracy:26.562 loss:0.409\n",
      "[40] accuracy:32.812 loss:0.298\n",
      "[45] accuracy:32.292 loss:0.406\n",
      "[50] accuracy:34.896 loss:0.451\n",
      "[55] accuracy:31.250 loss:0.351\n",
      "[60] accuracy:28.125 loss:0.345\n",
      "[65] accuracy:30.208 loss:0.382\n",
      "[70] accuracy:21.354 loss:0.329\n",
      "[75] accuracy:25.521 loss:0.358\n",
      "Result\n",
      "Train accuracy:34.70, Train loss: 0.00515, Val accuracy:32.07, Val loss: 0.00585\n",
      "Patient 0\n",
      "Epoch 11 of Train:\n",
      "[11/541/9] iter:5420 accuracy:40.10 loss:0.31188 lr: 0.001500\n",
      "[11/541/19] iter:5430 accuracy:36.98 loss:0.25301 lr: 0.001500\n",
      "[11/541/29] iter:5440 accuracy:32.81 loss:0.28545 lr: 0.001500\n",
      "[11/541/39] iter:5450 accuracy:31.77 loss:0.38265 lr: 0.001500\n",
      "[11/541/49] iter:5460 accuracy:30.73 loss:0.26876 lr: 0.001500\n",
      "[11/541/59] iter:5470 accuracy:39.06 loss:0.37333 lr: 0.001500\n",
      "[11/541/69] iter:5480 accuracy:30.21 loss:0.36434 lr: 0.001500\n",
      "[11/541/79] iter:5490 accuracy:31.25 loss:0.31437 lr: 0.001500\n",
      "[11/541/89] iter:5500 accuracy:42.71 loss:0.28948 lr: 0.001500\n",
      "[11/541/99] iter:5510 accuracy:35.42 loss:0.29659 lr: 0.001500\n",
      "[11/541/109] iter:5520 accuracy:39.06 loss:0.32763 lr: 0.001500\n",
      "[11/541/119] iter:5530 accuracy:45.31 loss:0.25508 lr: 0.001500\n",
      "[11/541/129] iter:5540 accuracy:34.38 loss:0.26644 lr: 0.001500\n",
      "[11/541/139] iter:5550 accuracy:48.44 loss:0.32473 lr: 0.001500\n",
      "[11/541/149] iter:5560 accuracy:35.42 loss:0.29470 lr: 0.001500\n",
      "[11/541/159] iter:5570 accuracy:30.73 loss:0.37442 lr: 0.001500\n",
      "[11/541/169] iter:5580 accuracy:41.67 loss:0.24586 lr: 0.001500\n",
      "[11/541/179] iter:5590 accuracy:32.29 loss:0.30548 lr: 0.001500\n",
      "[11/541/189] iter:5600 accuracy:38.54 loss:0.33246 lr: 0.001500\n",
      "[11/541/199] iter:5610 accuracy:45.83 loss:0.39450 lr: 0.001500\n",
      "[11/541/209] iter:5620 accuracy:53.12 loss:0.31538 lr: 0.001500\n",
      "[11/541/219] iter:5630 accuracy:36.98 loss:0.39655 lr: 0.001500\n",
      "[11/541/229] iter:5640 accuracy:45.83 loss:0.27798 lr: 0.001500\n",
      "[11/541/239] iter:5650 accuracy:40.62 loss:0.37792 lr: 0.001500\n",
      "[11/541/249] iter:5660 accuracy:35.94 loss:0.38334 lr: 0.001500\n",
      "[11/541/259] iter:5670 accuracy:36.98 loss:0.37012 lr: 0.001500\n",
      "[11/541/269] iter:5680 accuracy:32.29 loss:0.33560 lr: 0.001500\n",
      "[11/541/279] iter:5690 accuracy:35.94 loss:0.31612 lr: 0.001500\n",
      "[11/541/289] iter:5700 accuracy:36.46 loss:0.29583 lr: 0.001500\n",
      "[11/541/299] iter:5710 accuracy:39.06 loss:0.37010 lr: 0.001500\n",
      "[11/541/309] iter:5720 accuracy:27.60 loss:0.30237 lr: 0.001500\n",
      "[11/541/319] iter:5730 accuracy:22.40 loss:0.33342 lr: 0.001500\n",
      "[11/541/329] iter:5740 accuracy:34.90 loss:0.31493 lr: 0.001500\n",
      "[11/541/339] iter:5750 accuracy:34.38 loss:0.30611 lr: 0.001500\n",
      "[11/541/349] iter:5760 accuracy:39.06 loss:0.32629 lr: 0.001500\n",
      "[11/541/359] iter:5770 accuracy:34.90 loss:0.31419 lr: 0.001500\n",
      "[11/541/369] iter:5780 accuracy:34.38 loss:0.29344 lr: 0.001500\n",
      "[11/541/379] iter:5790 accuracy:39.06 loss:0.29159 lr: 0.001500\n",
      "[11/541/389] iter:5800 accuracy:27.60 loss:0.32437 lr: 0.001500\n",
      "[11/541/399] iter:5810 accuracy:27.08 loss:0.29255 lr: 0.001500\n",
      "[11/541/409] iter:5820 accuracy:44.79 loss:0.28622 lr: 0.001500\n",
      "[11/541/419] iter:5830 accuracy:32.29 loss:0.30042 lr: 0.001500\n",
      "[11/541/429] iter:5840 accuracy:33.33 loss:0.30605 lr: 0.001500\n",
      "[11/541/439] iter:5850 accuracy:27.60 loss:0.28299 lr: 0.001500\n",
      "[11/541/449] iter:5860 accuracy:35.94 loss:0.27100 lr: 0.001500\n",
      "[11/541/459] iter:5870 accuracy:29.17 loss:0.29137 lr: 0.001500\n",
      "[11/541/469] iter:5880 accuracy:35.42 loss:0.29087 lr: 0.001500\n",
      "[11/541/479] iter:5890 accuracy:29.69 loss:0.32751 lr: 0.001500\n",
      "[11/541/489] iter:5900 accuracy:29.69 loss:0.30482 lr: 0.001500\n",
      "[11/541/499] iter:5910 accuracy:37.50 loss:0.30232 lr: 0.001500\n",
      "[11/541/509] iter:5920 accuracy:36.98 loss:0.30129 lr: 0.001500\n",
      "[11/541/519] iter:5930 accuracy:33.33 loss:0.31056 lr: 0.001500\n",
      "[11/541/529] iter:5940 accuracy:31.77 loss:0.27986 lr: 0.001500\n",
      "[11/541/539] iter:5950 accuracy:37.50 loss:0.30544 lr: 0.001500\n",
      "Epoch 11 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.454\n",
      "[5] accuracy:41.146 loss:0.307\n",
      "[10] accuracy:43.229 loss:0.431\n",
      "[15] accuracy:24.479 loss:0.354\n",
      "[20] accuracy:27.604 loss:0.367\n",
      "[25] accuracy:33.333 loss:0.405\n",
      "[30] accuracy:34.896 loss:0.276\n",
      "[35] accuracy:25.000 loss:0.408\n",
      "[40] accuracy:38.542 loss:0.283\n",
      "[45] accuracy:41.667 loss:0.413\n",
      "[50] accuracy:34.375 loss:0.458\n",
      "[55] accuracy:34.375 loss:0.357\n",
      "[60] accuracy:30.729 loss:0.345\n",
      "[65] accuracy:30.208 loss:0.398\n",
      "[70] accuracy:24.479 loss:0.333\n",
      "[75] accuracy:24.479 loss:0.341\n",
      "Result\n",
      "Train accuracy:35.22, Train loss: 0.00498, Val accuracy:32.06, Val loss: 0.00589\n",
      "Patient 1\n",
      "Epoch 12 of Train:\n",
      "[12/541/9] iter:5961 accuracy:30.21 loss:0.26063 lr: 0.001500\n",
      "[12/541/19] iter:5971 accuracy:38.02 loss:0.24128 lr: 0.001500\n",
      "[12/541/29] iter:5981 accuracy:25.00 loss:0.30998 lr: 0.001500\n",
      "[12/541/39] iter:5991 accuracy:39.58 loss:0.33985 lr: 0.001500\n",
      "[12/541/49] iter:6001 accuracy:40.62 loss:0.25927 lr: 0.001500\n",
      "[12/541/59] iter:6011 accuracy:41.15 loss:0.29178 lr: 0.001500\n",
      "[12/541/69] iter:6021 accuracy:28.65 loss:0.26677 lr: 0.001500\n",
      "[12/541/79] iter:6031 accuracy:25.00 loss:0.33859 lr: 0.001500\n",
      "[12/541/89] iter:6041 accuracy:49.48 loss:0.23584 lr: 0.001500\n",
      "[12/541/99] iter:6051 accuracy:36.46 loss:0.27758 lr: 0.001500\n",
      "[12/541/109] iter:6061 accuracy:43.23 loss:0.31214 lr: 0.001500\n",
      "[12/541/119] iter:6071 accuracy:35.42 loss:0.30505 lr: 0.001500\n",
      "[12/541/129] iter:6081 accuracy:31.77 loss:0.28191 lr: 0.001500\n",
      "[12/541/139] iter:6091 accuracy:38.54 loss:0.26095 lr: 0.001500\n",
      "[12/541/149] iter:6101 accuracy:42.19 loss:0.28675 lr: 0.001500\n",
      "[12/541/159] iter:6111 accuracy:34.38 loss:0.24139 lr: 0.001500\n",
      "[12/541/169] iter:6121 accuracy:39.58 loss:0.24550 lr: 0.001500\n",
      "[12/541/179] iter:6131 accuracy:43.23 loss:0.27528 lr: 0.001500\n",
      "[12/541/189] iter:6141 accuracy:31.77 loss:0.32462 lr: 0.001500\n",
      "[12/541/199] iter:6151 accuracy:34.90 loss:0.33497 lr: 0.001500\n",
      "[12/541/209] iter:6161 accuracy:43.23 loss:0.28924 lr: 0.001500\n",
      "[12/541/219] iter:6171 accuracy:31.77 loss:0.34983 lr: 0.001500\n",
      "[12/541/229] iter:6181 accuracy:39.06 loss:0.32728 lr: 0.001500\n",
      "[12/541/239] iter:6191 accuracy:40.63 loss:0.25710 lr: 0.001500\n",
      "[12/541/249] iter:6201 accuracy:39.06 loss:0.35195 lr: 0.001500\n",
      "[12/541/259] iter:6211 accuracy:44.79 loss:0.26744 lr: 0.001500\n",
      "[12/541/269] iter:6221 accuracy:36.46 loss:0.30733 lr: 0.001500\n",
      "[12/541/279] iter:6231 accuracy:29.17 loss:0.31017 lr: 0.001500\n",
      "[12/541/289] iter:6241 accuracy:38.54 loss:0.26526 lr: 0.001500\n",
      "[12/541/299] iter:6251 accuracy:32.81 loss:0.30991 lr: 0.001500\n",
      "[12/541/309] iter:6261 accuracy:33.85 loss:0.32364 lr: 0.001500\n",
      "[12/541/319] iter:6271 accuracy:40.10 loss:0.30468 lr: 0.001500\n",
      "[12/541/329] iter:6281 accuracy:40.10 loss:0.30549 lr: 0.001500\n",
      "[12/541/339] iter:6291 accuracy:29.17 loss:0.32528 lr: 0.001500\n",
      "[12/541/349] iter:6301 accuracy:35.94 loss:0.34127 lr: 0.001500\n",
      "[12/541/359] iter:6311 accuracy:28.65 loss:0.26350 lr: 0.001500\n",
      "[12/541/369] iter:6321 accuracy:29.17 loss:0.29081 lr: 0.001500\n",
      "[12/541/379] iter:6331 accuracy:43.75 loss:0.30401 lr: 0.001500\n",
      "[12/541/389] iter:6341 accuracy:29.69 loss:0.36030 lr: 0.001500\n",
      "[12/541/399] iter:6351 accuracy:34.38 loss:0.36936 lr: 0.001500\n",
      "[12/541/409] iter:6361 accuracy:33.85 loss:0.31507 lr: 0.001500\n",
      "[12/541/419] iter:6371 accuracy:21.88 loss:0.30647 lr: 0.001500\n",
      "[12/541/429] iter:6381 accuracy:39.58 loss:0.26265 lr: 0.001500\n",
      "[12/541/439] iter:6391 accuracy:31.25 loss:0.29393 lr: 0.001500\n",
      "[12/541/449] iter:6401 accuracy:40.62 loss:0.31109 lr: 0.001500\n",
      "[12/541/459] iter:6411 accuracy:34.90 loss:0.34179 lr: 0.001500\n",
      "[12/541/469] iter:6421 accuracy:31.77 loss:0.23442 lr: 0.001500\n",
      "[12/541/479] iter:6431 accuracy:32.29 loss:0.39199 lr: 0.001500\n",
      "[12/541/489] iter:6441 accuracy:29.17 loss:0.23779 lr: 0.001500\n",
      "[12/541/499] iter:6451 accuracy:40.63 loss:0.26088 lr: 0.001500\n",
      "[12/541/509] iter:6461 accuracy:39.06 loss:0.32537 lr: 0.001500\n",
      "[12/541/519] iter:6471 accuracy:48.44 loss:0.28098 lr: 0.001500\n",
      "[12/541/529] iter:6481 accuracy:36.46 loss:0.37903 lr: 0.001500\n",
      "[12/541/539] iter:6491 accuracy:43.75 loss:0.34864 lr: 0.001500\n",
      "Epoch 12 of Valuation:\n",
      "[0] accuracy:27.604 loss:0.469\n",
      "[5] accuracy:39.062 loss:0.302\n",
      "[10] accuracy:43.229 loss:0.423\n",
      "[15] accuracy:22.917 loss:0.354\n",
      "[20] accuracy:30.208 loss:0.378\n",
      "[25] accuracy:29.167 loss:0.417\n",
      "[30] accuracy:37.500 loss:0.283\n",
      "[35] accuracy:22.917 loss:0.425\n",
      "[40] accuracy:35.417 loss:0.268\n",
      "[45] accuracy:34.896 loss:0.417\n",
      "[50] accuracy:32.812 loss:0.462\n",
      "[55] accuracy:31.771 loss:0.362\n",
      "[60] accuracy:28.125 loss:0.361\n",
      "[65] accuracy:30.729 loss:0.394\n",
      "[70] accuracy:23.958 loss:0.338\n",
      "[75] accuracy:26.562 loss:0.361\n",
      "Result\n",
      "Train accuracy:36.33, Train loss: 0.00482, Val accuracy:31.13, Val loss: 0.00597\n",
      "Patient 2\n",
      "Epoch 13 of Train:\n",
      "[13/541/9] iter:6502 accuracy:34.90 loss:0.31397 lr: 0.001500\n",
      "[13/541/19] iter:6512 accuracy:37.50 loss:0.25052 lr: 0.001500\n",
      "[13/541/29] iter:6522 accuracy:34.90 loss:0.30106 lr: 0.001500\n",
      "[13/541/39] iter:6532 accuracy:34.90 loss:0.26684 lr: 0.001500\n",
      "[13/541/49] iter:6542 accuracy:39.58 loss:0.27686 lr: 0.001500\n",
      "[13/541/59] iter:6552 accuracy:32.81 loss:0.29654 lr: 0.001500\n",
      "[13/541/69] iter:6562 accuracy:40.10 loss:0.28877 lr: 0.001500\n",
      "[13/541/79] iter:6572 accuracy:42.19 loss:0.30048 lr: 0.001500\n",
      "[13/541/89] iter:6582 accuracy:39.06 loss:0.25157 lr: 0.001500\n",
      "[13/541/99] iter:6592 accuracy:31.25 loss:0.32722 lr: 0.001500\n",
      "[13/541/109] iter:6602 accuracy:36.46 loss:0.26847 lr: 0.001500\n",
      "[13/541/119] iter:6612 accuracy:49.48 loss:0.25946 lr: 0.001500\n",
      "[13/541/129] iter:6622 accuracy:35.42 loss:0.25828 lr: 0.001500\n",
      "[13/541/139] iter:6632 accuracy:31.25 loss:0.35760 lr: 0.001500\n",
      "[13/541/149] iter:6642 accuracy:36.46 loss:0.30952 lr: 0.001500\n",
      "[13/541/159] iter:6652 accuracy:34.90 loss:0.34243 lr: 0.001500\n",
      "[13/541/169] iter:6662 accuracy:43.23 loss:0.30267 lr: 0.001500\n",
      "[13/541/179] iter:6672 accuracy:43.75 loss:0.27581 lr: 0.001500\n",
      "[13/541/189] iter:6682 accuracy:33.85 loss:0.27914 lr: 0.001500\n",
      "[13/541/199] iter:6692 accuracy:38.54 loss:0.33436 lr: 0.001500\n",
      "[13/541/209] iter:6702 accuracy:37.50 loss:0.24233 lr: 0.001500\n",
      "[13/541/219] iter:6712 accuracy:36.46 loss:0.24929 lr: 0.001500\n",
      "[13/541/229] iter:6722 accuracy:33.85 loss:0.26599 lr: 0.001500\n",
      "[13/541/239] iter:6732 accuracy:36.46 loss:0.40367 lr: 0.001500\n",
      "[13/541/249] iter:6742 accuracy:50.00 loss:0.32956 lr: 0.001500\n",
      "[13/541/259] iter:6752 accuracy:35.42 loss:0.28932 lr: 0.001500\n",
      "[13/541/269] iter:6762 accuracy:28.65 loss:0.33339 lr: 0.001500\n",
      "[13/541/279] iter:6772 accuracy:24.48 loss:0.33461 lr: 0.001500\n",
      "[13/541/289] iter:6782 accuracy:34.38 loss:0.31861 lr: 0.001500\n",
      "[13/541/299] iter:6792 accuracy:35.42 loss:0.25502 lr: 0.001500\n",
      "[13/541/309] iter:6802 accuracy:29.17 loss:0.30839 lr: 0.001500\n",
      "[13/541/319] iter:6812 accuracy:39.58 loss:0.34968 lr: 0.001500\n",
      "[13/541/329] iter:6822 accuracy:31.77 loss:0.30135 lr: 0.001500\n",
      "[13/541/339] iter:6832 accuracy:28.12 loss:0.28034 lr: 0.001500\n",
      "[13/541/349] iter:6842 accuracy:44.27 loss:0.36963 lr: 0.001500\n",
      "[13/541/359] iter:6852 accuracy:36.98 loss:0.30712 lr: 0.001500\n",
      "[13/541/369] iter:6862 accuracy:43.75 loss:0.38287 lr: 0.001500\n",
      "[13/541/379] iter:6872 accuracy:32.29 loss:0.29471 lr: 0.001500\n",
      "[13/541/389] iter:6882 accuracy:36.98 loss:0.31929 lr: 0.001500\n",
      "[13/541/399] iter:6892 accuracy:41.67 loss:0.30601 lr: 0.001500\n",
      "[13/541/409] iter:6902 accuracy:39.58 loss:0.26198 lr: 0.001500\n",
      "[13/541/419] iter:6912 accuracy:40.10 loss:0.28396 lr: 0.001500\n",
      "[13/541/429] iter:6922 accuracy:39.58 loss:0.32612 lr: 0.001500\n",
      "[13/541/439] iter:6932 accuracy:42.71 loss:0.36231 lr: 0.001500\n",
      "[13/541/449] iter:6942 accuracy:44.79 loss:0.30969 lr: 0.001500\n",
      "[13/541/459] iter:6952 accuracy:34.90 loss:0.30053 lr: 0.001500\n",
      "[13/541/469] iter:6962 accuracy:35.94 loss:0.35172 lr: 0.001500\n",
      "[13/541/479] iter:6972 accuracy:32.29 loss:0.31776 lr: 0.001500\n",
      "[13/541/489] iter:6982 accuracy:33.85 loss:0.28513 lr: 0.001500\n",
      "[13/541/499] iter:6992 accuracy:34.38 loss:0.26949 lr: 0.001500\n",
      "[13/541/509] iter:7002 accuracy:40.62 loss:0.30780 lr: 0.001500\n",
      "[13/541/519] iter:7012 accuracy:28.12 loss:0.28047 lr: 0.001500\n",
      "[13/541/529] iter:7022 accuracy:39.58 loss:0.28290 lr: 0.001500\n",
      "[13/541/539] iter:7032 accuracy:33.33 loss:0.26002 lr: 0.001500\n",
      "Epoch 13 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.448\n",
      "[5] accuracy:41.667 loss:0.289\n",
      "[10] accuracy:41.146 loss:0.424\n",
      "[15] accuracy:22.396 loss:0.358\n",
      "[20] accuracy:28.125 loss:0.380\n",
      "[25] accuracy:32.812 loss:0.409\n",
      "[30] accuracy:39.063 loss:0.290\n",
      "[35] accuracy:26.042 loss:0.414\n",
      "[40] accuracy:40.104 loss:0.274\n",
      "[45] accuracy:40.625 loss:0.417\n",
      "[50] accuracy:33.854 loss:0.452\n",
      "[55] accuracy:33.333 loss:0.367\n",
      "[60] accuracy:28.125 loss:0.359\n",
      "[65] accuracy:25.521 loss:0.411\n",
      "[70] accuracy:25.000 loss:0.357\n",
      "[75] accuracy:25.521 loss:0.355\n",
      "Result\n",
      "Train accuracy:37.08, Train loss: 0.00466, Val accuracy:31.73, Val loss: 0.00597\n",
      "Patient 3\n",
      "Epoch 14 of Train:\n",
      "[14/541/9] iter:7043 accuracy:50.52 loss:0.24480 lr: 0.000375\n",
      "[14/541/19] iter:7053 accuracy:44.79 loss:0.23791 lr: 0.000375\n",
      "[14/541/29] iter:7063 accuracy:32.81 loss:0.29208 lr: 0.000375\n",
      "[14/541/39] iter:7073 accuracy:38.02 loss:0.28535 lr: 0.000375\n",
      "[14/541/49] iter:7083 accuracy:44.79 loss:0.32470 lr: 0.000375\n",
      "[14/541/59] iter:7093 accuracy:33.33 loss:0.30002 lr: 0.000375\n",
      "[14/541/69] iter:7103 accuracy:26.04 loss:0.26441 lr: 0.000375\n",
      "[14/541/79] iter:7113 accuracy:26.56 loss:0.27938 lr: 0.000375\n",
      "[14/541/89] iter:7123 accuracy:35.42 loss:0.28062 lr: 0.000375\n",
      "[14/541/99] iter:7133 accuracy:47.40 loss:0.28108 lr: 0.000375\n",
      "[14/541/109] iter:7143 accuracy:44.27 loss:0.28300 lr: 0.000375\n",
      "[14/541/119] iter:7153 accuracy:38.54 loss:0.28021 lr: 0.000375\n",
      "[14/541/129] iter:7163 accuracy:44.27 loss:0.28759 lr: 0.000375\n",
      "[14/541/139] iter:7173 accuracy:45.83 loss:0.25544 lr: 0.000375\n",
      "[14/541/149] iter:7183 accuracy:40.62 loss:0.32990 lr: 0.000375\n",
      "[14/541/159] iter:7193 accuracy:33.85 loss:0.24524 lr: 0.000375\n",
      "[14/541/169] iter:7203 accuracy:44.79 loss:0.28747 lr: 0.000375\n",
      "[14/541/179] iter:7213 accuracy:46.35 loss:0.31741 lr: 0.000375\n",
      "[14/541/189] iter:7223 accuracy:39.58 loss:0.24438 lr: 0.000375\n",
      "[14/541/199] iter:7233 accuracy:39.58 loss:0.26409 lr: 0.000375\n",
      "[14/541/209] iter:7243 accuracy:34.38 loss:0.27782 lr: 0.000375\n",
      "[14/541/219] iter:7253 accuracy:46.35 loss:0.25621 lr: 0.000375\n",
      "[14/541/229] iter:7263 accuracy:39.58 loss:0.25609 lr: 0.000375\n",
      "[14/541/239] iter:7273 accuracy:48.96 loss:0.26638 lr: 0.000375\n",
      "[14/541/249] iter:7283 accuracy:40.62 loss:0.26285 lr: 0.000375\n",
      "[14/541/259] iter:7293 accuracy:35.94 loss:0.30033 lr: 0.000375\n",
      "[14/541/269] iter:7303 accuracy:45.83 loss:0.35740 lr: 0.000375\n",
      "[14/541/279] iter:7313 accuracy:35.42 loss:0.28607 lr: 0.000375\n",
      "[14/541/289] iter:7323 accuracy:47.92 loss:0.26208 lr: 0.000375\n",
      "[14/541/299] iter:7333 accuracy:42.19 loss:0.33750 lr: 0.000375\n",
      "[14/541/309] iter:7343 accuracy:43.23 loss:0.32317 lr: 0.000375\n",
      "[14/541/319] iter:7353 accuracy:43.75 loss:0.26605 lr: 0.000375\n",
      "[14/541/329] iter:7363 accuracy:44.27 loss:0.26748 lr: 0.000375\n",
      "[14/541/339] iter:7373 accuracy:40.63 loss:0.36072 lr: 0.000375\n",
      "[14/541/349] iter:7383 accuracy:33.33 loss:0.29896 lr: 0.000375\n",
      "[14/541/359] iter:7393 accuracy:32.81 loss:0.29682 lr: 0.000375\n",
      "[14/541/369] iter:7403 accuracy:35.42 loss:0.23653 lr: 0.000375\n",
      "[14/541/379] iter:7413 accuracy:34.38 loss:0.24518 lr: 0.000375\n",
      "[14/541/389] iter:7423 accuracy:39.06 loss:0.27985 lr: 0.000375\n",
      "[14/541/399] iter:7433 accuracy:43.75 loss:0.25605 lr: 0.000375\n",
      "[14/541/409] iter:7443 accuracy:39.58 loss:0.31803 lr: 0.000375\n",
      "[14/541/419] iter:7453 accuracy:38.54 loss:0.23360 lr: 0.000375\n",
      "[14/541/429] iter:7463 accuracy:38.02 loss:0.25185 lr: 0.000375\n",
      "[14/541/439] iter:7473 accuracy:41.67 loss:0.27387 lr: 0.000375\n",
      "[14/541/449] iter:7483 accuracy:53.12 loss:0.23670 lr: 0.000375\n",
      "[14/541/459] iter:7493 accuracy:33.85 loss:0.38824 lr: 0.000375\n",
      "[14/541/469] iter:7503 accuracy:38.02 loss:0.30625 lr: 0.000375\n",
      "[14/541/479] iter:7513 accuracy:39.58 loss:0.25195 lr: 0.000375\n",
      "[14/541/489] iter:7523 accuracy:35.94 loss:0.30763 lr: 0.000375\n",
      "[14/541/499] iter:7533 accuracy:44.79 loss:0.24359 lr: 0.000375\n",
      "[14/541/509] iter:7543 accuracy:44.79 loss:0.26626 lr: 0.000375\n",
      "[14/541/519] iter:7553 accuracy:40.62 loss:0.25795 lr: 0.000375\n",
      "[14/541/529] iter:7563 accuracy:35.94 loss:0.26851 lr: 0.000375\n",
      "[14/541/539] iter:7573 accuracy:31.77 loss:0.27841 lr: 0.000375\n",
      "Epoch 14 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.455\n",
      "[5] accuracy:43.229 loss:0.287\n",
      "[10] accuracy:41.667 loss:0.424\n",
      "[15] accuracy:24.479 loss:0.354\n",
      "[20] accuracy:27.604 loss:0.375\n",
      "[25] accuracy:32.812 loss:0.420\n",
      "[30] accuracy:41.146 loss:0.279\n",
      "[35] accuracy:28.125 loss:0.423\n",
      "[40] accuracy:38.542 loss:0.271\n",
      "[45] accuracy:37.500 loss:0.418\n",
      "[50] accuracy:34.896 loss:0.450\n",
      "[55] accuracy:34.375 loss:0.361\n",
      "[60] accuracy:29.688 loss:0.349\n",
      "[65] accuracy:32.292 loss:0.399\n",
      "[70] accuracy:23.438 loss:0.347\n",
      "[75] accuracy:26.562 loss:0.357\n",
      "Result\n",
      "Train accuracy:39.63, Train loss: 0.00426, Val accuracy:32.14, Val loss: 0.00593\n",
      "Patient 0\n",
      "Epoch 15 of Train:\n",
      "[15/541/9] iter:7584 accuracy:43.75 loss:0.23540 lr: 0.000375\n",
      "[15/541/19] iter:7594 accuracy:43.23 loss:0.28369 lr: 0.000375\n",
      "[15/541/29] iter:7604 accuracy:36.98 loss:0.26820 lr: 0.000375\n",
      "[15/541/39] iter:7614 accuracy:42.19 loss:0.25657 lr: 0.000375\n",
      "[15/541/49] iter:7624 accuracy:48.44 loss:0.25719 lr: 0.000375\n",
      "[15/541/59] iter:7634 accuracy:28.65 loss:0.27316 lr: 0.000375\n",
      "[15/541/69] iter:7644 accuracy:48.96 loss:0.20445 lr: 0.000375\n",
      "[15/541/79] iter:7654 accuracy:42.19 loss:0.27436 lr: 0.000375\n",
      "[15/541/89] iter:7664 accuracy:32.81 loss:0.21204 lr: 0.000375\n",
      "[15/541/99] iter:7674 accuracy:41.15 loss:0.25730 lr: 0.000375\n",
      "[15/541/109] iter:7684 accuracy:36.46 loss:0.26381 lr: 0.000375\n",
      "[15/541/119] iter:7694 accuracy:31.77 loss:0.25447 lr: 0.000375\n",
      "[15/541/129] iter:7704 accuracy:43.75 loss:0.26219 lr: 0.000375\n",
      "[15/541/139] iter:7714 accuracy:36.46 loss:0.29339 lr: 0.000375\n",
      "[15/541/149] iter:7724 accuracy:38.54 loss:0.34797 lr: 0.000375\n",
      "[15/541/159] iter:7734 accuracy:37.50 loss:0.19796 lr: 0.000375\n",
      "[15/541/169] iter:7744 accuracy:34.90 loss:0.32051 lr: 0.000375\n",
      "[15/541/179] iter:7754 accuracy:34.38 loss:0.27656 lr: 0.000375\n",
      "[15/541/189] iter:7764 accuracy:39.58 loss:0.25888 lr: 0.000375\n",
      "[15/541/199] iter:7774 accuracy:34.90 loss:0.23849 lr: 0.000375\n",
      "[15/541/209] iter:7784 accuracy:32.81 loss:0.25411 lr: 0.000375\n",
      "[15/541/219] iter:7794 accuracy:36.98 loss:0.24836 lr: 0.000375\n",
      "[15/541/229] iter:7804 accuracy:33.33 loss:0.33275 lr: 0.000375\n",
      "[15/541/239] iter:7814 accuracy:35.42 loss:0.26432 lr: 0.000375\n",
      "[15/541/249] iter:7824 accuracy:49.48 loss:0.29409 lr: 0.000375\n",
      "[15/541/259] iter:7834 accuracy:44.79 loss:0.27879 lr: 0.000375\n",
      "[15/541/269] iter:7844 accuracy:46.35 loss:0.26074 lr: 0.000375\n",
      "[15/541/279] iter:7854 accuracy:45.83 loss:0.21255 lr: 0.000375\n",
      "[15/541/289] iter:7864 accuracy:42.19 loss:0.22959 lr: 0.000375\n",
      "[15/541/299] iter:7874 accuracy:32.81 loss:0.27356 lr: 0.000375\n",
      "[15/541/309] iter:7884 accuracy:28.12 loss:0.34652 lr: 0.000375\n",
      "[15/541/319] iter:7894 accuracy:40.10 loss:0.25375 lr: 0.000375\n",
      "[15/541/329] iter:7904 accuracy:40.10 loss:0.30808 lr: 0.000375\n",
      "[15/541/339] iter:7914 accuracy:50.00 loss:0.26526 lr: 0.000375\n",
      "[15/541/349] iter:7924 accuracy:38.02 loss:0.29384 lr: 0.000375\n",
      "[15/541/359] iter:7934 accuracy:39.58 loss:0.24455 lr: 0.000375\n",
      "[15/541/369] iter:7944 accuracy:40.62 loss:0.29306 lr: 0.000375\n",
      "[15/541/379] iter:7954 accuracy:32.81 loss:0.22732 lr: 0.000375\n",
      "[15/541/389] iter:7964 accuracy:38.54 loss:0.23776 lr: 0.000375\n",
      "[15/541/399] iter:7974 accuracy:42.19 loss:0.28208 lr: 0.000375\n",
      "[15/541/409] iter:7984 accuracy:37.50 loss:0.28086 lr: 0.000375\n",
      "[15/541/419] iter:7994 accuracy:40.10 loss:0.27267 lr: 0.000375\n",
      "[15/541/429] iter:8004 accuracy:30.21 loss:0.26610 lr: 0.000375\n",
      "[15/541/439] iter:8014 accuracy:30.73 loss:0.24983 lr: 0.000375\n",
      "[15/541/449] iter:8024 accuracy:41.67 loss:0.27011 lr: 0.000375\n",
      "[15/541/459] iter:8034 accuracy:32.81 loss:0.34053 lr: 0.000375\n",
      "[15/541/469] iter:8044 accuracy:40.62 loss:0.24950 lr: 0.000375\n",
      "[15/541/479] iter:8054 accuracy:42.19 loss:0.31483 lr: 0.000375\n",
      "[15/541/489] iter:8064 accuracy:39.06 loss:0.23595 lr: 0.000375\n",
      "[15/541/499] iter:8074 accuracy:43.23 loss:0.24123 lr: 0.000375\n",
      "[15/541/509] iter:8084 accuracy:37.50 loss:0.25725 lr: 0.000375\n",
      "[15/541/519] iter:8094 accuracy:34.38 loss:0.27511 lr: 0.000375\n",
      "[15/541/529] iter:8104 accuracy:43.23 loss:0.21263 lr: 0.000375\n",
      "[15/541/539] iter:8114 accuracy:42.19 loss:0.23737 lr: 0.000375\n",
      "Epoch 15 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.466\n",
      "[5] accuracy:44.271 loss:0.285\n",
      "[10] accuracy:42.708 loss:0.430\n",
      "[15] accuracy:21.875 loss:0.359\n",
      "[20] accuracy:28.125 loss:0.383\n",
      "[25] accuracy:28.646 loss:0.410\n",
      "[30] accuracy:39.583 loss:0.275\n",
      "[35] accuracy:27.083 loss:0.420\n",
      "[40] accuracy:38.542 loss:0.274\n",
      "[45] accuracy:39.062 loss:0.419\n",
      "[50] accuracy:33.333 loss:0.469\n",
      "[55] accuracy:30.729 loss:0.367\n",
      "[60] accuracy:31.250 loss:0.348\n",
      "[65] accuracy:30.208 loss:0.401\n",
      "[70] accuracy:25.521 loss:0.350\n",
      "[75] accuracy:27.083 loss:0.356\n",
      "Result\n",
      "Train accuracy:40.23, Train loss: 0.00411, Val accuracy:32.19, Val loss: 0.00599\n",
      "Patient 0\n",
      "Epoch 16 of Train:\n",
      "[16/541/9] iter:8125 accuracy:44.79 loss:0.22349 lr: 0.000188\n",
      "[16/541/19] iter:8135 accuracy:48.96 loss:0.24220 lr: 0.000188\n",
      "[16/541/29] iter:8145 accuracy:40.10 loss:0.26689 lr: 0.000188\n",
      "[16/541/39] iter:8155 accuracy:32.29 loss:0.21924 lr: 0.000188\n",
      "[16/541/49] iter:8165 accuracy:34.38 loss:0.23173 lr: 0.000188\n",
      "[16/541/59] iter:8175 accuracy:39.06 loss:0.22329 lr: 0.000188\n",
      "[16/541/69] iter:8185 accuracy:45.31 loss:0.23106 lr: 0.000188\n",
      "[16/541/79] iter:8195 accuracy:36.98 loss:0.31247 lr: 0.000188\n",
      "[16/541/89] iter:8205 accuracy:39.06 loss:0.30114 lr: 0.000188\n",
      "[16/541/99] iter:8215 accuracy:43.23 loss:0.23246 lr: 0.000188\n",
      "[16/541/109] iter:8225 accuracy:40.62 loss:0.23753 lr: 0.000188\n",
      "[16/541/119] iter:8235 accuracy:41.67 loss:0.28268 lr: 0.000188\n",
      "[16/541/129] iter:8245 accuracy:38.02 loss:0.26767 lr: 0.000188\n",
      "[16/541/139] iter:8255 accuracy:31.77 loss:0.25464 lr: 0.000188\n",
      "[16/541/149] iter:8265 accuracy:33.33 loss:0.28762 lr: 0.000188\n",
      "[16/541/159] iter:8275 accuracy:34.90 loss:0.25433 lr: 0.000188\n",
      "[16/541/169] iter:8285 accuracy:45.31 loss:0.23379 lr: 0.000188\n",
      "[16/541/179] iter:8295 accuracy:47.40 loss:0.29021 lr: 0.000188\n",
      "[16/541/189] iter:8305 accuracy:36.46 loss:0.21546 lr: 0.000188\n",
      "[16/541/199] iter:8315 accuracy:50.52 loss:0.25633 lr: 0.000188\n",
      "[16/541/209] iter:8325 accuracy:33.33 loss:0.26804 lr: 0.000188\n",
      "[16/541/219] iter:8335 accuracy:36.46 loss:0.23128 lr: 0.000188\n",
      "[16/541/229] iter:8345 accuracy:50.00 loss:0.29935 lr: 0.000188\n",
      "[16/541/239] iter:8355 accuracy:40.10 loss:0.26691 lr: 0.000188\n",
      "[16/541/249] iter:8365 accuracy:38.54 loss:0.33464 lr: 0.000188\n",
      "[16/541/259] iter:8375 accuracy:35.94 loss:0.30057 lr: 0.000188\n",
      "[16/541/269] iter:8385 accuracy:44.27 loss:0.23677 lr: 0.000188\n",
      "[16/541/279] iter:8395 accuracy:37.50 loss:0.30064 lr: 0.000188\n",
      "[16/541/289] iter:8405 accuracy:36.46 loss:0.27772 lr: 0.000188\n",
      "[16/541/299] iter:8415 accuracy:52.60 loss:0.20964 lr: 0.000188\n",
      "[16/541/309] iter:8425 accuracy:36.46 loss:0.27933 lr: 0.000188\n",
      "[16/541/319] iter:8435 accuracy:39.06 loss:0.23415 lr: 0.000188\n",
      "[16/541/329] iter:8445 accuracy:41.67 loss:0.28080 lr: 0.000188\n",
      "[16/541/339] iter:8455 accuracy:44.79 loss:0.26085 lr: 0.000188\n",
      "[16/541/349] iter:8465 accuracy:38.54 loss:0.30867 lr: 0.000188\n",
      "[16/541/359] iter:8475 accuracy:36.98 loss:0.24798 lr: 0.000188\n",
      "[16/541/369] iter:8485 accuracy:43.23 loss:0.22947 lr: 0.000188\n",
      "[16/541/379] iter:8495 accuracy:46.88 loss:0.29015 lr: 0.000188\n",
      "[16/541/389] iter:8505 accuracy:46.88 loss:0.22451 lr: 0.000188\n",
      "[16/541/399] iter:8515 accuracy:43.23 loss:0.24393 lr: 0.000188\n",
      "[16/541/409] iter:8525 accuracy:47.92 loss:0.35427 lr: 0.000188\n",
      "[16/541/419] iter:8535 accuracy:42.71 loss:0.29157 lr: 0.000188\n",
      "[16/541/429] iter:8545 accuracy:39.58 loss:0.27556 lr: 0.000188\n",
      "[16/541/439] iter:8555 accuracy:44.79 loss:0.24396 lr: 0.000188\n",
      "[16/541/449] iter:8565 accuracy:48.96 loss:0.32047 lr: 0.000188\n",
      "[16/541/459] iter:8575 accuracy:51.04 loss:0.24632 lr: 0.000188\n",
      "[16/541/469] iter:8585 accuracy:45.31 loss:0.24644 lr: 0.000188\n",
      "[16/541/479] iter:8595 accuracy:37.50 loss:0.28167 lr: 0.000188\n",
      "[16/541/489] iter:8605 accuracy:47.40 loss:0.25245 lr: 0.000188\n",
      "[16/541/499] iter:8615 accuracy:44.27 loss:0.29082 lr: 0.000188\n",
      "[16/541/509] iter:8625 accuracy:37.50 loss:0.23659 lr: 0.000188\n",
      "[16/541/519] iter:8635 accuracy:40.10 loss:0.29697 lr: 0.000188\n",
      "[16/541/529] iter:8645 accuracy:34.90 loss:0.26752 lr: 0.000188\n",
      "[16/541/539] iter:8655 accuracy:39.58 loss:0.23612 lr: 0.000188\n",
      "Epoch 16 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.466\n",
      "[5] accuracy:44.792 loss:0.285\n",
      "[10] accuracy:43.750 loss:0.422\n",
      "[15] accuracy:21.875 loss:0.358\n",
      "[20] accuracy:29.688 loss:0.379\n",
      "[25] accuracy:28.646 loss:0.411\n",
      "[30] accuracy:38.021 loss:0.276\n",
      "[35] accuracy:26.562 loss:0.427\n",
      "[40] accuracy:39.583 loss:0.273\n",
      "[45] accuracy:38.021 loss:0.420\n",
      "[50] accuracy:31.771 loss:0.470\n",
      "[55] accuracy:32.292 loss:0.359\n",
      "[60] accuracy:31.250 loss:0.353\n",
      "[65] accuracy:30.729 loss:0.399\n",
      "[70] accuracy:25.000 loss:0.350\n",
      "[75] accuracy:26.042 loss:0.360\n",
      "Result\n",
      "Train accuracy:41.09, Train loss: 0.00402, Val accuracy:32.21, Val loss: 0.00600\n",
      "Patient 0\n",
      "Epoch 17 of Train:\n",
      "[17/541/9] iter:8666 accuracy:35.94 loss:0.24711 lr: 0.000188\n",
      "[17/541/19] iter:8676 accuracy:36.46 loss:0.30202 lr: 0.000188\n",
      "[17/541/29] iter:8686 accuracy:52.08 loss:0.26987 lr: 0.000188\n",
      "[17/541/39] iter:8696 accuracy:47.40 loss:0.23900 lr: 0.000188\n",
      "[17/541/49] iter:8706 accuracy:40.62 loss:0.29605 lr: 0.000188\n",
      "[17/541/59] iter:8716 accuracy:44.79 loss:0.23146 lr: 0.000188\n",
      "[17/541/69] iter:8726 accuracy:43.75 loss:0.22819 lr: 0.000188\n",
      "[17/541/79] iter:8736 accuracy:39.58 loss:0.29809 lr: 0.000188\n",
      "[17/541/89] iter:8746 accuracy:46.35 loss:0.30105 lr: 0.000188\n",
      "[17/541/99] iter:8756 accuracy:55.73 loss:0.24671 lr: 0.000188\n",
      "[17/541/109] iter:8766 accuracy:45.31 loss:0.27184 lr: 0.000188\n",
      "[17/541/119] iter:8776 accuracy:43.75 loss:0.27240 lr: 0.000188\n",
      "[17/541/129] iter:8786 accuracy:43.23 loss:0.27105 lr: 0.000188\n",
      "[17/541/139] iter:8796 accuracy:36.46 loss:0.21156 lr: 0.000188\n",
      "[17/541/149] iter:8806 accuracy:39.06 loss:0.29537 lr: 0.000188\n",
      "[17/541/159] iter:8816 accuracy:50.00 loss:0.23003 lr: 0.000188\n",
      "[17/541/169] iter:8826 accuracy:35.42 loss:0.22548 lr: 0.000188\n",
      "[17/541/179] iter:8836 accuracy:42.19 loss:0.23774 lr: 0.000188\n",
      "[17/541/189] iter:8846 accuracy:41.15 loss:0.21999 lr: 0.000188\n",
      "[17/541/199] iter:8856 accuracy:42.71 loss:0.26349 lr: 0.000188\n",
      "[17/541/209] iter:8866 accuracy:45.31 loss:0.27314 lr: 0.000188\n",
      "[17/541/219] iter:8876 accuracy:43.75 loss:0.26589 lr: 0.000188\n",
      "[17/541/229] iter:8886 accuracy:42.19 loss:0.22869 lr: 0.000188\n",
      "[17/541/239] iter:8896 accuracy:46.88 loss:0.26587 lr: 0.000188\n",
      "[17/541/249] iter:8906 accuracy:30.21 loss:0.25421 lr: 0.000188\n",
      "[17/541/259] iter:8916 accuracy:57.29 loss:0.28103 lr: 0.000188\n",
      "[17/541/269] iter:8926 accuracy:33.85 loss:0.27912 lr: 0.000188\n",
      "[17/541/279] iter:8936 accuracy:41.15 loss:0.24435 lr: 0.000188\n",
      "[17/541/289] iter:8946 accuracy:44.27 loss:0.24024 lr: 0.000188\n",
      "[17/541/299] iter:8956 accuracy:45.31 loss:0.22646 lr: 0.000188\n",
      "[17/541/309] iter:8966 accuracy:45.31 loss:0.26848 lr: 0.000188\n",
      "[17/541/319] iter:8976 accuracy:42.71 loss:0.30406 lr: 0.000188\n",
      "[17/541/329] iter:8986 accuracy:32.81 loss:0.35229 lr: 0.000188\n",
      "[17/541/339] iter:8996 accuracy:35.94 loss:0.21593 lr: 0.000188\n",
      "[17/541/349] iter:9006 accuracy:42.71 loss:0.17789 lr: 0.000188\n",
      "[17/541/359] iter:9016 accuracy:38.02 loss:0.21844 lr: 0.000188\n",
      "[17/541/369] iter:9026 accuracy:39.58 loss:0.26117 lr: 0.000188\n",
      "[17/541/379] iter:9036 accuracy:33.85 loss:0.23715 lr: 0.000188\n",
      "[17/541/389] iter:9046 accuracy:45.83 loss:0.23169 lr: 0.000188\n",
      "[17/541/399] iter:9056 accuracy:36.46 loss:0.27786 lr: 0.000188\n",
      "[17/541/409] iter:9066 accuracy:46.35 loss:0.26657 lr: 0.000188\n",
      "[17/541/419] iter:9076 accuracy:31.77 loss:0.28450 lr: 0.000188\n",
      "[17/541/429] iter:9086 accuracy:39.58 loss:0.30688 lr: 0.000188\n",
      "[17/541/439] iter:9096 accuracy:50.52 loss:0.20562 lr: 0.000188\n",
      "[17/541/449] iter:9106 accuracy:47.40 loss:0.24738 lr: 0.000188\n",
      "[17/541/459] iter:9116 accuracy:63.54 loss:0.21552 lr: 0.000188\n",
      "[17/541/469] iter:9126 accuracy:43.23 loss:0.28792 lr: 0.000188\n",
      "[17/541/479] iter:9136 accuracy:43.75 loss:0.29798 lr: 0.000188\n",
      "[17/541/489] iter:9146 accuracy:53.12 loss:0.23027 lr: 0.000188\n",
      "[17/541/499] iter:9156 accuracy:35.42 loss:0.26687 lr: 0.000188\n",
      "[17/541/509] iter:9166 accuracy:41.67 loss:0.22247 lr: 0.000188\n",
      "[17/541/519] iter:9176 accuracy:39.06 loss:0.25398 lr: 0.000188\n",
      "[17/541/529] iter:9186 accuracy:36.98 loss:0.26424 lr: 0.000188\n",
      "[17/541/539] iter:9196 accuracy:39.06 loss:0.17663 lr: 0.000188\n",
      "Epoch 17 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.467\n",
      "[5] accuracy:42.708 loss:0.289\n",
      "[10] accuracy:44.271 loss:0.426\n",
      "[15] accuracy:20.312 loss:0.359\n",
      "[20] accuracy:29.688 loss:0.386\n",
      "[25] accuracy:28.125 loss:0.413\n",
      "[30] accuracy:40.625 loss:0.280\n",
      "[35] accuracy:26.562 loss:0.429\n",
      "[40] accuracy:41.667 loss:0.276\n",
      "[45] accuracy:38.542 loss:0.421\n",
      "[50] accuracy:34.896 loss:0.472\n",
      "[55] accuracy:34.896 loss:0.361\n",
      "[60] accuracy:31.250 loss:0.361\n",
      "[65] accuracy:30.729 loss:0.407\n",
      "[70] accuracy:25.521 loss:0.354\n",
      "[75] accuracy:26.562 loss:0.364\n",
      "Result\n",
      "Train accuracy:41.04, Train loss: 0.00395, Val accuracy:32.31, Val loss: 0.00603\n",
      "Patient 0\n",
      "Epoch 18 of Train:\n",
      "[18/541/9] iter:9207 accuracy:39.58 loss:0.28710 lr: 0.000125\n",
      "[18/541/19] iter:9217 accuracy:51.56 loss:0.21739 lr: 0.000125\n",
      "[18/541/29] iter:9227 accuracy:43.75 loss:0.20671 lr: 0.000125\n",
      "[18/541/39] iter:9237 accuracy:41.67 loss:0.28718 lr: 0.000125\n",
      "[18/541/49] iter:9247 accuracy:46.88 loss:0.22632 lr: 0.000125\n",
      "[18/541/59] iter:9257 accuracy:44.79 loss:0.27563 lr: 0.000125\n",
      "[18/541/69] iter:9267 accuracy:41.67 loss:0.26474 lr: 0.000125\n",
      "[18/541/79] iter:9277 accuracy:32.29 loss:0.22512 lr: 0.000125\n",
      "[18/541/89] iter:9287 accuracy:33.85 loss:0.30109 lr: 0.000125\n",
      "[18/541/99] iter:9297 accuracy:42.71 loss:0.28528 lr: 0.000125\n",
      "[18/541/109] iter:9307 accuracy:39.06 loss:0.20119 lr: 0.000125\n",
      "[18/541/119] iter:9317 accuracy:43.23 loss:0.28509 lr: 0.000125\n",
      "[18/541/129] iter:9327 accuracy:39.06 loss:0.29987 lr: 0.000125\n",
      "[18/541/139] iter:9337 accuracy:43.23 loss:0.22240 lr: 0.000125\n",
      "[18/541/149] iter:9347 accuracy:41.67 loss:0.24076 lr: 0.000125\n",
      "[18/541/159] iter:9357 accuracy:54.17 loss:0.20802 lr: 0.000125\n",
      "[18/541/169] iter:9367 accuracy:45.83 loss:0.26312 lr: 0.000125\n",
      "[18/541/179] iter:9377 accuracy:35.94 loss:0.25395 lr: 0.000125\n",
      "[18/541/189] iter:9387 accuracy:39.06 loss:0.21692 lr: 0.000125\n",
      "[18/541/199] iter:9397 accuracy:36.46 loss:0.24138 lr: 0.000125\n",
      "[18/541/209] iter:9407 accuracy:39.58 loss:0.22974 lr: 0.000125\n",
      "[18/541/219] iter:9417 accuracy:42.71 loss:0.22345 lr: 0.000125\n",
      "[18/541/229] iter:9427 accuracy:44.27 loss:0.24124 lr: 0.000125\n",
      "[18/541/239] iter:9437 accuracy:32.29 loss:0.20207 lr: 0.000125\n",
      "[18/541/249] iter:9447 accuracy:47.92 loss:0.22914 lr: 0.000125\n",
      "[18/541/259] iter:9457 accuracy:39.58 loss:0.28301 lr: 0.000125\n",
      "[18/541/269] iter:9467 accuracy:43.75 loss:0.27981 lr: 0.000125\n",
      "[18/541/279] iter:9477 accuracy:41.15 loss:0.24811 lr: 0.000125\n",
      "[18/541/289] iter:9487 accuracy:46.35 loss:0.20230 lr: 0.000125\n",
      "[18/541/299] iter:9497 accuracy:33.85 loss:0.25548 lr: 0.000125\n",
      "[18/541/309] iter:9507 accuracy:40.10 loss:0.25370 lr: 0.000125\n",
      "[18/541/319] iter:9517 accuracy:50.52 loss:0.27519 lr: 0.000125\n",
      "[18/541/329] iter:9527 accuracy:36.98 loss:0.24799 lr: 0.000125\n",
      "[18/541/339] iter:9537 accuracy:35.42 loss:0.27039 lr: 0.000125\n",
      "[18/541/349] iter:9547 accuracy:33.33 loss:0.26890 lr: 0.000125\n",
      "[18/541/359] iter:9557 accuracy:43.75 loss:0.28087 lr: 0.000125\n",
      "[18/541/369] iter:9567 accuracy:34.38 loss:0.23820 lr: 0.000125\n",
      "[18/541/379] iter:9577 accuracy:45.83 loss:0.28824 lr: 0.000125\n",
      "[18/541/389] iter:9587 accuracy:41.15 loss:0.24147 lr: 0.000125\n",
      "[18/541/399] iter:9597 accuracy:38.02 loss:0.30760 lr: 0.000125\n",
      "[18/541/409] iter:9607 accuracy:43.23 loss:0.29212 lr: 0.000125\n",
      "[18/541/419] iter:9617 accuracy:39.58 loss:0.29795 lr: 0.000125\n",
      "[18/541/429] iter:9627 accuracy:46.88 loss:0.22258 lr: 0.000125\n",
      "[18/541/439] iter:9637 accuracy:51.04 loss:0.21266 lr: 0.000125\n",
      "[18/541/449] iter:9647 accuracy:40.10 loss:0.20609 lr: 0.000125\n",
      "[18/541/459] iter:9657 accuracy:40.63 loss:0.21909 lr: 0.000125\n",
      "[18/541/469] iter:9667 accuracy:39.58 loss:0.23873 lr: 0.000125\n",
      "[18/541/479] iter:9677 accuracy:51.56 loss:0.22151 lr: 0.000125\n",
      "[18/541/489] iter:9687 accuracy:41.67 loss:0.27357 lr: 0.000125\n",
      "[18/541/499] iter:9697 accuracy:20.83 loss:0.28628 lr: 0.000125\n",
      "[18/541/509] iter:9707 accuracy:45.83 loss:0.22766 lr: 0.000125\n",
      "[18/541/519] iter:9717 accuracy:48.96 loss:0.25007 lr: 0.000125\n",
      "[18/541/529] iter:9727 accuracy:41.15 loss:0.28741 lr: 0.000125\n",
      "[18/541/539] iter:9737 accuracy:46.35 loss:0.23993 lr: 0.000125\n",
      "Epoch 18 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.470\n",
      "[5] accuracy:44.271 loss:0.287\n",
      "[10] accuracy:43.229 loss:0.430\n",
      "[15] accuracy:20.312 loss:0.356\n",
      "[20] accuracy:29.688 loss:0.387\n",
      "[25] accuracy:30.208 loss:0.414\n",
      "[30] accuracy:40.625 loss:0.279\n",
      "[35] accuracy:31.250 loss:0.430\n",
      "[40] accuracy:38.021 loss:0.273\n",
      "[45] accuracy:39.583 loss:0.422\n",
      "[50] accuracy:34.375 loss:0.476\n",
      "[55] accuracy:33.333 loss:0.360\n",
      "[60] accuracy:31.250 loss:0.362\n",
      "[65] accuracy:28.646 loss:0.407\n",
      "[70] accuracy:25.000 loss:0.356\n",
      "[75] accuracy:26.042 loss:0.364\n",
      "Result\n",
      "Train accuracy:41.60, Train loss: 0.00392, Val accuracy:32.14, Val loss: 0.00605\n",
      "Patient 1\n",
      "Epoch 19 of Train:\n",
      "[19/541/9] iter:9748 accuracy:42.19 loss:0.25774 lr: 0.000125\n",
      "[19/541/19] iter:9758 accuracy:42.19 loss:0.26646 lr: 0.000125\n",
      "[19/541/29] iter:9768 accuracy:51.04 loss:0.31422 lr: 0.000125\n",
      "[19/541/39] iter:9778 accuracy:44.27 loss:0.20375 lr: 0.000125\n",
      "[19/541/49] iter:9788 accuracy:44.27 loss:0.19920 lr: 0.000125\n",
      "[19/541/59] iter:9798 accuracy:40.10 loss:0.20100 lr: 0.000125\n",
      "[19/541/69] iter:9808 accuracy:53.12 loss:0.19567 lr: 0.000125\n",
      "[19/541/79] iter:9818 accuracy:44.27 loss:0.18311 lr: 0.000125\n",
      "[19/541/89] iter:9828 accuracy:46.88 loss:0.22757 lr: 0.000125\n",
      "[19/541/99] iter:9838 accuracy:42.71 loss:0.18799 lr: 0.000125\n",
      "[19/541/109] iter:9848 accuracy:43.75 loss:0.24040 lr: 0.000125\n",
      "[19/541/119] iter:9858 accuracy:36.98 loss:0.26596 lr: 0.000125\n",
      "[19/541/129] iter:9868 accuracy:30.21 loss:0.25611 lr: 0.000125\n",
      "[19/541/139] iter:9878 accuracy:40.10 loss:0.16949 lr: 0.000125\n",
      "[19/541/149] iter:9888 accuracy:43.23 loss:0.27658 lr: 0.000125\n",
      "[19/541/159] iter:9898 accuracy:41.67 loss:0.24938 lr: 0.000125\n",
      "[19/541/169] iter:9908 accuracy:43.23 loss:0.29401 lr: 0.000125\n",
      "[19/541/179] iter:9918 accuracy:29.69 loss:0.21387 lr: 0.000125\n",
      "[19/541/189] iter:9928 accuracy:39.58 loss:0.23979 lr: 0.000125\n",
      "[19/541/199] iter:9938 accuracy:38.02 loss:0.28287 lr: 0.000125\n",
      "[19/541/209] iter:9948 accuracy:39.58 loss:0.24501 lr: 0.000125\n",
      "[19/541/219] iter:9958 accuracy:34.38 loss:0.29722 lr: 0.000125\n",
      "[19/541/229] iter:9968 accuracy:48.96 loss:0.23384 lr: 0.000125\n",
      "[19/541/239] iter:9978 accuracy:47.40 loss:0.20721 lr: 0.000125\n",
      "[19/541/249] iter:9988 accuracy:47.40 loss:0.23424 lr: 0.000125\n",
      "[19/541/259] iter:9998 accuracy:34.90 loss:0.21899 lr: 0.000125\n",
      "[19/541/269] iter:10008 accuracy:41.67 loss:0.23294 lr: 0.000125\n",
      "[19/541/279] iter:10018 accuracy:44.79 loss:0.27406 lr: 0.000125\n",
      "[19/541/289] iter:10028 accuracy:47.92 loss:0.24370 lr: 0.000125\n",
      "[19/541/299] iter:10038 accuracy:43.75 loss:0.25069 lr: 0.000125\n",
      "[19/541/309] iter:10048 accuracy:37.50 loss:0.24591 lr: 0.000125\n",
      "[19/541/319] iter:10058 accuracy:32.29 loss:0.26416 lr: 0.000125\n",
      "[19/541/329] iter:10068 accuracy:54.69 loss:0.24961 lr: 0.000125\n",
      "[19/541/339] iter:10078 accuracy:43.23 loss:0.27073 lr: 0.000125\n",
      "[19/541/349] iter:10088 accuracy:45.83 loss:0.24094 lr: 0.000125\n",
      "[19/541/359] iter:10098 accuracy:49.48 loss:0.27015 lr: 0.000125\n",
      "[19/541/369] iter:10108 accuracy:41.15 loss:0.26407 lr: 0.000125\n",
      "[19/541/379] iter:10118 accuracy:33.33 loss:0.22292 lr: 0.000125\n",
      "[19/541/389] iter:10128 accuracy:36.98 loss:0.22485 lr: 0.000125\n",
      "[19/541/399] iter:10138 accuracy:45.83 loss:0.25728 lr: 0.000125\n",
      "[19/541/409] iter:10148 accuracy:39.58 loss:0.24776 lr: 0.000125\n",
      "[19/541/419] iter:10158 accuracy:30.73 loss:0.27364 lr: 0.000125\n",
      "[19/541/429] iter:10168 accuracy:38.02 loss:0.26783 lr: 0.000125\n",
      "[19/541/439] iter:10178 accuracy:34.38 loss:0.22396 lr: 0.000125\n",
      "[19/541/449] iter:10188 accuracy:30.73 loss:0.21404 lr: 0.000125\n",
      "[19/541/459] iter:10198 accuracy:38.02 loss:0.23134 lr: 0.000125\n",
      "[19/541/469] iter:10208 accuracy:42.19 loss:0.27120 lr: 0.000125\n",
      "[19/541/479] iter:10218 accuracy:46.88 loss:0.22622 lr: 0.000125\n",
      "[19/541/489] iter:10228 accuracy:41.67 loss:0.29071 lr: 0.000125\n",
      "[19/541/499] iter:10238 accuracy:48.96 loss:0.22494 lr: 0.000125\n",
      "[19/541/509] iter:10248 accuracy:40.62 loss:0.24220 lr: 0.000125\n",
      "[19/541/519] iter:10258 accuracy:41.67 loss:0.29165 lr: 0.000125\n",
      "[19/541/529] iter:10268 accuracy:42.19 loss:0.20346 lr: 0.000125\n",
      "[19/541/539] iter:10278 accuracy:53.65 loss:0.24548 lr: 0.000125\n",
      "Epoch 19 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.473\n",
      "[5] accuracy:45.833 loss:0.288\n",
      "[10] accuracy:43.229 loss:0.431\n",
      "[15] accuracy:21.875 loss:0.362\n",
      "[20] accuracy:31.250 loss:0.385\n",
      "[25] accuracy:28.646 loss:0.424\n",
      "[30] accuracy:39.062 loss:0.283\n",
      "[35] accuracy:29.688 loss:0.434\n",
      "[40] accuracy:39.583 loss:0.272\n",
      "[45] accuracy:39.062 loss:0.421\n",
      "[50] accuracy:31.250 loss:0.483\n",
      "[55] accuracy:31.771 loss:0.363\n",
      "[60] accuracy:31.250 loss:0.361\n",
      "[65] accuracy:29.167 loss:0.408\n",
      "[70] accuracy:25.000 loss:0.362\n",
      "[75] accuracy:26.562 loss:0.370\n",
      "Result\n",
      "Train accuracy:41.75, Train loss: 0.00388, Val accuracy:31.95, Val loss: 0.00611\n",
      "Patient 2\n",
      "Epoch 20 of Train:\n",
      "[20/541/9] iter:10289 accuracy:40.62 loss:0.24083 lr: 0.000094\n",
      "[20/541/19] iter:10299 accuracy:49.48 loss:0.23949 lr: 0.000094\n",
      "[20/541/29] iter:10309 accuracy:34.38 loss:0.25008 lr: 0.000094\n",
      "[20/541/39] iter:10319 accuracy:51.04 loss:0.22439 lr: 0.000094\n",
      "[20/541/49] iter:10329 accuracy:44.27 loss:0.29635 lr: 0.000094\n",
      "[20/541/59] iter:10339 accuracy:45.31 loss:0.25989 lr: 0.000094\n",
      "[20/541/69] iter:10349 accuracy:39.06 loss:0.23373 lr: 0.000094\n",
      "[20/541/79] iter:10359 accuracy:44.79 loss:0.20480 lr: 0.000094\n",
      "[20/541/89] iter:10369 accuracy:43.23 loss:0.22606 lr: 0.000094\n",
      "[20/541/99] iter:10379 accuracy:31.25 loss:0.25864 lr: 0.000094\n",
      "[20/541/109] iter:10389 accuracy:43.75 loss:0.30436 lr: 0.000094\n",
      "[20/541/119] iter:10399 accuracy:34.38 loss:0.26184 lr: 0.000094\n",
      "[20/541/129] iter:10409 accuracy:35.94 loss:0.26736 lr: 0.000094\n",
      "[20/541/139] iter:10419 accuracy:42.71 loss:0.25630 lr: 0.000094\n",
      "[20/541/149] iter:10429 accuracy:50.52 loss:0.21854 lr: 0.000094\n",
      "[20/541/159] iter:10439 accuracy:43.23 loss:0.26655 lr: 0.000094\n",
      "[20/541/169] iter:10449 accuracy:42.19 loss:0.21890 lr: 0.000094\n",
      "[20/541/179] iter:10459 accuracy:45.83 loss:0.29086 lr: 0.000094\n",
      "[20/541/189] iter:10469 accuracy:48.96 loss:0.23151 lr: 0.000094\n",
      "[20/541/199] iter:10479 accuracy:50.00 loss:0.28540 lr: 0.000094\n",
      "[20/541/209] iter:10489 accuracy:38.54 loss:0.23018 lr: 0.000094\n",
      "[20/541/219] iter:10499 accuracy:31.25 loss:0.22672 lr: 0.000094\n",
      "[20/541/229] iter:10509 accuracy:51.56 loss:0.24403 lr: 0.000094\n",
      "[20/541/239] iter:10519 accuracy:40.10 loss:0.21269 lr: 0.000094\n",
      "[20/541/249] iter:10529 accuracy:38.02 loss:0.27843 lr: 0.000094\n",
      "[20/541/259] iter:10539 accuracy:49.48 loss:0.24718 lr: 0.000094\n",
      "[20/541/269] iter:10549 accuracy:54.17 loss:0.28315 lr: 0.000094\n",
      "[20/541/279] iter:10559 accuracy:49.48 loss:0.27534 lr: 0.000094\n",
      "[20/541/289] iter:10569 accuracy:41.15 loss:0.28499 lr: 0.000094\n",
      "[20/541/299] iter:10579 accuracy:36.46 loss:0.27118 lr: 0.000094\n",
      "[20/541/309] iter:10589 accuracy:34.38 loss:0.23946 lr: 0.000094\n",
      "[20/541/319] iter:10599 accuracy:41.67 loss:0.25880 lr: 0.000094\n",
      "[20/541/329] iter:10609 accuracy:43.23 loss:0.25152 lr: 0.000094\n",
      "[20/541/339] iter:10619 accuracy:44.27 loss:0.28390 lr: 0.000094\n",
      "[20/541/349] iter:10629 accuracy:44.79 loss:0.22289 lr: 0.000094\n",
      "[20/541/359] iter:10639 accuracy:44.79 loss:0.26825 lr: 0.000094\n",
      "[20/541/369] iter:10649 accuracy:36.46 loss:0.25211 lr: 0.000094\n",
      "[20/541/379] iter:10659 accuracy:34.90 loss:0.23079 lr: 0.000094\n",
      "[20/541/389] iter:10669 accuracy:34.38 loss:0.26051 lr: 0.000094\n",
      "[20/541/399] iter:10679 accuracy:32.81 loss:0.25241 lr: 0.000094\n",
      "[20/541/409] iter:10689 accuracy:39.58 loss:0.22203 lr: 0.000094\n",
      "[20/541/419] iter:10699 accuracy:36.98 loss:0.24121 lr: 0.000094\n",
      "[20/541/429] iter:10709 accuracy:35.42 loss:0.31546 lr: 0.000094\n",
      "[20/541/439] iter:10719 accuracy:34.38 loss:0.22330 lr: 0.000094\n",
      "[20/541/449] iter:10729 accuracy:54.69 loss:0.22134 lr: 0.000094\n",
      "[20/541/459] iter:10739 accuracy:49.48 loss:0.27656 lr: 0.000094\n",
      "[20/541/469] iter:10749 accuracy:37.50 loss:0.30823 lr: 0.000094\n",
      "[20/541/479] iter:10759 accuracy:36.46 loss:0.26155 lr: 0.000094\n",
      "[20/541/489] iter:10769 accuracy:35.42 loss:0.29639 lr: 0.000094\n",
      "[20/541/499] iter:10779 accuracy:43.23 loss:0.24021 lr: 0.000094\n",
      "[20/541/509] iter:10789 accuracy:42.71 loss:0.37293 lr: 0.000094\n",
      "[20/541/519] iter:10799 accuracy:43.23 loss:0.22928 lr: 0.000094\n",
      "[20/541/529] iter:10809 accuracy:39.58 loss:0.24597 lr: 0.000094\n",
      "[20/541/539] iter:10819 accuracy:43.75 loss:0.27538 lr: 0.000094\n",
      "Epoch 20 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.474\n",
      "[5] accuracy:42.708 loss:0.290\n",
      "[10] accuracy:43.229 loss:0.435\n",
      "[15] accuracy:21.875 loss:0.360\n",
      "[20] accuracy:31.250 loss:0.386\n",
      "[25] accuracy:28.646 loss:0.426\n",
      "[30] accuracy:40.625 loss:0.281\n",
      "[35] accuracy:28.646 loss:0.433\n",
      "[40] accuracy:35.417 loss:0.273\n",
      "[45] accuracy:38.542 loss:0.422\n",
      "[50] accuracy:31.771 loss:0.481\n",
      "[55] accuracy:31.771 loss:0.362\n",
      "[60] accuracy:31.250 loss:0.360\n",
      "[65] accuracy:28.646 loss:0.413\n",
      "[70] accuracy:25.000 loss:0.361\n",
      "[75] accuracy:27.604 loss:0.371\n",
      "Result\n",
      "Train accuracy:41.94, Train loss: 0.00385, Val accuracy:31.85, Val loss: 0.00611\n",
      "Patient 3\n",
      "Epoch 21 of Train:\n",
      "[21/541/9] iter:10830 accuracy:36.98 loss:0.17462 lr: 0.000094\n",
      "[21/541/19] iter:10840 accuracy:39.06 loss:0.32172 lr: 0.000094\n",
      "[21/541/29] iter:10850 accuracy:45.83 loss:0.23203 lr: 0.000094\n",
      "[21/541/39] iter:10860 accuracy:43.23 loss:0.27008 lr: 0.000094\n",
      "[21/541/49] iter:10870 accuracy:38.02 loss:0.22231 lr: 0.000094\n",
      "[21/541/59] iter:10880 accuracy:52.08 loss:0.29138 lr: 0.000094\n",
      "[21/541/69] iter:10890 accuracy:40.62 loss:0.20192 lr: 0.000094\n",
      "[21/541/79] iter:10900 accuracy:41.15 loss:0.26739 lr: 0.000094\n",
      "[21/541/89] iter:10910 accuracy:30.21 loss:0.22390 lr: 0.000094\n",
      "[21/541/99] iter:10920 accuracy:42.19 loss:0.23842 lr: 0.000094\n",
      "[21/541/109] iter:10930 accuracy:30.21 loss:0.27751 lr: 0.000094\n",
      "[21/541/119] iter:10940 accuracy:31.25 loss:0.22674 lr: 0.000094\n",
      "[21/541/129] iter:10950 accuracy:48.96 loss:0.23955 lr: 0.000094\n",
      "[21/541/139] iter:10960 accuracy:54.69 loss:0.22982 lr: 0.000094\n",
      "[21/541/149] iter:10970 accuracy:50.00 loss:0.21049 lr: 0.000094\n",
      "[21/541/159] iter:10980 accuracy:38.02 loss:0.21417 lr: 0.000094\n",
      "[21/541/169] iter:10990 accuracy:45.83 loss:0.21449 lr: 0.000094\n",
      "[21/541/179] iter:11000 accuracy:38.02 loss:0.24767 lr: 0.000094\n",
      "[21/541/189] iter:11010 accuracy:44.79 loss:0.27489 lr: 0.000094\n",
      "[21/541/199] iter:11020 accuracy:52.60 loss:0.24762 lr: 0.000094\n",
      "[21/541/209] iter:11030 accuracy:36.46 loss:0.22938 lr: 0.000094\n",
      "[21/541/219] iter:11040 accuracy:35.42 loss:0.22104 lr: 0.000094\n",
      "[21/541/229] iter:11050 accuracy:53.12 loss:0.22514 lr: 0.000094\n",
      "[21/541/239] iter:11060 accuracy:49.48 loss:0.21638 lr: 0.000094\n",
      "[21/541/249] iter:11070 accuracy:39.58 loss:0.22141 lr: 0.000094\n",
      "[21/541/259] iter:11080 accuracy:42.19 loss:0.20436 lr: 0.000094\n",
      "[21/541/269] iter:11090 accuracy:47.40 loss:0.26438 lr: 0.000094\n",
      "[21/541/279] iter:11100 accuracy:38.02 loss:0.26901 lr: 0.000094\n",
      "[21/541/289] iter:11110 accuracy:41.15 loss:0.25563 lr: 0.000094\n",
      "[21/541/299] iter:11120 accuracy:34.90 loss:0.21239 lr: 0.000094\n",
      "[21/541/309] iter:11130 accuracy:45.83 loss:0.19938 lr: 0.000094\n",
      "[21/541/319] iter:11140 accuracy:38.54 loss:0.21157 lr: 0.000094\n",
      "[21/541/329] iter:11150 accuracy:41.15 loss:0.23977 lr: 0.000094\n",
      "[21/541/339] iter:11160 accuracy:44.79 loss:0.23508 lr: 0.000094\n",
      "[21/541/349] iter:11170 accuracy:45.83 loss:0.23015 lr: 0.000094\n",
      "[21/541/359] iter:11180 accuracy:49.48 loss:0.27329 lr: 0.000094\n",
      "[21/541/369] iter:11190 accuracy:39.58 loss:0.24888 lr: 0.000094\n",
      "[21/541/379] iter:11200 accuracy:45.83 loss:0.27965 lr: 0.000094\n",
      "[21/541/389] iter:11210 accuracy:33.85 loss:0.25255 lr: 0.000094\n",
      "[21/541/399] iter:11220 accuracy:35.94 loss:0.28498 lr: 0.000094\n",
      "[21/541/409] iter:11230 accuracy:46.88 loss:0.25517 lr: 0.000094\n",
      "[21/541/419] iter:11240 accuracy:42.71 loss:0.24530 lr: 0.000094\n",
      "[21/541/429] iter:11250 accuracy:41.15 loss:0.20499 lr: 0.000094\n",
      "[21/541/439] iter:11260 accuracy:44.79 loss:0.30592 lr: 0.000094\n",
      "[21/541/449] iter:11270 accuracy:43.23 loss:0.23196 lr: 0.000094\n",
      "[21/541/459] iter:11280 accuracy:46.88 loss:0.22439 lr: 0.000094\n",
      "[21/541/469] iter:11290 accuracy:35.42 loss:0.23664 lr: 0.000094\n",
      "[21/541/479] iter:11300 accuracy:34.38 loss:0.24162 lr: 0.000094\n",
      "[21/541/489] iter:11310 accuracy:39.58 loss:0.25355 lr: 0.000094\n",
      "[21/541/499] iter:11320 accuracy:54.69 loss:0.26108 lr: 0.000094\n",
      "[21/541/509] iter:11330 accuracy:40.10 loss:0.26446 lr: 0.000094\n",
      "[21/541/519] iter:11340 accuracy:36.98 loss:0.26360 lr: 0.000094\n",
      "[21/541/529] iter:11350 accuracy:36.98 loss:0.29208 lr: 0.000094\n",
      "[21/541/539] iter:11360 accuracy:38.54 loss:0.24861 lr: 0.000094\n",
      "Epoch 21 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.475\n",
      "[5] accuracy:42.708 loss:0.292\n",
      "[10] accuracy:44.271 loss:0.432\n",
      "[15] accuracy:24.479 loss:0.361\n",
      "[20] accuracy:29.688 loss:0.385\n",
      "[25] accuracy:28.646 loss:0.424\n",
      "[30] accuracy:40.625 loss:0.281\n",
      "[35] accuracy:28.646 loss:0.432\n",
      "[40] accuracy:38.542 loss:0.272\n",
      "[45] accuracy:39.062 loss:0.423\n",
      "[50] accuracy:29.688 loss:0.494\n",
      "[55] accuracy:31.771 loss:0.368\n",
      "[60] accuracy:29.688 loss:0.362\n",
      "[65] accuracy:29.167 loss:0.413\n",
      "[70] accuracy:25.521 loss:0.365\n",
      "[75] accuracy:26.042 loss:0.370\n",
      "Result\n",
      "Train accuracy:42.18, Train loss: 0.00383, Val accuracy:31.98, Val loss: 0.00613\n",
      "Patient 4\n",
      "Epoch 22 of Train:\n",
      "[22/541/9] iter:11371 accuracy:40.62 loss:0.23248 lr: 0.000075\n",
      "[22/541/19] iter:11381 accuracy:51.56 loss:0.19667 lr: 0.000075\n",
      "[22/541/29] iter:11391 accuracy:42.19 loss:0.25098 lr: 0.000075\n",
      "[22/541/39] iter:11401 accuracy:41.15 loss:0.25902 lr: 0.000075\n",
      "[22/541/49] iter:11411 accuracy:46.88 loss:0.22462 lr: 0.000075\n",
      "[22/541/59] iter:11421 accuracy:39.06 loss:0.21837 lr: 0.000075\n",
      "[22/541/69] iter:11431 accuracy:42.19 loss:0.23363 lr: 0.000075\n",
      "[22/541/79] iter:11441 accuracy:47.40 loss:0.22246 lr: 0.000075\n",
      "[22/541/89] iter:11451 accuracy:36.98 loss:0.22512 lr: 0.000075\n",
      "[22/541/99] iter:11461 accuracy:38.54 loss:0.25835 lr: 0.000075\n",
      "[22/541/109] iter:11471 accuracy:42.71 loss:0.28437 lr: 0.000075\n",
      "[22/541/119] iter:11481 accuracy:41.67 loss:0.30165 lr: 0.000075\n",
      "[22/541/129] iter:11491 accuracy:35.42 loss:0.29354 lr: 0.000075\n",
      "[22/541/139] iter:11501 accuracy:47.92 loss:0.20489 lr: 0.000075\n",
      "[22/541/149] iter:11511 accuracy:47.40 loss:0.25589 lr: 0.000075\n",
      "[22/541/159] iter:11521 accuracy:41.67 loss:0.25369 lr: 0.000075\n",
      "[22/541/169] iter:11531 accuracy:41.67 loss:0.24674 lr: 0.000075\n",
      "[22/541/179] iter:11541 accuracy:39.06 loss:0.24604 lr: 0.000075\n",
      "[22/541/189] iter:11551 accuracy:37.50 loss:0.24771 lr: 0.000075\n",
      "[22/541/199] iter:11561 accuracy:42.71 loss:0.25016 lr: 0.000075\n",
      "[22/541/209] iter:11571 accuracy:55.21 loss:0.25191 lr: 0.000075\n",
      "[22/541/219] iter:11581 accuracy:40.62 loss:0.22671 lr: 0.000075\n",
      "[22/541/229] iter:11591 accuracy:42.19 loss:0.26424 lr: 0.000075\n",
      "[22/541/239] iter:11601 accuracy:50.52 loss:0.24173 lr: 0.000075\n",
      "[22/541/249] iter:11611 accuracy:34.38 loss:0.28624 lr: 0.000075\n",
      "[22/541/259] iter:11621 accuracy:48.44 loss:0.30819 lr: 0.000075\n",
      "[22/541/269] iter:11631 accuracy:34.38 loss:0.27166 lr: 0.000075\n",
      "[22/541/279] iter:11641 accuracy:32.81 loss:0.22952 lr: 0.000075\n",
      "[22/541/289] iter:11651 accuracy:36.98 loss:0.24895 lr: 0.000075\n",
      "[22/541/299] iter:11661 accuracy:50.52 loss:0.19989 lr: 0.000075\n",
      "[22/541/309] iter:11671 accuracy:52.08 loss:0.29147 lr: 0.000075\n",
      "[22/541/319] iter:11681 accuracy:45.31 loss:0.25290 lr: 0.000075\n",
      "[22/541/329] iter:11691 accuracy:42.71 loss:0.19931 lr: 0.000075\n",
      "[22/541/339] iter:11701 accuracy:42.71 loss:0.18376 lr: 0.000075\n",
      "[22/541/349] iter:11711 accuracy:41.15 loss:0.21184 lr: 0.000075\n",
      "[22/541/359] iter:11721 accuracy:49.48 loss:0.23007 lr: 0.000075\n",
      "[22/541/369] iter:11731 accuracy:41.67 loss:0.23306 lr: 0.000075\n",
      "[22/541/379] iter:11741 accuracy:34.90 loss:0.19667 lr: 0.000075\n",
      "[22/541/389] iter:11751 accuracy:45.83 loss:0.23790 lr: 0.000075\n",
      "[22/541/399] iter:11761 accuracy:45.31 loss:0.21761 lr: 0.000075\n",
      "[22/541/409] iter:11771 accuracy:42.19 loss:0.27915 lr: 0.000075\n",
      "[22/541/419] iter:11781 accuracy:41.15 loss:0.19862 lr: 0.000075\n",
      "[22/541/429] iter:11791 accuracy:37.50 loss:0.28554 lr: 0.000075\n",
      "[22/541/439] iter:11801 accuracy:48.96 loss:0.27184 lr: 0.000075\n",
      "[22/541/449] iter:11811 accuracy:43.23 loss:0.22961 lr: 0.000075\n",
      "[22/541/459] iter:11821 accuracy:39.58 loss:0.23640 lr: 0.000075\n",
      "[22/541/469] iter:11831 accuracy:33.33 loss:0.26364 lr: 0.000075\n",
      "[22/541/479] iter:11841 accuracy:38.54 loss:0.22903 lr: 0.000075\n",
      "[22/541/489] iter:11851 accuracy:35.94 loss:0.17488 lr: 0.000075\n",
      "[22/541/499] iter:11861 accuracy:35.94 loss:0.20107 lr: 0.000075\n",
      "[22/541/509] iter:11871 accuracy:36.98 loss:0.22778 lr: 0.000075\n",
      "[22/541/519] iter:11881 accuracy:45.83 loss:0.26019 lr: 0.000075\n",
      "[22/541/529] iter:11891 accuracy:35.94 loss:0.20605 lr: 0.000075\n",
      "[22/541/539] iter:11901 accuracy:41.15 loss:0.23244 lr: 0.000075\n",
      "Epoch 22 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.474\n",
      "[5] accuracy:42.708 loss:0.290\n",
      "[10] accuracy:44.792 loss:0.435\n",
      "[15] accuracy:23.438 loss:0.360\n",
      "[20] accuracy:29.688 loss:0.388\n",
      "[25] accuracy:28.646 loss:0.424\n",
      "[30] accuracy:40.625 loss:0.280\n",
      "[35] accuracy:28.646 loss:0.433\n",
      "[40] accuracy:38.542 loss:0.273\n",
      "[45] accuracy:38.021 loss:0.426\n",
      "[50] accuracy:31.250 loss:0.489\n",
      "[55] accuracy:32.292 loss:0.366\n",
      "[60] accuracy:29.688 loss:0.363\n",
      "[65] accuracy:27.604 loss:0.413\n",
      "[70] accuracy:25.521 loss:0.362\n",
      "[75] accuracy:26.042 loss:0.371\n",
      "Result\n",
      "Train accuracy:42.14, Train loss: 0.00381, Val accuracy:31.94, Val loss: 0.00613\n",
      "Patient 5\n",
      "Epoch 23 of Train:\n",
      "[23/541/9] iter:11912 accuracy:48.44 loss:0.25227 lr: 0.000075\n",
      "[23/541/19] iter:11922 accuracy:40.10 loss:0.28675 lr: 0.000075\n",
      "[23/541/29] iter:11932 accuracy:44.79 loss:0.23392 lr: 0.000075\n",
      "[23/541/39] iter:11942 accuracy:35.94 loss:0.22541 lr: 0.000075\n",
      "[23/541/49] iter:11952 accuracy:59.38 loss:0.25006 lr: 0.000075\n",
      "[23/541/59] iter:11962 accuracy:43.75 loss:0.29301 lr: 0.000075\n",
      "[23/541/69] iter:11972 accuracy:46.88 loss:0.23590 lr: 0.000075\n",
      "[23/541/79] iter:11982 accuracy:39.58 loss:0.23308 lr: 0.000075\n",
      "[23/541/89] iter:11992 accuracy:40.10 loss:0.20207 lr: 0.000075\n",
      "[23/541/99] iter:12002 accuracy:44.27 loss:0.23421 lr: 0.000075\n",
      "[23/541/109] iter:12012 accuracy:42.71 loss:0.30738 lr: 0.000075\n",
      "[23/541/119] iter:12022 accuracy:34.90 loss:0.25271 lr: 0.000075\n",
      "[23/541/129] iter:12032 accuracy:46.88 loss:0.25022 lr: 0.000075\n",
      "[23/541/139] iter:12042 accuracy:33.85 loss:0.21175 lr: 0.000075\n",
      "[23/541/149] iter:12052 accuracy:42.71 loss:0.24363 lr: 0.000075\n",
      "[23/541/159] iter:12062 accuracy:39.58 loss:0.24074 lr: 0.000075\n",
      "[23/541/169] iter:12072 accuracy:37.50 loss:0.27636 lr: 0.000075\n",
      "[23/541/179] iter:12082 accuracy:44.79 loss:0.24311 lr: 0.000075\n",
      "[23/541/189] iter:12092 accuracy:45.31 loss:0.23812 lr: 0.000075\n",
      "[23/541/199] iter:12102 accuracy:56.25 loss:0.19360 lr: 0.000075\n",
      "[23/541/209] iter:12112 accuracy:29.69 loss:0.21517 lr: 0.000075\n",
      "[23/541/219] iter:12122 accuracy:51.56 loss:0.28862 lr: 0.000075\n",
      "[23/541/229] iter:12132 accuracy:43.75 loss:0.22579 lr: 0.000075\n",
      "[23/541/239] iter:12142 accuracy:51.04 loss:0.24027 lr: 0.000075\n",
      "[23/541/249] iter:12152 accuracy:37.50 loss:0.23901 lr: 0.000075\n",
      "[23/541/259] iter:12162 accuracy:52.08 loss:0.33485 lr: 0.000075\n",
      "[23/541/269] iter:12172 accuracy:41.15 loss:0.25318 lr: 0.000075\n",
      "[23/541/279] iter:12182 accuracy:50.52 loss:0.20093 lr: 0.000075\n",
      "[23/541/289] iter:12192 accuracy:35.94 loss:0.20022 lr: 0.000075\n",
      "[23/541/299] iter:12202 accuracy:41.67 loss:0.27029 lr: 0.000075\n",
      "[23/541/309] iter:12212 accuracy:39.58 loss:0.20677 lr: 0.000075\n",
      "[23/541/319] iter:12222 accuracy:31.25 loss:0.22366 lr: 0.000075\n",
      "[23/541/329] iter:12232 accuracy:41.67 loss:0.23899 lr: 0.000075\n",
      "[23/541/339] iter:12242 accuracy:42.71 loss:0.27893 lr: 0.000075\n",
      "[23/541/349] iter:12252 accuracy:41.15 loss:0.24860 lr: 0.000075\n",
      "[23/541/359] iter:12262 accuracy:41.15 loss:0.27343 lr: 0.000075\n",
      "[23/541/369] iter:12272 accuracy:44.27 loss:0.27924 lr: 0.000075\n",
      "[23/541/379] iter:12282 accuracy:54.17 loss:0.21462 lr: 0.000075\n",
      "[23/541/389] iter:12292 accuracy:47.92 loss:0.18640 lr: 0.000075\n",
      "[23/541/399] iter:12302 accuracy:48.96 loss:0.24657 lr: 0.000075\n",
      "[23/541/409] iter:12312 accuracy:46.88 loss:0.25324 lr: 0.000075\n",
      "[23/541/419] iter:12322 accuracy:43.23 loss:0.24599 lr: 0.000075\n",
      "[23/541/429] iter:12332 accuracy:41.15 loss:0.23025 lr: 0.000075\n",
      "[23/541/439] iter:12342 accuracy:36.98 loss:0.22935 lr: 0.000075\n",
      "[23/541/449] iter:12352 accuracy:36.98 loss:0.19776 lr: 0.000075\n",
      "[23/541/459] iter:12362 accuracy:51.04 loss:0.25103 lr: 0.000075\n",
      "[23/541/469] iter:12372 accuracy:46.88 loss:0.20598 lr: 0.000075\n",
      "[23/541/479] iter:12382 accuracy:51.04 loss:0.24712 lr: 0.000075\n",
      "[23/541/489] iter:12392 accuracy:46.35 loss:0.19155 lr: 0.000075\n",
      "[23/541/499] iter:12402 accuracy:44.27 loss:0.28368 lr: 0.000075\n",
      "[23/541/509] iter:12412 accuracy:33.85 loss:0.25862 lr: 0.000075\n",
      "[23/541/519] iter:12422 accuracy:38.02 loss:0.25924 lr: 0.000075\n",
      "[23/541/529] iter:12432 accuracy:46.88 loss:0.26445 lr: 0.000075\n",
      "[23/541/539] iter:12442 accuracy:43.75 loss:0.22737 lr: 0.000075\n",
      "Epoch 23 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.475\n",
      "[5] accuracy:42.708 loss:0.292\n",
      "[10] accuracy:44.271 loss:0.436\n",
      "[15] accuracy:22.917 loss:0.366\n",
      "[20] accuracy:29.688 loss:0.388\n",
      "[25] accuracy:28.646 loss:0.430\n",
      "[30] accuracy:39.062 loss:0.282\n",
      "[35] accuracy:28.646 loss:0.436\n",
      "[40] accuracy:40.104 loss:0.272\n",
      "[45] accuracy:39.062 loss:0.425\n",
      "[50] accuracy:32.812 loss:0.494\n",
      "[55] accuracy:31.771 loss:0.369\n",
      "[60] accuracy:31.250 loss:0.364\n",
      "[65] accuracy:29.167 loss:0.417\n",
      "[70] accuracy:25.521 loss:0.365\n",
      "[75] accuracy:27.604 loss:0.375\n",
      "Result\n",
      "Train accuracy:42.52, Train loss: 0.00378, Val accuracy:32.01, Val loss: 0.00616\n",
      "Patient 6\n",
      "Epoch 24 of Train:\n",
      "[24/541/9] iter:12453 accuracy:45.31 loss:0.23442 lr: 0.000063\n",
      "[24/541/19] iter:12463 accuracy:52.08 loss:0.24314 lr: 0.000063\n",
      "[24/541/29] iter:12473 accuracy:38.54 loss:0.19679 lr: 0.000063\n",
      "[24/541/39] iter:12483 accuracy:44.27 loss:0.25594 lr: 0.000063\n",
      "[24/541/49] iter:12493 accuracy:40.62 loss:0.20358 lr: 0.000063\n",
      "[24/541/59] iter:12503 accuracy:33.33 loss:0.25143 lr: 0.000063\n",
      "[24/541/69] iter:12513 accuracy:43.75 loss:0.32802 lr: 0.000063\n",
      "[24/541/79] iter:12523 accuracy:47.40 loss:0.21578 lr: 0.000063\n",
      "[24/541/89] iter:12533 accuracy:50.52 loss:0.21740 lr: 0.000063\n",
      "[24/541/99] iter:12543 accuracy:43.23 loss:0.29046 lr: 0.000063\n",
      "[24/541/109] iter:12553 accuracy:46.88 loss:0.24116 lr: 0.000063\n",
      "[24/541/119] iter:12563 accuracy:39.06 loss:0.20851 lr: 0.000063\n",
      "[24/541/129] iter:12573 accuracy:38.02 loss:0.23711 lr: 0.000063\n",
      "[24/541/139] iter:12583 accuracy:36.46 loss:0.22166 lr: 0.000063\n",
      "[24/541/149] iter:12593 accuracy:41.67 loss:0.23867 lr: 0.000063\n",
      "[24/541/159] iter:12603 accuracy:43.23 loss:0.29305 lr: 0.000063\n",
      "[24/541/169] iter:12613 accuracy:38.54 loss:0.28470 lr: 0.000063\n",
      "[24/541/179] iter:12623 accuracy:44.79 loss:0.25655 lr: 0.000063\n",
      "[24/541/189] iter:12633 accuracy:36.46 loss:0.27448 lr: 0.000063\n",
      "[24/541/199] iter:12643 accuracy:47.92 loss:0.23074 lr: 0.000063\n",
      "[24/541/209] iter:12653 accuracy:46.35 loss:0.23002 lr: 0.000063\n",
      "[24/541/219] iter:12663 accuracy:44.27 loss:0.25428 lr: 0.000063\n",
      "[24/541/229] iter:12673 accuracy:42.19 loss:0.30395 lr: 0.000063\n",
      "[24/541/239] iter:12683 accuracy:48.44 loss:0.23216 lr: 0.000063\n",
      "[24/541/249] iter:12693 accuracy:43.75 loss:0.30610 lr: 0.000063\n",
      "[24/541/259] iter:12703 accuracy:47.92 loss:0.22747 lr: 0.000063\n",
      "[24/541/269] iter:12713 accuracy:36.46 loss:0.29975 lr: 0.000063\n",
      "[24/541/279] iter:12723 accuracy:33.33 loss:0.23566 lr: 0.000063\n",
      "[24/541/289] iter:12733 accuracy:45.31 loss:0.21376 lr: 0.000063\n",
      "[24/541/299] iter:12743 accuracy:40.62 loss:0.24672 lr: 0.000063\n",
      "[24/541/309] iter:12753 accuracy:41.15 loss:0.28454 lr: 0.000063\n",
      "[24/541/319] iter:12763 accuracy:39.06 loss:0.26784 lr: 0.000063\n",
      "[24/541/329] iter:12773 accuracy:40.62 loss:0.28886 lr: 0.000063\n",
      "[24/541/339] iter:12783 accuracy:51.56 loss:0.28262 lr: 0.000063\n",
      "[24/541/349] iter:12793 accuracy:42.71 loss:0.23877 lr: 0.000063\n",
      "[24/541/359] iter:12803 accuracy:39.06 loss:0.23166 lr: 0.000063\n",
      "[24/541/369] iter:12813 accuracy:45.83 loss:0.24239 lr: 0.000063\n",
      "[24/541/379] iter:12823 accuracy:42.71 loss:0.24332 lr: 0.000063\n",
      "[24/541/389] iter:12833 accuracy:40.10 loss:0.24968 lr: 0.000063\n",
      "[24/541/399] iter:12843 accuracy:47.40 loss:0.28674 lr: 0.000063\n",
      "[24/541/409] iter:12853 accuracy:39.06 loss:0.17562 lr: 0.000063\n",
      "[24/541/419] iter:12863 accuracy:36.46 loss:0.25670 lr: 0.000063\n",
      "[24/541/429] iter:12873 accuracy:41.15 loss:0.27641 lr: 0.000063\n",
      "[24/541/439] iter:12883 accuracy:45.31 loss:0.27458 lr: 0.000063\n",
      "[24/541/449] iter:12893 accuracy:36.46 loss:0.28138 lr: 0.000063\n",
      "[24/541/459] iter:12903 accuracy:39.58 loss:0.27084 lr: 0.000063\n",
      "[24/541/469] iter:12913 accuracy:35.42 loss:0.27049 lr: 0.000063\n",
      "[24/541/479] iter:12923 accuracy:46.88 loss:0.25818 lr: 0.000063\n",
      "[24/541/489] iter:12933 accuracy:48.44 loss:0.26487 lr: 0.000063\n",
      "[24/541/499] iter:12943 accuracy:44.79 loss:0.20737 lr: 0.000063\n",
      "[24/541/509] iter:12953 accuracy:42.19 loss:0.25383 lr: 0.000063\n",
      "[24/541/519] iter:12963 accuracy:43.75 loss:0.30781 lr: 0.000063\n",
      "[24/541/529] iter:12973 accuracy:41.15 loss:0.26166 lr: 0.000063\n",
      "[24/541/539] iter:12983 accuracy:46.88 loss:0.23911 lr: 0.000063\n",
      "Epoch 24 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.474\n",
      "[5] accuracy:41.146 loss:0.293\n",
      "[10] accuracy:43.750 loss:0.438\n",
      "[15] accuracy:23.438 loss:0.365\n",
      "[20] accuracy:29.688 loss:0.389\n",
      "[25] accuracy:28.646 loss:0.431\n",
      "[30] accuracy:39.062 loss:0.284\n",
      "[35] accuracy:27.604 loss:0.438\n",
      "[40] accuracy:41.667 loss:0.271\n",
      "[45] accuracy:39.583 loss:0.429\n",
      "[50] accuracy:32.812 loss:0.495\n",
      "[55] accuracy:32.292 loss:0.369\n",
      "[60] accuracy:31.250 loss:0.366\n",
      "[65] accuracy:29.167 loss:0.416\n",
      "[70] accuracy:25.521 loss:0.365\n",
      "[75] accuracy:26.562 loss:0.374\n",
      "Result\n",
      "Train accuracy:42.41, Train loss: 0.00378, Val accuracy:31.84, Val loss: 0.00617\n",
      "Patient 7\n",
      "Epoch 25 of Train:\n",
      "[25/541/9] iter:12994 accuracy:43.23 loss:0.31137 lr: 0.000063\n",
      "[25/541/19] iter:13004 accuracy:45.31 loss:0.24915 lr: 0.000063\n",
      "[25/541/29] iter:13014 accuracy:50.00 loss:0.26482 lr: 0.000063\n",
      "[25/541/39] iter:13024 accuracy:39.06 loss:0.27015 lr: 0.000063\n",
      "[25/541/49] iter:13034 accuracy:40.10 loss:0.25444 lr: 0.000063\n",
      "[25/541/59] iter:13044 accuracy:41.15 loss:0.31597 lr: 0.000063\n",
      "[25/541/69] iter:13054 accuracy:44.27 loss:0.27665 lr: 0.000063\n",
      "[25/541/79] iter:13064 accuracy:33.85 loss:0.25536 lr: 0.000063\n",
      "[25/541/89] iter:13074 accuracy:36.98 loss:0.17116 lr: 0.000063\n",
      "[25/541/99] iter:13084 accuracy:30.73 loss:0.18425 lr: 0.000063\n",
      "[25/541/109] iter:13094 accuracy:39.58 loss:0.18481 lr: 0.000063\n",
      "[25/541/119] iter:13104 accuracy:51.56 loss:0.26346 lr: 0.000063\n",
      "[25/541/129] iter:13114 accuracy:53.65 loss:0.23523 lr: 0.000063\n",
      "[25/541/139] iter:13124 accuracy:33.85 loss:0.23122 lr: 0.000063\n",
      "[25/541/149] iter:13134 accuracy:39.58 loss:0.23055 lr: 0.000063\n",
      "[25/541/159] iter:13144 accuracy:41.67 loss:0.17181 lr: 0.000063\n",
      "[25/541/169] iter:13154 accuracy:34.90 loss:0.24835 lr: 0.000063\n",
      "[25/541/179] iter:13164 accuracy:44.27 loss:0.25512 lr: 0.000063\n",
      "[25/541/189] iter:13174 accuracy:34.38 loss:0.22462 lr: 0.000063\n",
      "[25/541/199] iter:13184 accuracy:40.62 loss:0.24993 lr: 0.000063\n",
      "[25/541/209] iter:13194 accuracy:51.56 loss:0.28359 lr: 0.000063\n",
      "[25/541/219] iter:13204 accuracy:41.15 loss:0.25985 lr: 0.000063\n",
      "[25/541/229] iter:13214 accuracy:49.48 loss:0.24689 lr: 0.000063\n",
      "[25/541/239] iter:13224 accuracy:46.88 loss:0.21890 lr: 0.000063\n",
      "[25/541/249] iter:13234 accuracy:35.42 loss:0.20810 lr: 0.000063\n",
      "[25/541/259] iter:13244 accuracy:35.94 loss:0.24396 lr: 0.000063\n",
      "[25/541/269] iter:13254 accuracy:40.62 loss:0.25687 lr: 0.000063\n",
      "[25/541/279] iter:13264 accuracy:44.27 loss:0.26897 lr: 0.000063\n",
      "[25/541/289] iter:13274 accuracy:54.69 loss:0.24334 lr: 0.000063\n",
      "[25/541/299] iter:13284 accuracy:48.96 loss:0.26657 lr: 0.000063\n",
      "[25/541/309] iter:13294 accuracy:36.46 loss:0.27164 lr: 0.000063\n",
      "[25/541/319] iter:13304 accuracy:45.31 loss:0.21747 lr: 0.000063\n",
      "[25/541/329] iter:13314 accuracy:50.52 loss:0.23140 lr: 0.000063\n",
      "[25/541/339] iter:13324 accuracy:41.15 loss:0.28116 lr: 0.000063\n",
      "[25/541/349] iter:13334 accuracy:45.83 loss:0.24438 lr: 0.000063\n",
      "[25/541/359] iter:13344 accuracy:45.83 loss:0.28215 lr: 0.000063\n",
      "[25/541/369] iter:13354 accuracy:42.19 loss:0.16577 lr: 0.000063\n",
      "[25/541/379] iter:13364 accuracy:44.27 loss:0.25014 lr: 0.000063\n",
      "[25/541/389] iter:13374 accuracy:49.48 loss:0.24734 lr: 0.000063\n",
      "[25/541/399] iter:13384 accuracy:37.50 loss:0.22753 lr: 0.000063\n",
      "[25/541/409] iter:13394 accuracy:47.40 loss:0.24257 lr: 0.000063\n",
      "[25/541/419] iter:13404 accuracy:28.65 loss:0.24496 lr: 0.000063\n",
      "[25/541/429] iter:13414 accuracy:52.60 loss:0.20350 lr: 0.000063\n",
      "[25/541/439] iter:13424 accuracy:49.48 loss:0.19973 lr: 0.000063\n",
      "[25/541/449] iter:13434 accuracy:38.54 loss:0.28227 lr: 0.000063\n",
      "[25/541/459] iter:13444 accuracy:45.83 loss:0.23581 lr: 0.000063\n",
      "[25/541/469] iter:13454 accuracy:41.67 loss:0.23051 lr: 0.000063\n",
      "[25/541/479] iter:13464 accuracy:38.02 loss:0.20991 lr: 0.000063\n",
      "[25/541/489] iter:13474 accuracy:37.50 loss:0.22391 lr: 0.000063\n",
      "[25/541/499] iter:13484 accuracy:50.52 loss:0.21444 lr: 0.000063\n",
      "[25/541/509] iter:13494 accuracy:43.75 loss:0.25308 lr: 0.000063\n",
      "[25/541/519] iter:13504 accuracy:36.46 loss:0.22691 lr: 0.000063\n",
      "[25/541/529] iter:13514 accuracy:35.94 loss:0.24854 lr: 0.000063\n",
      "[25/541/539] iter:13524 accuracy:43.23 loss:0.23799 lr: 0.000063\n",
      "Epoch 25 of Valuation:\n",
      "[0] accuracy:27.083 loss:0.475\n",
      "[5] accuracy:44.271 loss:0.293\n",
      "[10] accuracy:42.708 loss:0.438\n",
      "[15] accuracy:21.875 loss:0.367\n",
      "[20] accuracy:29.688 loss:0.390\n",
      "[25] accuracy:28.646 loss:0.432\n",
      "[30] accuracy:39.062 loss:0.288\n",
      "[35] accuracy:28.646 loss:0.440\n",
      "[40] accuracy:41.667 loss:0.273\n",
      "[45] accuracy:39.583 loss:0.427\n",
      "[50] accuracy:33.333 loss:0.497\n",
      "[55] accuracy:32.292 loss:0.371\n",
      "[60] accuracy:31.250 loss:0.370\n",
      "[65] accuracy:29.167 loss:0.418\n",
      "[70] accuracy:25.521 loss:0.371\n",
      "[75] accuracy:28.125 loss:0.375\n",
      "Result\n",
      "Train accuracy:42.58, Train loss: 0.00375, Val accuracy:31.93, Val loss: 0.00620\n",
      "Patient 8\n",
      "Epoch 26 of Train:\n",
      "[26/541/9] iter:13535 accuracy:32.81 loss:0.23345 lr: 0.000054\n",
      "[26/541/19] iter:13545 accuracy:38.54 loss:0.20833 lr: 0.000054\n",
      "[26/541/29] iter:13555 accuracy:38.02 loss:0.20777 lr: 0.000054\n",
      "[26/541/39] iter:13565 accuracy:40.10 loss:0.22380 lr: 0.000054\n",
      "[26/541/49] iter:13575 accuracy:43.75 loss:0.28624 lr: 0.000054\n",
      "[26/541/59] iter:13585 accuracy:47.92 loss:0.30260 lr: 0.000054\n",
      "[26/541/69] iter:13595 accuracy:41.67 loss:0.24974 lr: 0.000054\n",
      "[26/541/79] iter:13605 accuracy:42.71 loss:0.25934 lr: 0.000054\n",
      "[26/541/89] iter:13615 accuracy:44.27 loss:0.23025 lr: 0.000054\n",
      "[26/541/99] iter:13625 accuracy:50.00 loss:0.26600 lr: 0.000054\n",
      "[26/541/109] iter:13635 accuracy:40.62 loss:0.25083 lr: 0.000054\n",
      "[26/541/119] iter:13645 accuracy:46.35 loss:0.26768 lr: 0.000054\n",
      "[26/541/129] iter:13655 accuracy:34.38 loss:0.21157 lr: 0.000054\n",
      "[26/541/139] iter:13665 accuracy:46.35 loss:0.18674 lr: 0.000054\n",
      "[26/541/149] iter:13675 accuracy:38.54 loss:0.24144 lr: 0.000054\n",
      "[26/541/159] iter:13685 accuracy:39.58 loss:0.18785 lr: 0.000054\n",
      "[26/541/169] iter:13695 accuracy:46.88 loss:0.26799 lr: 0.000054\n",
      "[26/541/179] iter:13705 accuracy:47.92 loss:0.21728 lr: 0.000054\n",
      "[26/541/189] iter:13715 accuracy:46.88 loss:0.26511 lr: 0.000054\n",
      "[26/541/199] iter:13725 accuracy:45.31 loss:0.24706 lr: 0.000054\n",
      "[26/541/209] iter:13735 accuracy:39.58 loss:0.23486 lr: 0.000054\n",
      "[26/541/219] iter:13745 accuracy:38.54 loss:0.24476 lr: 0.000054\n",
      "[26/541/229] iter:13755 accuracy:39.58 loss:0.32089 lr: 0.000054\n",
      "[26/541/239] iter:13765 accuracy:36.98 loss:0.28704 lr: 0.000054\n",
      "[26/541/249] iter:13775 accuracy:42.71 loss:0.27088 lr: 0.000054\n",
      "[26/541/259] iter:13785 accuracy:55.73 loss:0.19862 lr: 0.000054\n",
      "[26/541/269] iter:13795 accuracy:40.10 loss:0.24152 lr: 0.000054\n",
      "[26/541/279] iter:13805 accuracy:33.85 loss:0.23866 lr: 0.000054\n",
      "[26/541/289] iter:13815 accuracy:35.94 loss:0.17874 lr: 0.000054\n",
      "[26/541/299] iter:13825 accuracy:51.56 loss:0.26260 lr: 0.000054\n",
      "[26/541/309] iter:13835 accuracy:45.31 loss:0.21882 lr: 0.000054\n",
      "[26/541/319] iter:13845 accuracy:45.31 loss:0.24414 lr: 0.000054\n",
      "[26/541/329] iter:13855 accuracy:43.23 loss:0.21112 lr: 0.000054\n",
      "[26/541/339] iter:13865 accuracy:30.21 loss:0.14000 lr: 0.000054\n",
      "[26/541/349] iter:13875 accuracy:39.06 loss:0.24232 lr: 0.000054\n",
      "[26/541/359] iter:13885 accuracy:43.23 loss:0.25853 lr: 0.000054\n",
      "[26/541/369] iter:13895 accuracy:44.27 loss:0.29813 lr: 0.000054\n",
      "[26/541/379] iter:13905 accuracy:42.19 loss:0.26625 lr: 0.000054\n",
      "[26/541/389] iter:13915 accuracy:42.19 loss:0.22347 lr: 0.000054\n",
      "[26/541/399] iter:13925 accuracy:48.44 loss:0.24184 lr: 0.000054\n",
      "[26/541/409] iter:13935 accuracy:35.94 loss:0.20623 lr: 0.000054\n",
      "[26/541/419] iter:13945 accuracy:38.02 loss:0.25434 lr: 0.000054\n",
      "[26/541/429] iter:13955 accuracy:35.94 loss:0.20416 lr: 0.000054\n",
      "[26/541/439] iter:13965 accuracy:33.33 loss:0.22041 lr: 0.000054\n",
      "[26/541/449] iter:13975 accuracy:44.79 loss:0.19232 lr: 0.000054\n",
      "[26/541/459] iter:13985 accuracy:47.40 loss:0.26221 lr: 0.000054\n",
      "[26/541/469] iter:13995 accuracy:42.71 loss:0.19427 lr: 0.000054\n",
      "[26/541/479] iter:14005 accuracy:45.31 loss:0.23864 lr: 0.000054\n",
      "[26/541/489] iter:14015 accuracy:47.92 loss:0.19146 lr: 0.000054\n",
      "[26/541/499] iter:14025 accuracy:45.31 loss:0.20626 lr: 0.000054\n",
      "[26/541/509] iter:14035 accuracy:43.23 loss:0.22451 lr: 0.000054\n",
      "[26/541/519] iter:14045 accuracy:44.27 loss:0.26236 lr: 0.000054\n",
      "[26/541/529] iter:14055 accuracy:44.79 loss:0.24361 lr: 0.000054\n",
      "[26/541/539] iter:14065 accuracy:33.85 loss:0.29847 lr: 0.000054\n",
      "Epoch 26 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.476\n",
      "[5] accuracy:42.708 loss:0.292\n",
      "[10] accuracy:44.271 loss:0.438\n",
      "[15] accuracy:23.438 loss:0.366\n",
      "[20] accuracy:29.688 loss:0.389\n",
      "[25] accuracy:28.646 loss:0.438\n",
      "[30] accuracy:39.062 loss:0.286\n",
      "[35] accuracy:28.646 loss:0.440\n",
      "[40] accuracy:41.667 loss:0.274\n",
      "[45] accuracy:40.104 loss:0.430\n",
      "[50] accuracy:32.812 loss:0.499\n",
      "[55] accuracy:32.292 loss:0.371\n",
      "[60] accuracy:31.250 loss:0.369\n",
      "[65] accuracy:30.729 loss:0.417\n",
      "[70] accuracy:25.521 loss:0.369\n",
      "[75] accuracy:26.562 loss:0.378\n",
      "Result\n",
      "Train accuracy:42.70, Train loss: 0.00375, Val accuracy:31.88, Val loss: 0.00621\n",
      "Patient 9\n",
      "Epoch 27 of Train:\n",
      "[27/541/9] iter:14076 accuracy:43.23 loss:0.21493 lr: 0.000054\n",
      "[27/541/19] iter:14086 accuracy:54.69 loss:0.22839 lr: 0.000054\n",
      "[27/541/29] iter:14096 accuracy:43.23 loss:0.26240 lr: 0.000054\n",
      "[27/541/39] iter:14106 accuracy:32.29 loss:0.21219 lr: 0.000054\n",
      "[27/541/49] iter:14116 accuracy:48.44 loss:0.25582 lr: 0.000054\n",
      "[27/541/59] iter:14126 accuracy:46.35 loss:0.24087 lr: 0.000054\n",
      "[27/541/69] iter:14136 accuracy:39.06 loss:0.22668 lr: 0.000054\n",
      "[27/541/79] iter:14146 accuracy:45.83 loss:0.23601 lr: 0.000054\n",
      "[27/541/89] iter:14156 accuracy:50.52 loss:0.22616 lr: 0.000054\n",
      "[27/541/99] iter:14166 accuracy:45.83 loss:0.25608 lr: 0.000054\n",
      "[27/541/109] iter:14176 accuracy:45.83 loss:0.33666 lr: 0.000054\n",
      "[27/541/119] iter:14186 accuracy:44.79 loss:0.22482 lr: 0.000054\n",
      "[27/541/129] iter:14196 accuracy:26.04 loss:0.23084 lr: 0.000054\n",
      "[27/541/139] iter:14206 accuracy:41.67 loss:0.20496 lr: 0.000054\n",
      "[27/541/149] iter:14216 accuracy:47.40 loss:0.28565 lr: 0.000054\n",
      "[27/541/159] iter:14226 accuracy:36.98 loss:0.29509 lr: 0.000054\n",
      "[27/541/169] iter:14236 accuracy:36.46 loss:0.25378 lr: 0.000054\n",
      "[27/541/179] iter:14246 accuracy:44.27 loss:0.21724 lr: 0.000054\n",
      "[27/541/189] iter:14256 accuracy:40.62 loss:0.22038 lr: 0.000054\n",
      "[27/541/199] iter:14266 accuracy:42.71 loss:0.23791 lr: 0.000054\n",
      "[27/541/209] iter:14276 accuracy:46.35 loss:0.25709 lr: 0.000054\n",
      "[27/541/219] iter:14286 accuracy:41.67 loss:0.22563 lr: 0.000054\n",
      "[27/541/229] iter:14296 accuracy:44.27 loss:0.24060 lr: 0.000054\n",
      "[27/541/239] iter:14306 accuracy:43.75 loss:0.25912 lr: 0.000054\n",
      "[27/541/249] iter:14316 accuracy:36.46 loss:0.26183 lr: 0.000054\n",
      "[27/541/259] iter:14326 accuracy:41.67 loss:0.21531 lr: 0.000054\n",
      "[27/541/269] iter:14336 accuracy:33.85 loss:0.23890 lr: 0.000054\n",
      "[27/541/279] iter:14346 accuracy:47.92 loss:0.22218 lr: 0.000054\n",
      "[27/541/289] iter:14356 accuracy:38.02 loss:0.19015 lr: 0.000054\n",
      "[27/541/299] iter:14366 accuracy:46.35 loss:0.22588 lr: 0.000054\n",
      "[27/541/309] iter:14376 accuracy:40.62 loss:0.22668 lr: 0.000054\n",
      "[27/541/319] iter:14386 accuracy:48.96 loss:0.23141 lr: 0.000054\n",
      "[27/541/329] iter:14396 accuracy:46.88 loss:0.24017 lr: 0.000054\n",
      "[27/541/339] iter:14406 accuracy:41.15 loss:0.24569 lr: 0.000054\n",
      "[27/541/349] iter:14416 accuracy:41.67 loss:0.25663 lr: 0.000054\n",
      "[27/541/359] iter:14426 accuracy:39.58 loss:0.27980 lr: 0.000054\n",
      "[27/541/369] iter:14436 accuracy:45.31 loss:0.24298 lr: 0.000054\n",
      "[27/541/379] iter:14446 accuracy:43.75 loss:0.21917 lr: 0.000054\n",
      "[27/541/389] iter:14456 accuracy:41.67 loss:0.21811 lr: 0.000054\n",
      "[27/541/399] iter:14466 accuracy:50.52 loss:0.25201 lr: 0.000054\n",
      "[27/541/409] iter:14476 accuracy:48.44 loss:0.21433 lr: 0.000054\n",
      "[27/541/419] iter:14486 accuracy:40.10 loss:0.26784 lr: 0.000054\n",
      "[27/541/429] iter:14496 accuracy:47.40 loss:0.26395 lr: 0.000054\n",
      "[27/541/439] iter:14506 accuracy:47.40 loss:0.20619 lr: 0.000054\n",
      "[27/541/449] iter:14516 accuracy:48.96 loss:0.23153 lr: 0.000054\n",
      "[27/541/459] iter:14526 accuracy:47.92 loss:0.23911 lr: 0.000054\n",
      "[27/541/469] iter:14536 accuracy:50.00 loss:0.24306 lr: 0.000054\n",
      "[27/541/479] iter:14546 accuracy:47.40 loss:0.21434 lr: 0.000054\n",
      "[27/541/489] iter:14556 accuracy:46.88 loss:0.24540 lr: 0.000054\n",
      "[27/541/499] iter:14566 accuracy:44.27 loss:0.26611 lr: 0.000054\n",
      "[27/541/509] iter:14576 accuracy:30.21 loss:0.27483 lr: 0.000054\n",
      "[27/541/519] iter:14586 accuracy:51.04 loss:0.27299 lr: 0.000054\n",
      "[27/541/529] iter:14596 accuracy:31.25 loss:0.23167 lr: 0.000054\n",
      "[27/541/539] iter:14606 accuracy:42.19 loss:0.25688 lr: 0.000054\n",
      "Epoch 27 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.480\n",
      "[5] accuracy:42.708 loss:0.292\n",
      "[10] accuracy:45.833 loss:0.441\n",
      "[15] accuracy:22.396 loss:0.368\n",
      "[20] accuracy:31.250 loss:0.390\n",
      "[25] accuracy:29.688 loss:0.435\n",
      "[30] accuracy:39.062 loss:0.287\n",
      "[35] accuracy:28.646 loss:0.440\n",
      "[40] accuracy:40.104 loss:0.276\n",
      "[45] accuracy:40.104 loss:0.431\n",
      "[50] accuracy:31.250 loss:0.498\n",
      "[55] accuracy:32.292 loss:0.370\n",
      "[60] accuracy:31.250 loss:0.371\n",
      "[65] accuracy:29.167 loss:0.420\n",
      "[70] accuracy:25.521 loss:0.371\n",
      "[75] accuracy:26.562 loss:0.377\n",
      "Result\n",
      "Train accuracy:42.57, Train loss: 0.00373, Val accuracy:32.05, Val loss: 0.00622\n",
      "Patient 10\n",
      "Epoch 28 of Train:\n",
      "[28/541/9] iter:14617 accuracy:43.23 loss:0.25545 lr: 0.000047\n",
      "[28/541/19] iter:14627 accuracy:33.85 loss:0.26754 lr: 0.000047\n",
      "[28/541/29] iter:14637 accuracy:39.58 loss:0.16198 lr: 0.000047\n",
      "[28/541/39] iter:14647 accuracy:42.71 loss:0.28929 lr: 0.000047\n",
      "[28/541/49] iter:14657 accuracy:38.54 loss:0.18062 lr: 0.000047\n",
      "[28/541/59] iter:14667 accuracy:33.85 loss:0.24468 lr: 0.000047\n",
      "[28/541/69] iter:14677 accuracy:53.12 loss:0.25916 lr: 0.000047\n",
      "[28/541/79] iter:14687 accuracy:38.54 loss:0.23205 lr: 0.000047\n",
      "[28/541/89] iter:14697 accuracy:32.81 loss:0.24182 lr: 0.000047\n",
      "[28/541/99] iter:14707 accuracy:39.58 loss:0.21310 lr: 0.000047\n",
      "[28/541/109] iter:14717 accuracy:45.83 loss:0.28601 lr: 0.000047\n",
      "[28/541/119] iter:14727 accuracy:36.46 loss:0.22579 lr: 0.000047\n",
      "[28/541/129] iter:14737 accuracy:47.40 loss:0.20489 lr: 0.000047\n",
      "[28/541/139] iter:14747 accuracy:43.75 loss:0.21071 lr: 0.000047\n",
      "[28/541/149] iter:14757 accuracy:56.77 loss:0.26884 lr: 0.000047\n",
      "[28/541/159] iter:14767 accuracy:47.40 loss:0.25369 lr: 0.000047\n",
      "[28/541/169] iter:14777 accuracy:36.98 loss:0.25279 lr: 0.000047\n",
      "[28/541/179] iter:14787 accuracy:47.92 loss:0.23724 lr: 0.000047\n",
      "[28/541/189] iter:14797 accuracy:35.94 loss:0.22516 lr: 0.000047\n",
      "[28/541/199] iter:14807 accuracy:49.48 loss:0.25235 lr: 0.000047\n",
      "[28/541/209] iter:14817 accuracy:32.81 loss:0.22757 lr: 0.000047\n",
      "[28/541/219] iter:14827 accuracy:35.94 loss:0.25571 lr: 0.000047\n",
      "[28/541/229] iter:14837 accuracy:39.58 loss:0.17983 lr: 0.000047\n",
      "[28/541/239] iter:14847 accuracy:36.98 loss:0.26552 lr: 0.000047\n",
      "[28/541/249] iter:14857 accuracy:35.94 loss:0.27102 lr: 0.000047\n",
      "[28/541/259] iter:14867 accuracy:43.23 loss:0.19773 lr: 0.000047\n",
      "[28/541/269] iter:14877 accuracy:42.19 loss:0.24881 lr: 0.000047\n",
      "[28/541/279] iter:14887 accuracy:39.06 loss:0.27004 lr: 0.000047\n",
      "[28/541/289] iter:14897 accuracy:38.54 loss:0.27402 lr: 0.000047\n",
      "[28/541/299] iter:14907 accuracy:39.58 loss:0.22115 lr: 0.000047\n",
      "[28/541/309] iter:14917 accuracy:35.42 loss:0.27062 lr: 0.000047\n",
      "[28/541/319] iter:14927 accuracy:44.79 loss:0.19778 lr: 0.000047\n",
      "[28/541/329] iter:14937 accuracy:41.15 loss:0.20879 lr: 0.000047\n",
      "[28/541/339] iter:14947 accuracy:42.19 loss:0.27772 lr: 0.000047\n",
      "[28/541/349] iter:14957 accuracy:44.79 loss:0.29410 lr: 0.000047\n",
      "[28/541/359] iter:14967 accuracy:42.19 loss:0.23381 lr: 0.000047\n",
      "[28/541/369] iter:14977 accuracy:34.90 loss:0.23054 lr: 0.000047\n",
      "[28/541/379] iter:14987 accuracy:35.94 loss:0.24824 lr: 0.000047\n",
      "[28/541/389] iter:14997 accuracy:40.10 loss:0.28081 lr: 0.000047\n",
      "[28/541/399] iter:15007 accuracy:54.17 loss:0.21789 lr: 0.000047\n",
      "[28/541/409] iter:15017 accuracy:43.75 loss:0.23457 lr: 0.000047\n",
      "[28/541/419] iter:15027 accuracy:48.44 loss:0.20110 lr: 0.000047\n",
      "[28/541/429] iter:15037 accuracy:36.98 loss:0.21373 lr: 0.000047\n",
      "[28/541/439] iter:15047 accuracy:49.48 loss:0.21262 lr: 0.000047\n",
      "[28/541/449] iter:15057 accuracy:40.10 loss:0.17702 lr: 0.000047\n",
      "[28/541/459] iter:15067 accuracy:39.58 loss:0.20284 lr: 0.000047\n",
      "[28/541/469] iter:15077 accuracy:51.04 loss:0.23521 lr: 0.000047\n",
      "[28/541/479] iter:15087 accuracy:38.54 loss:0.24178 lr: 0.000047\n",
      "[28/541/489] iter:15097 accuracy:47.40 loss:0.19791 lr: 0.000047\n",
      "[28/541/499] iter:15107 accuracy:46.35 loss:0.20443 lr: 0.000047\n",
      "[28/541/509] iter:15117 accuracy:33.85 loss:0.21253 lr: 0.000047\n",
      "[28/541/519] iter:15127 accuracy:29.69 loss:0.26112 lr: 0.000047\n",
      "[28/541/529] iter:15137 accuracy:38.54 loss:0.24924 lr: 0.000047\n",
      "[28/541/539] iter:15147 accuracy:45.31 loss:0.25614 lr: 0.000047\n",
      "Epoch 28 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.478\n",
      "[5] accuracy:44.271 loss:0.292\n",
      "[10] accuracy:44.271 loss:0.440\n",
      "[15] accuracy:23.958 loss:0.365\n",
      "[20] accuracy:31.250 loss:0.389\n",
      "[25] accuracy:30.208 loss:0.435\n",
      "[30] accuracy:40.625 loss:0.286\n",
      "[35] accuracy:28.646 loss:0.440\n",
      "[40] accuracy:37.500 loss:0.276\n",
      "[45] accuracy:40.104 loss:0.429\n",
      "[50] accuracy:32.812 loss:0.497\n",
      "[55] accuracy:32.292 loss:0.370\n",
      "[60] accuracy:29.688 loss:0.372\n",
      "[65] accuracy:30.729 loss:0.419\n",
      "[70] accuracy:25.521 loss:0.370\n",
      "[75] accuracy:26.562 loss:0.377\n",
      "Result\n",
      "Train accuracy:42.84, Train loss: 0.00372, Val accuracy:31.94, Val loss: 0.00621\n",
      "Patient 11\n",
      "Epoch 29 of Train:\n",
      "[29/541/9] iter:15158 accuracy:39.58 loss:0.27393 lr: 0.000047\n",
      "[29/541/19] iter:15168 accuracy:42.19 loss:0.27099 lr: 0.000047\n",
      "[29/541/29] iter:15178 accuracy:39.06 loss:0.24592 lr: 0.000047\n",
      "[29/541/39] iter:15188 accuracy:42.71 loss:0.27516 lr: 0.000047\n",
      "[29/541/49] iter:15198 accuracy:45.31 loss:0.23080 lr: 0.000047\n",
      "[29/541/59] iter:15208 accuracy:55.21 loss:0.23467 lr: 0.000047\n",
      "[29/541/69] iter:15218 accuracy:46.35 loss:0.19616 lr: 0.000047\n",
      "[29/541/79] iter:15228 accuracy:41.67 loss:0.18280 lr: 0.000047\n",
      "[29/541/89] iter:15238 accuracy:41.15 loss:0.17664 lr: 0.000047\n",
      "[29/541/99] iter:15248 accuracy:41.15 loss:0.18822 lr: 0.000047\n",
      "[29/541/109] iter:15258 accuracy:40.10 loss:0.25097 lr: 0.000047\n",
      "[29/541/119] iter:15268 accuracy:45.31 loss:0.24526 lr: 0.000047\n",
      "[29/541/129] iter:15278 accuracy:37.50 loss:0.18636 lr: 0.000047\n",
      "[29/541/139] iter:15288 accuracy:38.54 loss:0.31448 lr: 0.000047\n",
      "[29/541/149] iter:15298 accuracy:38.54 loss:0.20283 lr: 0.000047\n",
      "[29/541/159] iter:15308 accuracy:52.60 loss:0.15974 lr: 0.000047\n",
      "[29/541/169] iter:15318 accuracy:50.00 loss:0.24983 lr: 0.000047\n",
      "[29/541/179] iter:15328 accuracy:43.23 loss:0.27351 lr: 0.000047\n",
      "[29/541/189] iter:15338 accuracy:41.67 loss:0.19366 lr: 0.000047\n",
      "[29/541/199] iter:15348 accuracy:43.75 loss:0.24330 lr: 0.000047\n",
      "[29/541/209] iter:15358 accuracy:46.88 loss:0.24483 lr: 0.000047\n",
      "[29/541/219] iter:15368 accuracy:44.79 loss:0.21682 lr: 0.000047\n",
      "[29/541/229] iter:15378 accuracy:36.98 loss:0.24409 lr: 0.000047\n",
      "[29/541/239] iter:15388 accuracy:40.62 loss:0.24215 lr: 0.000047\n",
      "[29/541/249] iter:15398 accuracy:50.00 loss:0.22440 lr: 0.000047\n",
      "[29/541/259] iter:15408 accuracy:42.19 loss:0.22440 lr: 0.000047\n",
      "[29/541/269] iter:15418 accuracy:48.44 loss:0.27241 lr: 0.000047\n",
      "[29/541/279] iter:15428 accuracy:37.50 loss:0.19609 lr: 0.000047\n",
      "[29/541/289] iter:15438 accuracy:41.67 loss:0.17754 lr: 0.000047\n",
      "[29/541/299] iter:15448 accuracy:35.94 loss:0.20065 lr: 0.000047\n",
      "[29/541/309] iter:15458 accuracy:50.00 loss:0.24859 lr: 0.000047\n",
      "[29/541/319] iter:15468 accuracy:41.15 loss:0.19990 lr: 0.000047\n",
      "[29/541/329] iter:15478 accuracy:39.58 loss:0.23528 lr: 0.000047\n",
      "[29/541/339] iter:15488 accuracy:41.15 loss:0.25132 lr: 0.000047\n",
      "[29/541/349] iter:15498 accuracy:40.62 loss:0.17766 lr: 0.000047\n",
      "[29/541/359] iter:15508 accuracy:46.88 loss:0.21451 lr: 0.000047\n",
      "[29/541/369] iter:15518 accuracy:55.21 loss:0.16825 lr: 0.000047\n",
      "[29/541/379] iter:15528 accuracy:44.27 loss:0.25133 lr: 0.000047\n",
      "[29/541/389] iter:15538 accuracy:49.48 loss:0.24577 lr: 0.000047\n",
      "[29/541/399] iter:15548 accuracy:46.88 loss:0.23438 lr: 0.000047\n",
      "[29/541/409] iter:15558 accuracy:48.44 loss:0.25150 lr: 0.000047\n",
      "[29/541/419] iter:15568 accuracy:42.71 loss:0.23193 lr: 0.000047\n",
      "[29/541/429] iter:15578 accuracy:47.92 loss:0.25419 lr: 0.000047\n",
      "[29/541/439] iter:15588 accuracy:50.52 loss:0.29248 lr: 0.000047\n",
      "[29/541/449] iter:15598 accuracy:39.58 loss:0.18943 lr: 0.000047\n",
      "[29/541/459] iter:15608 accuracy:46.35 loss:0.22485 lr: 0.000047\n",
      "[29/541/469] iter:15618 accuracy:46.35 loss:0.21863 lr: 0.000047\n",
      "[29/541/479] iter:15628 accuracy:37.50 loss:0.20797 lr: 0.000047\n",
      "[29/541/489] iter:15638 accuracy:36.98 loss:0.22531 lr: 0.000047\n",
      "[29/541/499] iter:15648 accuracy:43.23 loss:0.26097 lr: 0.000047\n",
      "[29/541/509] iter:15658 accuracy:36.46 loss:0.21557 lr: 0.000047\n",
      "[29/541/519] iter:15668 accuracy:39.58 loss:0.23184 lr: 0.000047\n",
      "[29/541/529] iter:15678 accuracy:46.88 loss:0.24219 lr: 0.000047\n",
      "[29/541/539] iter:15688 accuracy:39.58 loss:0.26921 lr: 0.000047\n",
      "Epoch 29 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.477\n",
      "[5] accuracy:42.708 loss:0.293\n",
      "[10] accuracy:44.792 loss:0.439\n",
      "[15] accuracy:25.521 loss:0.367\n",
      "[20] accuracy:29.688 loss:0.391\n",
      "[25] accuracy:28.125 loss:0.432\n",
      "[30] accuracy:39.062 loss:0.289\n",
      "[35] accuracy:28.646 loss:0.441\n",
      "[40] accuracy:39.062 loss:0.274\n",
      "[45] accuracy:40.104 loss:0.428\n",
      "[50] accuracy:31.250 loss:0.500\n",
      "[55] accuracy:32.292 loss:0.372\n",
      "[60] accuracy:29.688 loss:0.371\n",
      "[65] accuracy:30.729 loss:0.419\n",
      "[70] accuracy:25.521 loss:0.373\n",
      "[75] accuracy:26.562 loss:0.376\n",
      "Result\n",
      "Train accuracy:42.68, Train loss: 0.00371, Val accuracy:32.07, Val loss: 0.00623\n",
      "Patient 12\n",
      "Epoch 30 of Train:\n",
      "[30/541/9] iter:15699 accuracy:39.58 loss:0.30765 lr: 0.000042\n",
      "[30/541/19] iter:15709 accuracy:46.88 loss:0.23829 lr: 0.000042\n",
      "[30/541/29] iter:15719 accuracy:44.27 loss:0.26594 lr: 0.000042\n",
      "[30/541/39] iter:15729 accuracy:46.35 loss:0.21835 lr: 0.000042\n",
      "[30/541/49] iter:15739 accuracy:38.54 loss:0.23903 lr: 0.000042\n",
      "[30/541/59] iter:15749 accuracy:46.35 loss:0.25731 lr: 0.000042\n",
      "[30/541/69] iter:15759 accuracy:44.79 loss:0.22696 lr: 0.000042\n",
      "[30/541/79] iter:15769 accuracy:51.04 loss:0.29262 lr: 0.000042\n",
      "[30/541/89] iter:15779 accuracy:40.10 loss:0.21918 lr: 0.000042\n",
      "[30/541/99] iter:15789 accuracy:40.10 loss:0.23363 lr: 0.000042\n",
      "[30/541/109] iter:15799 accuracy:32.29 loss:0.24855 lr: 0.000042\n",
      "[30/541/119] iter:15809 accuracy:42.19 loss:0.29177 lr: 0.000042\n",
      "[30/541/129] iter:15819 accuracy:38.02 loss:0.22735 lr: 0.000042\n",
      "[30/541/139] iter:15829 accuracy:37.50 loss:0.23440 lr: 0.000042\n",
      "[30/541/149] iter:15839 accuracy:43.23 loss:0.19433 lr: 0.000042\n",
      "[30/541/159] iter:15849 accuracy:42.19 loss:0.23059 lr: 0.000042\n",
      "[30/541/169] iter:15859 accuracy:41.67 loss:0.21568 lr: 0.000042\n",
      "[30/541/179] iter:15869 accuracy:46.88 loss:0.22404 lr: 0.000042\n",
      "[30/541/189] iter:15879 accuracy:50.52 loss:0.25607 lr: 0.000042\n",
      "[30/541/199] iter:15889 accuracy:50.00 loss:0.22959 lr: 0.000042\n",
      "[30/541/209] iter:15899 accuracy:43.75 loss:0.25371 lr: 0.000042\n",
      "[30/541/219] iter:15909 accuracy:39.06 loss:0.25847 lr: 0.000042\n",
      "[30/541/229] iter:15919 accuracy:46.35 loss:0.19520 lr: 0.000042\n",
      "[30/541/239] iter:15929 accuracy:50.00 loss:0.27373 lr: 0.000042\n",
      "[30/541/249] iter:15939 accuracy:44.79 loss:0.19446 lr: 0.000042\n",
      "[30/541/259] iter:15949 accuracy:43.75 loss:0.29737 lr: 0.000042\n",
      "[30/541/269] iter:15959 accuracy:36.98 loss:0.28547 lr: 0.000042\n",
      "[30/541/279] iter:15969 accuracy:46.88 loss:0.23991 lr: 0.000042\n",
      "[30/541/289] iter:15979 accuracy:44.27 loss:0.26025 lr: 0.000042\n",
      "[30/541/299] iter:15989 accuracy:39.06 loss:0.27690 lr: 0.000042\n",
      "[30/541/309] iter:15999 accuracy:38.54 loss:0.26342 lr: 0.000042\n",
      "[30/541/319] iter:16009 accuracy:33.85 loss:0.23958 lr: 0.000042\n",
      "[30/541/329] iter:16019 accuracy:37.50 loss:0.21797 lr: 0.000042\n",
      "[30/541/339] iter:16029 accuracy:46.35 loss:0.25377 lr: 0.000042\n",
      "[30/541/349] iter:16039 accuracy:47.40 loss:0.22202 lr: 0.000042\n",
      "[30/541/359] iter:16049 accuracy:43.75 loss:0.23695 lr: 0.000042\n",
      "[30/541/369] iter:16059 accuracy:41.67 loss:0.24438 lr: 0.000042\n",
      "[30/541/379] iter:16069 accuracy:32.29 loss:0.22018 lr: 0.000042\n",
      "[30/541/389] iter:16079 accuracy:56.77 loss:0.26078 lr: 0.000042\n",
      "[30/541/399] iter:16089 accuracy:34.38 loss:0.25184 lr: 0.000042\n",
      "[30/541/409] iter:16099 accuracy:33.85 loss:0.24921 lr: 0.000042\n",
      "[30/541/419] iter:16109 accuracy:40.63 loss:0.23239 lr: 0.000042\n",
      "[30/541/429] iter:16119 accuracy:44.79 loss:0.25555 lr: 0.000042\n",
      "[30/541/439] iter:16129 accuracy:35.94 loss:0.26055 lr: 0.000042\n",
      "[30/541/449] iter:16139 accuracy:39.58 loss:0.19739 lr: 0.000042\n",
      "[30/541/459] iter:16149 accuracy:51.04 loss:0.20528 lr: 0.000042\n",
      "[30/541/469] iter:16159 accuracy:36.98 loss:0.21214 lr: 0.000042\n",
      "[30/541/479] iter:16169 accuracy:44.27 loss:0.23481 lr: 0.000042\n",
      "[30/541/489] iter:16179 accuracy:56.77 loss:0.23472 lr: 0.000042\n",
      "[30/541/499] iter:16189 accuracy:45.31 loss:0.17587 lr: 0.000042\n",
      "[30/541/509] iter:16199 accuracy:42.19 loss:0.19653 lr: 0.000042\n",
      "[30/541/519] iter:16209 accuracy:31.25 loss:0.22375 lr: 0.000042\n",
      "[30/541/529] iter:16219 accuracy:43.23 loss:0.27402 lr: 0.000042\n",
      "[30/541/539] iter:16229 accuracy:44.79 loss:0.22702 lr: 0.000042\n",
      "Epoch 30 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.478\n",
      "[5] accuracy:42.708 loss:0.293\n",
      "[10] accuracy:44.271 loss:0.440\n",
      "[15] accuracy:25.521 loss:0.365\n",
      "[20] accuracy:31.250 loss:0.389\n",
      "[25] accuracy:28.125 loss:0.433\n",
      "[30] accuracy:39.062 loss:0.287\n",
      "[35] accuracy:28.646 loss:0.441\n",
      "[40] accuracy:37.500 loss:0.274\n",
      "[45] accuracy:40.104 loss:0.429\n",
      "[50] accuracy:31.250 loss:0.497\n",
      "[55] accuracy:32.292 loss:0.370\n",
      "[60] accuracy:29.688 loss:0.372\n",
      "[65] accuracy:29.167 loss:0.417\n",
      "[70] accuracy:25.521 loss:0.371\n",
      "[75] accuracy:26.042 loss:0.377\n",
      "Result\n",
      "Train accuracy:42.77, Train loss: 0.00370, Val accuracy:31.99, Val loss: 0.00622\n",
      "Patient 13\n",
      "Epoch 31 of Train:\n",
      "[31/541/9] iter:16240 accuracy:46.88 loss:0.25231 lr: 0.000042\n",
      "[31/541/19] iter:16250 accuracy:31.25 loss:0.21687 lr: 0.000042\n",
      "[31/541/29] iter:16260 accuracy:47.92 loss:0.23703 lr: 0.000042\n",
      "[31/541/39] iter:16270 accuracy:34.90 loss:0.23835 lr: 0.000042\n",
      "[31/541/49] iter:16280 accuracy:39.06 loss:0.24263 lr: 0.000042\n",
      "[31/541/59] iter:16290 accuracy:43.23 loss:0.22073 lr: 0.000042\n",
      "[31/541/69] iter:16300 accuracy:41.15 loss:0.22536 lr: 0.000042\n",
      "[31/541/79] iter:16310 accuracy:47.40 loss:0.24032 lr: 0.000042\n",
      "[31/541/89] iter:16320 accuracy:38.02 loss:0.21071 lr: 0.000042\n",
      "[31/541/99] iter:16330 accuracy:38.02 loss:0.24853 lr: 0.000042\n",
      "[31/541/109] iter:16340 accuracy:31.25 loss:0.22599 lr: 0.000042\n",
      "[31/541/119] iter:16350 accuracy:43.23 loss:0.19412 lr: 0.000042\n",
      "[31/541/129] iter:16360 accuracy:43.75 loss:0.24533 lr: 0.000042\n",
      "[31/541/139] iter:16370 accuracy:28.12 loss:0.23198 lr: 0.000042\n",
      "[31/541/149] iter:16380 accuracy:35.42 loss:0.20866 lr: 0.000042\n",
      "[31/541/159] iter:16390 accuracy:42.71 loss:0.22258 lr: 0.000042\n",
      "[31/541/169] iter:16400 accuracy:47.92 loss:0.18550 lr: 0.000042\n",
      "[31/541/179] iter:16410 accuracy:51.04 loss:0.18751 lr: 0.000042\n",
      "[31/541/189] iter:16420 accuracy:35.94 loss:0.21773 lr: 0.000042\n",
      "[31/541/199] iter:16430 accuracy:47.40 loss:0.21765 lr: 0.000042\n",
      "[31/541/209] iter:16440 accuracy:34.90 loss:0.25059 lr: 0.000042\n",
      "[31/541/219] iter:16450 accuracy:50.52 loss:0.22588 lr: 0.000042\n",
      "[31/541/229] iter:16460 accuracy:50.52 loss:0.21423 lr: 0.000042\n",
      "[31/541/239] iter:16470 accuracy:55.73 loss:0.27452 lr: 0.000042\n",
      "[31/541/249] iter:16480 accuracy:44.79 loss:0.25016 lr: 0.000042\n",
      "[31/541/259] iter:16490 accuracy:41.67 loss:0.22326 lr: 0.000042\n",
      "[31/541/269] iter:16500 accuracy:52.08 loss:0.19364 lr: 0.000042\n",
      "[31/541/279] iter:16510 accuracy:48.44 loss:0.24976 lr: 0.000042\n",
      "[31/541/289] iter:16520 accuracy:36.98 loss:0.21273 lr: 0.000042\n",
      "[31/541/299] iter:16530 accuracy:47.40 loss:0.24050 lr: 0.000042\n",
      "[31/541/309] iter:16540 accuracy:38.02 loss:0.24723 lr: 0.000042\n",
      "[31/541/319] iter:16550 accuracy:41.67 loss:0.24891 lr: 0.000042\n",
      "[31/541/329] iter:16560 accuracy:40.10 loss:0.20684 lr: 0.000042\n",
      "[31/541/339] iter:16570 accuracy:47.92 loss:0.20993 lr: 0.000042\n",
      "[31/541/349] iter:16580 accuracy:48.44 loss:0.24157 lr: 0.000042\n",
      "[31/541/359] iter:16590 accuracy:40.62 loss:0.23300 lr: 0.000042\n",
      "[31/541/369] iter:16600 accuracy:42.71 loss:0.26254 lr: 0.000042\n",
      "[31/541/379] iter:16610 accuracy:48.96 loss:0.23197 lr: 0.000042\n",
      "[31/541/389] iter:16620 accuracy:38.02 loss:0.19603 lr: 0.000042\n",
      "[31/541/399] iter:16630 accuracy:33.85 loss:0.19101 lr: 0.000042\n",
      "[31/541/409] iter:16640 accuracy:41.15 loss:0.20683 lr: 0.000042\n",
      "[31/541/419] iter:16650 accuracy:43.75 loss:0.22455 lr: 0.000042\n",
      "[31/541/429] iter:16660 accuracy:48.44 loss:0.27531 lr: 0.000042\n",
      "[31/541/439] iter:16670 accuracy:58.33 loss:0.22210 lr: 0.000042\n",
      "[31/541/449] iter:16680 accuracy:40.63 loss:0.21676 lr: 0.000042\n",
      "[31/541/459] iter:16690 accuracy:55.73 loss:0.26916 lr: 0.000042\n",
      "[31/541/469] iter:16700 accuracy:39.58 loss:0.23940 lr: 0.000042\n",
      "[31/541/479] iter:16710 accuracy:43.23 loss:0.21444 lr: 0.000042\n",
      "[31/541/489] iter:16720 accuracy:47.92 loss:0.30371 lr: 0.000042\n",
      "[31/541/499] iter:16730 accuracy:33.33 loss:0.26305 lr: 0.000042\n",
      "[31/541/509] iter:16740 accuracy:42.19 loss:0.23420 lr: 0.000042\n",
      "[31/541/519] iter:16750 accuracy:45.31 loss:0.18823 lr: 0.000042\n",
      "[31/541/529] iter:16760 accuracy:45.83 loss:0.26314 lr: 0.000042\n",
      "[31/541/539] iter:16770 accuracy:42.71 loss:0.29308 lr: 0.000042\n",
      "Epoch 31 of Valuation:\n",
      "[0] accuracy:23.958 loss:0.481\n",
      "[5] accuracy:42.708 loss:0.293\n",
      "[10] accuracy:44.271 loss:0.445\n",
      "[15] accuracy:23.958 loss:0.369\n",
      "[20] accuracy:29.688 loss:0.389\n",
      "[25] accuracy:29.688 loss:0.437\n",
      "[30] accuracy:39.062 loss:0.288\n",
      "[35] accuracy:28.646 loss:0.441\n",
      "[40] accuracy:37.500 loss:0.274\n",
      "[45] accuracy:40.104 loss:0.432\n",
      "[50] accuracy:31.771 loss:0.501\n",
      "[55] accuracy:33.854 loss:0.374\n",
      "[60] accuracy:31.250 loss:0.373\n",
      "[65] accuracy:29.167 loss:0.422\n",
      "[70] accuracy:25.521 loss:0.374\n",
      "[75] accuracy:26.562 loss:0.379\n",
      "Result\n",
      "Train accuracy:42.91, Train loss: 0.00368, Val accuracy:32.03, Val loss: 0.00626\n",
      "Patient 14\n",
      "Epoch 32 of Train:\n",
      "[32/541/9] iter:16781 accuracy:33.85 loss:0.25621 lr: 0.000038\n",
      "[32/541/19] iter:16791 accuracy:46.35 loss:0.19510 lr: 0.000038\n",
      "[32/541/29] iter:16801 accuracy:34.90 loss:0.24828 lr: 0.000038\n",
      "[32/541/39] iter:16811 accuracy:36.46 loss:0.25233 lr: 0.000038\n",
      "[32/541/49] iter:16821 accuracy:38.54 loss:0.26381 lr: 0.000038\n",
      "[32/541/59] iter:16831 accuracy:48.44 loss:0.25825 lr: 0.000038\n",
      "[32/541/69] iter:16841 accuracy:31.25 loss:0.23063 lr: 0.000038\n",
      "[32/541/79] iter:16851 accuracy:45.83 loss:0.24884 lr: 0.000038\n",
      "[32/541/89] iter:16861 accuracy:36.98 loss:0.23411 lr: 0.000038\n",
      "[32/541/99] iter:16871 accuracy:40.62 loss:0.25919 lr: 0.000038\n",
      "[32/541/109] iter:16881 accuracy:41.15 loss:0.20564 lr: 0.000038\n",
      "[32/541/119] iter:16891 accuracy:39.06 loss:0.25702 lr: 0.000038\n",
      "[32/541/129] iter:16901 accuracy:46.35 loss:0.25885 lr: 0.000038\n",
      "[32/541/139] iter:16911 accuracy:46.88 loss:0.30230 lr: 0.000038\n",
      "[32/541/149] iter:16921 accuracy:47.40 loss:0.21226 lr: 0.000038\n",
      "[32/541/159] iter:16931 accuracy:38.54 loss:0.24685 lr: 0.000038\n",
      "[32/541/169] iter:16941 accuracy:49.48 loss:0.23661 lr: 0.000038\n",
      "[32/541/179] iter:16951 accuracy:46.88 loss:0.22378 lr: 0.000038\n",
      "[32/541/189] iter:16961 accuracy:46.35 loss:0.25350 lr: 0.000038\n",
      "[32/541/199] iter:16971 accuracy:46.35 loss:0.22485 lr: 0.000038\n",
      "[32/541/209] iter:16981 accuracy:49.48 loss:0.23426 lr: 0.000038\n",
      "[32/541/219] iter:16991 accuracy:36.98 loss:0.27000 lr: 0.000038\n",
      "[32/541/229] iter:17001 accuracy:38.02 loss:0.27153 lr: 0.000038\n",
      "[32/541/239] iter:17011 accuracy:48.44 loss:0.21491 lr: 0.000038\n",
      "[32/541/249] iter:17021 accuracy:44.79 loss:0.20660 lr: 0.000038\n",
      "[32/541/259] iter:17031 accuracy:44.79 loss:0.19245 lr: 0.000038\n",
      "[32/541/269] iter:17041 accuracy:49.48 loss:0.25492 lr: 0.000038\n",
      "[32/541/279] iter:17051 accuracy:43.75 loss:0.23655 lr: 0.000038\n",
      "[32/541/289] iter:17061 accuracy:41.67 loss:0.25242 lr: 0.000038\n",
      "[32/541/299] iter:17071 accuracy:36.98 loss:0.26337 lr: 0.000038\n",
      "[32/541/309] iter:17081 accuracy:48.44 loss:0.24254 lr: 0.000038\n",
      "[32/541/319] iter:17091 accuracy:54.69 loss:0.21779 lr: 0.000038\n",
      "[32/541/329] iter:17101 accuracy:58.33 loss:0.23395 lr: 0.000038\n",
      "[32/541/339] iter:17111 accuracy:43.23 loss:0.25501 lr: 0.000038\n",
      "[32/541/349] iter:17121 accuracy:48.96 loss:0.22454 lr: 0.000038\n",
      "[32/541/359] iter:17131 accuracy:38.54 loss:0.23522 lr: 0.000038\n",
      "[32/541/369] iter:17141 accuracy:41.67 loss:0.23718 lr: 0.000038\n",
      "[32/541/379] iter:17151 accuracy:39.58 loss:0.19970 lr: 0.000038\n",
      "[32/541/389] iter:17161 accuracy:43.75 loss:0.27216 lr: 0.000038\n",
      "[32/541/399] iter:17171 accuracy:47.40 loss:0.29405 lr: 0.000038\n",
      "[32/541/409] iter:17181 accuracy:46.88 loss:0.24991 lr: 0.000038\n",
      "[32/541/419] iter:17191 accuracy:38.54 loss:0.22759 lr: 0.000038\n",
      "[32/541/429] iter:17201 accuracy:39.06 loss:0.21237 lr: 0.000038\n",
      "[32/541/439] iter:17211 accuracy:45.83 loss:0.26306 lr: 0.000038\n",
      "[32/541/449] iter:17221 accuracy:42.19 loss:0.20486 lr: 0.000038\n",
      "[32/541/459] iter:17231 accuracy:41.67 loss:0.24324 lr: 0.000038\n",
      "[32/541/469] iter:17241 accuracy:50.00 loss:0.18875 lr: 0.000038\n",
      "[32/541/479] iter:17251 accuracy:32.81 loss:0.26596 lr: 0.000038\n",
      "[32/541/489] iter:17261 accuracy:37.50 loss:0.24878 lr: 0.000038\n",
      "[32/541/499] iter:17271 accuracy:49.48 loss:0.25638 lr: 0.000038\n",
      "[32/541/509] iter:17281 accuracy:41.15 loss:0.22876 lr: 0.000038\n",
      "[32/541/519] iter:17291 accuracy:35.94 loss:0.23812 lr: 0.000038\n",
      "[32/541/529] iter:17301 accuracy:46.35 loss:0.27153 lr: 0.000038\n",
      "[32/541/539] iter:17311 accuracy:40.62 loss:0.18032 lr: 0.000038\n",
      "Epoch 32 of Valuation:\n",
      "[0] accuracy:25.521 loss:0.477\n",
      "[5] accuracy:44.271 loss:0.293\n",
      "[10] accuracy:44.271 loss:0.445\n",
      "[15] accuracy:23.958 loss:0.366\n",
      "[20] accuracy:29.688 loss:0.392\n",
      "[25] accuracy:29.688 loss:0.436\n",
      "[30] accuracy:39.062 loss:0.290\n",
      "[35] accuracy:28.646 loss:0.442\n",
      "[40] accuracy:37.500 loss:0.275\n",
      "[45] accuracy:40.104 loss:0.433\n",
      "[50] accuracy:31.250 loss:0.503\n",
      "[55] accuracy:33.854 loss:0.374\n",
      "[60] accuracy:31.250 loss:0.373\n",
      "[65] accuracy:29.167 loss:0.423\n",
      "[70] accuracy:25.521 loss:0.373\n",
      "[75] accuracy:26.562 loss:0.381\n",
      "Result\n",
      "Train accuracy:43.01, Train loss: 0.00369, Val accuracy:32.03, Val loss: 0.00625\n",
      "Patient 15 early stop!!\n",
      "best val accuracy : 32.31 at 17 epoch. \n",
      "compute val result !\n",
      "[0/79]\n",
      "[10/79]\n",
      "[20/79]\n",
      "[30/79]\n",
      "[40/79]\n",
      "[50/79]\n",
      "[60/79]\n",
      "[70/79]\n",
      "val score: 32.31\n",
      "Statistic Result:\n",
      "ocr: 2871, correct: 1150, ratio：40.06 \n",
      "classifier: 2129, correct: 671, ratio：31.52 \n",
      "accuracy 32.31\n",
      "computing result compelet!\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python run.py --config options/al/exp_1_20_1.yaml --is_train True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_pt4]",
   "language": "python",
   "name": "conda-env-py3_pt4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
