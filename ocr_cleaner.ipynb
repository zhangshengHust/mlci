{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw ,ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../data/imdb/textvqa_0.5/imdb_textvqa_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取图像的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(dataset, image_id):\n",
    "    image_dir = '/home/data/textvqa/' + ('train' if dataset == 'train' or dataset == 'val' else 'test') + '_images/'\n",
    "    image = Image.open(image_dir + image_id + '.jpg')\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 画图像的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(dataset, image_id):\n",
    "    \n",
    "    # 获取图像\n",
    "    image = get_image(dataset, image_id)\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "#     for i in range(bb.shape[0]):\n",
    "#         at1 = x_in_top(i,ind[:,0]) \n",
    "#         at2 = x_in_top(i,ind[:,1])\n",
    "#         if at1 or at2:\n",
    "#             color = get_color()\n",
    "#         else:\n",
    "#             continue\n",
    "#         draw.rectangle((bb[i][0]*image.width,bb[i][1]*image.height,bb[i][2]*image.width,bb[i][3]*image.height), outline=color,width=3)\n",
    "#     image.save(save_dir+str(index)+'_'+image_name)\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test： 画一张图片\n",
    "draw_image('val', '831bcec304a17054')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把所有的图片保存成jpg格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本检测\n",
    "   dataset：numpy.ndarray, 里面都是字典类型（每张图对应一个dict）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_index in range(1, len(dataset)):\n",
    "for image_index in range(1, 2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from nets import model_train as model\n",
    "from utils.rpn_msr.proposal_layer import proposal_layer\n",
    "from utils.text_connector.detectors import TextDetector\n",
    "\n",
    "tf.app.flags.DEFINE_string('test_data_path', 'data/demo/', '')\n",
    "tf.app.flags.DEFINE_string('output_path', 'data/res/', '')\n",
    "tf.app.flags.DEFINE_string('gpu', '0', '')\n",
    "tf.app.flags.DEFINE_string('checkpoint_path', 'checkpoints_mlt/', '')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "def get_images():\n",
    "    files = []\n",
    "    exts = ['jpg', 'png', 'jpeg', 'JPG']\n",
    "    for parent, dirnames, filenames in os.walk(FLAGS.test_data_path):\n",
    "        for filename in filenames:\n",
    "            for ext in exts:\n",
    "                if filename.endswith(ext):\n",
    "                    files.append(os.path.join(parent, filename))\n",
    "                    break\n",
    "    print('Find {} images'.format(len(files)))\n",
    "    return files\n",
    "\n",
    "\n",
    "def resize_image(img):\n",
    "    img_size = img.shape\n",
    "    im_size_min = np.min(img_size[0:2])\n",
    "    im_size_max = np.max(img_size[0:2])\n",
    "\n",
    "    im_scale = float(600) / float(im_size_min)\n",
    "    if np.round(im_scale * im_size_max) > 1200:\n",
    "        im_scale = float(1200) / float(im_size_max)\n",
    "    new_h = int(img_size[0] * im_scale)\n",
    "    new_w = int(img_size[1] * im_scale)\n",
    "\n",
    "    new_h = new_h if new_h // 16 == 0 else (new_h // 16 + 1) * 16\n",
    "    new_w = new_w if new_w // 16 == 0 else (new_w // 16 + 1) * 16\n",
    "\n",
    "    re_im = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "    return re_im, (new_h / img_size[0], new_w / img_size[1])\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    if os.path.exists(FLAGS.output_path):\n",
    "        shutil.rmtree(FLAGS.output_path)\n",
    "    os.makedirs(FLAGS.output_path)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "\n",
    "    with tf.get_default_graph().as_default():\n",
    "        input_image = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_image')\n",
    "        input_im_info = tf.placeholder(tf.float32, shape=[None, 3], name='input_im_info')\n",
    "\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        bbox_pred, cls_pred, cls_prob = model.model(input_image)\n",
    "\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)\n",
    "        saver = tf.train.Saver(variable_averages.variables_to_restore())\n",
    "\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            ckpt_state = tf.train.get_checkpoint_state(FLAGS.checkpoint_path)\n",
    "            model_path = os.path.join(FLAGS.checkpoint_path, os.path.basename(ckpt_state.model_checkpoint_path))\n",
    "            print('Restore from {}'.format(model_path))\n",
    "            saver.restore(sess, model_path)\n",
    "\n",
    "            im_fn_list = get_images()\n",
    "            for im_fn in im_fn_list:\n",
    "                print('===============')\n",
    "                print(im_fn)\n",
    "                start = time.time()\n",
    "                try:\n",
    "                    im = cv2.imread(im_fn)[:, :, ::-1]\n",
    "                except:\n",
    "                    print(\"Error reading image {}!\".format(im_fn))\n",
    "                    continue\n",
    "\n",
    "                img, (rh, rw) = resize_image(im)\n",
    "                h, w, c = img.shape\n",
    "                im_info = np.array([h, w, c]).reshape([1, 3])\n",
    "                bbox_pred_val, cls_prob_val = sess.run([bbox_pred, cls_prob],\n",
    "                                                       feed_dict={input_image: [img],\n",
    "                                                                  input_im_info: im_info})\n",
    "\n",
    "                textsegs, _ = proposal_layer(cls_prob_val, bbox_pred_val, im_info)\n",
    "                scores = textsegs[:, 0]\n",
    "                textsegs = textsegs[:, 1:5]\n",
    "\n",
    "                textdetector = TextDetector(DETECT_MODE='H')\n",
    "                boxes = textdetector.detect(textsegs, scores[:, np.newaxis], img.shape[:2])\n",
    "                boxes = np.array(boxes, dtype=np.int)\n",
    "\n",
    "                cost_time = (time.time() - start)\n",
    "                print(\"cost time: {:.2f}s\".format(cost_time))\n",
    "\n",
    "                for i, box in enumerate(boxes):\n",
    "                    cv2.polylines(img, [box[:8].astype(np.int32).reshape((-1, 1, 2))], True, color=(0, 255, 0),\n",
    "                                  thickness=2)\n",
    "                img = cv2.resize(img, None, None, fx=1.0 / rh, fy=1.0 / rw, interpolation=cv2.INTER_LINEAR)\n",
    "                cv2.imwrite(os.path.join(FLAGS.output_path, os.path.basename(im_fn)), img[:, :, ::-1])\n",
    "\n",
    "                with open(os.path.join(FLAGS.output_path, os.path.splitext(os.path.basename(im_fn))[0]) + \".txt\",\n",
    "                          \"w\") as f:\n",
    "                    for i, box in enumerate(boxes):\n",
    "                        line = \",\".join(str(box[k]) for k in range(8))\n",
    "                        line += \",\" + str(scores[i]) + \"\\r\\n\"\n",
    "                        f.writelines(line)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_pt4]",
   "language": "python",
   "name": "conda-env-py3_pt4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
